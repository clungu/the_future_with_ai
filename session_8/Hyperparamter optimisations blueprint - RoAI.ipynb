{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hyperparameter optimisation blueprint\n",
    "\n",
    "Join us as we explore the blueprint for hyperparameter optimization in machine learning. This talk covers tools like TensorFlow and Optuna, thorough preparatory steps including data handling and baseline modeling, and approaches from grid search to Bayesian optimization. Learn to effectively utilize algorithms such as Gaussian Processes and Tree-structured Parzen Estimators to fine-tune your models, enhancing performance and ensuring robustness. Perfect for ML professionals aiming to master their model's efficiency and accuracy."
   ],
   "id": "ba2dc70d0ded2da1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5a334ddb490083ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:06:32.574616Z",
     "start_time": "2024-06-10T10:04:13.437732Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio",
   "id": "89215d717486ebb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting torch\r\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m779.1/779.1 MB\u001B[0m \u001B[31m86.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torchvision\r\n",
      "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.0/7.0 MB\u001B[0m \u001B[31m90.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hCollecting torchaudio\r\n",
      "  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/3.3 MB\u001B[0m \u001B[31m92.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting filelock\r\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\r\n",
      "Collecting jinja2\r\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m133.3/133.3 KB\u001B[0m \u001B[31m176.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting fsspec\r\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.9/176.9 KB\u001B[0m \u001B[31m214.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m823.6/823.6 KB\u001B[0m \u001B[31m179.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.7/23.7 MB\u001B[0m \u001B[31m90.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nccl-cu12==2.20.5\r\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m176.2/176.2 MB\u001B[0m \u001B[31m90.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\r\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m731.7/731.7 MB\u001B[0m \u001B[31m90.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nvtx-cu12==12.1.105\r\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.1/99.1 KB\u001B[0m \u001B[31m192.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-curand-cu12==10.3.2.106\r\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.5/56.5 MB\u001B[0m \u001B[31m53.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cublas-cu12==12.1.3.1\r\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.6/410.6 MB\u001B[0m \u001B[31m89.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting networkx\r\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m145.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting sympy\r\n",
      "  Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/5.7 MB\u001B[0m \u001B[31m98.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting typing-extensions>=4.8.0\r\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/14.1 MB\u001B[0m \u001B[31m86.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cufft-cu12==11.0.2.54\r\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m121.6/121.6 MB\u001B[0m \u001B[31m90.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\r\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.2/124.2 MB\u001B[0m \u001B[31m89.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting triton==2.3.1\r\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m168.1/168.1 MB\u001B[0m \u001B[31m49.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\r\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m196.0/196.0 MB\u001B[0m \u001B[31m87.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting nvidia-nvjitlink-cu12\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.3/21.3 MB\u001B[0m \u001B[31m90.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy in ./envs/sentiocx/lib/python3.10/site-packages (from torchvision) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./envs/sentiocx/lib/python3.10/site-packages (from torchvision) (10.2.0)\r\n",
      "Collecting MarkupSafe>=2.0\r\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\r\n",
      "Collecting mpmath<1.4.0,>=1.1.0\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 KB\u001B[0m \u001B[31m184.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\r\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.14.0 fsspec-2024.6.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sympy-1.12.1 torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1 triton-2.3.1 typing-extensions-4.12.2\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T13:36:14.027024Z",
     "start_time": "2024-06-10T13:36:12.744153Z"
    }
   },
   "source": [
    "import torch as pt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "8ae93443060f6c88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:36:15.706195Z",
     "start_time": "2024-06-10T13:36:15.496813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=50000, n_features=32, n_classes=10, n_informative=5, n_redundant=5, n_repeated=5)\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ],
   "id": "8f51f3822b7c8f98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 32), (7500, 32), (7500, 32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid search",
   "id": "66f1e1343add8032"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:27:03.523615Z",
     "start_time": "2024-06-10T11:27:02.971439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocessor', None),\n",
    "    ('model',  SGDClassifier(loss=\"hinge\", penalty=\"elasticnet\", fit_intercept=True, n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Score: {model.score(X_val, y_val): .3f}\")\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ],
   "id": "ce5b52a0dd83a499",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.192\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       777\n",
      "           1       0.35      0.05      0.08       768\n",
      "           2       0.10      0.23      0.14       725\n",
      "           3       0.21      0.37      0.27       735\n",
      "           4       0.46      0.47      0.46       738\n",
      "           5       0.00      0.00      0.00       744\n",
      "           6       0.25      0.02      0.04       780\n",
      "           7       0.23      0.02      0.04       749\n",
      "           8       0.00      0.00      0.00       756\n",
      "           9       0.16      0.80      0.27       728\n",
      "\n",
      "    accuracy                           0.19      7500\n",
      "   macro avg       0.18      0.20      0.13      7500\n",
      "weighted avg       0.18      0.19      0.13      7500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid search",
   "id": "306b3db3ebe36381"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid search",
   "id": "e5ab842fdf0b5704"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid search",
   "id": "ff65f2be9751808a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:41:08.732358Z",
     "start_time": "2024-06-10T11:38:29.914915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__alpha': [1e-4, 1e-2, 1],\n",
    "    'model__l1_ratio': [0, 0.1, 0.5, 1],\n",
    "    'model__max_iter': [1000, 500001 ,],\n",
    "    'model__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "id": "de934347f9043786",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "72 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'epsilon_insensitive', 'perceptron', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'modified_huber', 'squared_error', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'hinge', 'perceptron', 'huber', 'log_loss', 'modified_huber', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_hinge', 'log_loss', 'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_error', 'huber', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'huber', 'perceptron', 'squared_error', 'log_loss', 'squared_epsilon_insensitive', 'modified_huber', 'epsilon_insensitive', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'squared_hinge', 'huber', 'epsilon_insensitive', 'log_loss', 'hinge', 'squared_error', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'hinge', 'log_loss', 'modified_huber', 'squared_epsilon_insensitive', 'huber', 'perceptron', 'epsilon_insensitive', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'log_loss', 'squared_epsilon_insensitive', 'hinge', 'huber', 'squared_error', 'perceptron', 'modified_huber', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'huber', 'modified_huber', 'epsilon_insensitive', 'hinge', 'perceptron', 'log_loss', 'squared_epsilon_insensitive', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'squared_error', 'log_loss', 'perceptron', 'squared_hinge', 'epsilon_insensitive', 'modified_huber', 'hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_epsilon_insensitive', 'perceptron', 'epsilon_insensitive', 'hinge', 'squared_error', 'huber', 'log_loss', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'modified_huber', 'hinge', 'squared_error', 'log_loss', 'huber', 'epsilon_insensitive', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'squared_hinge', 'huber', 'hinge', 'squared_epsilon_insensitive', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_hinge', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'log_loss', 'perceptron', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'huber', 'perceptron', 'squared_error', 'squared_hinge', 'hinge', 'modified_huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'squared_error', 'log_loss', 'huber', 'perceptron', 'squared_hinge', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_error', 'modified_huber', 'huber', 'log_loss', 'perceptron', 'squared_epsilon_insensitive', 'squared_hinge', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_epsilon_insensitive', 'squared_error', 'modified_huber', 'hinge', 'perceptron', 'epsilon_insensitive', 'squared_hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'modified_huber', 'log_loss', 'squared_epsilon_insensitive', 'huber', 'perceptron', 'squared_hinge', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_hinge', 'perceptron', 'log_loss', 'squared_error', 'huber', 'modified_huber', 'squared_epsilon_insensitive', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'huber', 'epsilon_insensitive', 'squared_hinge', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_error', 'log_loss', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'perceptron', 'modified_huber', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'huber', 'squared_hinge', 'squared_error', 'log_loss', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_error', 'hinge', 'huber', 'squared_epsilon_insensitive', 'squared_hinge', 'modified_huber', 'perceptron', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'log_loss', 'squared_error', 'hinge', 'perceptron', 'huber', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_hinge', 'perceptron', 'huber', 'hinge', 'squared_error', 'squared_epsilon_insensitive', 'modified_huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'log_loss', 'modified_huber', 'squared_error', 'hinge', 'huber', 'squared_epsilon_insensitive', 'squared_hinge', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'squared_hinge', 'log_loss', 'modified_huber', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'hinge', 'huber', 'squared_error', 'log_loss', 'perceptron', 'modified_huber', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'squared_error', 'modified_huber', 'log_loss', 'hinge', 'perceptron', 'epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_hinge', 'modified_huber', 'hinge', 'squared_error', 'log_loss', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'huber', 'modified_huber', 'squared_error', 'squared_epsilon_insensitive', 'squared_hinge', 'epsilon_insensitive', 'log_loss', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'huber', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber', 'squared_error', 'epsilon_insensitive', 'hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.22414282 0.22414282        nan        nan 0.24491425 0.24491425\n",
      " 0.25271397 0.25271397 0.20351462 0.20351462 0.19434225 0.19434225\n",
      "        nan        nan 0.24371476 0.24371476 0.24479991 0.24479991\n",
      " 0.18719948 0.18719948 0.18780048 0.18780048        nan        nan\n",
      " 0.2326573  0.2326573  0.23042935 0.23042935 0.18311316 0.18311316\n",
      " 0.20728548 0.20728548        nan        nan 0.23680071 0.23680071\n",
      " 0.22974361 0.22974361 0.17342733 0.17342733 0.23585709 0.23585709\n",
      "        nan        nan 0.31722835 0.31722835 0.30791433 0.31014283\n",
      " 0.21322845 0.21322845 0.20162848 0.20162848        nan        nan\n",
      " 0.3144288  0.3144288  0.3124288  0.31531443 0.14525719 0.14525719\n",
      " 0.21708635 0.21708635        nan        nan 0.30771409 0.30771409\n",
      " 0.30300052 0.31562873 0.17728522 0.17728522 0.19011489 0.19011489\n",
      "        nan        nan 0.31288577 0.31288577 0.24317149 0.27697166\n",
      " 0.18485703 0.18485703 0.19785739 0.19785739        nan        nan\n",
      " 0.27185732 0.27185732 0.12368641 0.12305772 0.22788643 0.22788643\n",
      " 0.09942854 0.09942854        nan        nan 0.26808585 0.26808585\n",
      " 0.12374264 0.1255712  0.09848563 0.09848563 0.09988572 0.09988572\n",
      "        nan        nan 0.12040072 0.12040072 0.12954245 0.12854248\n",
      " 0.09965715 0.09965715 0.10034286 0.10034286        nan        nan\n",
      " 0.10025715 0.10025715 0.15782777 0.15699924 0.09939997 0.09939997]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor', None),\n",
       "                                       ('model',\n",
       "                                        SGDClassifier(n_jobs=-1,\n",
       "                                                      penalty='elasticnet',\n",
       "                                                      random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.01, 1],\n",
       "                         'model__l1_ratio': [0, 0.1, 0.5, 1],\n",
       "                         'model__loss': ['hinge', 'log', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron'],\n",
       "                         'model__max_iter': [1000, 5000]},\n",
       "             verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        SGDClassifier(n_jobs=-1,\n",
       "                                                      penalty=&#x27;elasticnet&#x27;,\n",
       "                                                      random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__alpha&#x27;: [0.0001, 0.01, 1],\n",
       "                         &#x27;model__l1_ratio&#x27;: [0, 0.1, 0.5, 1],\n",
       "                         &#x27;model__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;, &#x27;modified_huber&#x27;,\n",
       "                                         &#x27;squared_hinge&#x27;, &#x27;perceptron&#x27;],\n",
       "                         &#x27;model__max_iter&#x27;: [1000, 5000]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        SGDClassifier(n_jobs=-1,\n",
       "                                                      penalty=&#x27;elasticnet&#x27;,\n",
       "                                                      random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__alpha&#x27;: [0.0001, 0.01, 1],\n",
       "                         &#x27;model__l1_ratio&#x27;: [0, 0.1, 0.5, 1],\n",
       "                         &#x27;model__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;, &#x27;modified_huber&#x27;,\n",
       "                                         &#x27;squared_hinge&#x27;, &#x27;perceptron&#x27;],\n",
       "                         &#x27;model__max_iter&#x27;: [1000, 5000]},\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                (&#x27;model&#x27;,\n",
       "                 SGDClassifier(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                               random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">None</label><div class=\"sk-toggleable__content fitted\"><pre>None</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:43:00.120713Z",
     "start_time": "2024-06-10T11:43:00.100540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "df.head()"
   ],
   "id": "26e7d50a9f702236",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.727875      0.583665         0.007173        0.000801   \n",
       "1       2.902700      0.649870         0.011543        0.003527   \n",
       "2       0.010537      0.003385         0.000000        0.000000   \n",
       "3       0.008649      0.000654         0.000000        0.000000   \n",
       "4      11.217524      0.818289         0.025633        0.000908   \n",
       "\n",
       "  param_model__alpha param_model__l1_ratio param_model__loss  \\\n",
       "0             0.0001                     0             hinge   \n",
       "1             0.0001                     0             hinge   \n",
       "2             0.0001                     0               log   \n",
       "3             0.0001                     0               log   \n",
       "4             0.0001                     0    modified_huber   \n",
       "\n",
       "  param_model__max_iter                                             params  \\\n",
       "0                  1000  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...   \n",
       "1                  5000  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...   \n",
       "2                  1000  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...   \n",
       "3                  5000  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...   \n",
       "4                  1000  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.218394           0.231336           0.222698         0.224143   \n",
       "1           0.218394           0.231336           0.222698         0.224143   \n",
       "2                NaN                NaN                NaN              NaN   \n",
       "3                NaN                NaN                NaN              NaN   \n",
       "4           0.228422           0.262707           0.243614         0.244914   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.005382               41  \n",
       "1        0.005382               41  \n",
       "2             NaN               97  \n",
       "3             NaN               97  \n",
       "4        0.014027               22  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__l1_ratio</th>\n",
       "      <th>param_model__loss</th>\n",
       "      <th>param_model__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.727875</td>\n",
       "      <td>0.583665</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "      <td>0.218394</td>\n",
       "      <td>0.231336</td>\n",
       "      <td>0.222698</td>\n",
       "      <td>0.224143</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.902700</td>\n",
       "      <td>0.649870</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "      <td>0.218394</td>\n",
       "      <td>0.231336</td>\n",
       "      <td>0.222698</td>\n",
       "      <td>0.224143</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010537</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008649</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>log</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.217524</td>\n",
       "      <td>0.818289</td>\n",
       "      <td>0.025633</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "      <td>0.228422</td>\n",
       "      <td>0.262707</td>\n",
       "      <td>0.243614</td>\n",
       "      <td>0.244914</td>\n",
       "      <td>0.014027</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:43:08.141903Z",
     "start_time": "2024-06-10T11:43:08.130385Z"
    }
   },
   "cell_type": "code",
   "source": "df[['mean_test_score', 'params']]",
   "id": "b9a445f6f7f35e9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     mean_test_score                                             params\n",
       "0           0.224143  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...\n",
       "1           0.224143  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...\n",
       "2                NaN  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...\n",
       "3                NaN  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...\n",
       "4           0.244914  {'model__alpha': 0.0001, 'model__l1_ratio': 0,...\n",
       "..               ...                                                ...\n",
       "115         0.100257  {'model__alpha': 1, 'model__l1_ratio': 1, 'mod...\n",
       "116         0.157828  {'model__alpha': 1, 'model__l1_ratio': 1, 'mod...\n",
       "117         0.156999  {'model__alpha': 1, 'model__l1_ratio': 1, 'mod...\n",
       "118         0.099400  {'model__alpha': 1, 'model__l1_ratio': 1, 'mod...\n",
       "119         0.099400  {'model__alpha': 1, 'model__l1_ratio': 1, 'mod...\n",
       "\n",
       "[120 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.224143</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.224143</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244914</td>\n",
       "      <td>{'model__alpha': 0.0001, 'model__l1_ratio': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.100257</td>\n",
       "      <td>{'model__alpha': 1, 'model__l1_ratio': 1, 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.157828</td>\n",
       "      <td>{'model__alpha': 1, 'model__l1_ratio': 1, 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.156999</td>\n",
       "      <td>{'model__alpha': 1, 'model__l1_ratio': 1, 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.099400</td>\n",
       "      <td>{'model__alpha': 1, 'model__l1_ratio': 1, 'mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.099400</td>\n",
       "      <td>{'model__alpha': 1, 'model__l1_ratio': 1, 'mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:43:13.349329Z",
     "start_time": "2024-06-10T11:43:13.338729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = pd.DataFrame.from_records(df['params'].tolist())\n",
    "res['score'] = df['mean_test_score']\n",
    "\n",
    "res.head()"
   ],
   "id": "a7f9bbff1f368c35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   model__alpha  model__l1_ratio     model__loss  model__max_iter     score\n",
       "0        0.0001              0.0           hinge             1000  0.224143\n",
       "1        0.0001              0.0           hinge             5000  0.224143\n",
       "2        0.0001              0.0             log             1000       NaN\n",
       "3        0.0001              0.0             log             5000       NaN\n",
       "4        0.0001              0.0  modified_huber             1000  0.244914"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model__alpha</th>\n",
       "      <th>model__l1_ratio</th>\n",
       "      <th>model__loss</th>\n",
       "      <th>model__max_iter</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.224143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hinge</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.224143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>log</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>log</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.244914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visualizing the results",
   "id": "a578e40ec19c82d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:43:18.229376Z",
     "start_time": "2024-06-10T11:43:18.198719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res.pivot_table(\n",
    "    values=['score'], \n",
    "    index=['model__alpha', 'model__l1_ratio'],     # df.columns[:len(df.columns)//2]\n",
    "    columns=['model__loss', 'model__max_iter']                  # df.columns[len(df.columns)//2:]         \n",
    ")"
   ],
   "id": "b6206339651cd4c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                 score                                     \\\n",
       "model__loss                      hinge           modified_huber             \n",
       "model__max_iter                   1000      5000           1000      5000   \n",
       "model__alpha model__l1_ratio                                                \n",
       "0.0001       0.0              0.224143  0.224143       0.244914  0.244914   \n",
       "             0.1              0.194342  0.194342       0.243715  0.243715   \n",
       "             0.5              0.187800  0.187800       0.232657  0.232657   \n",
       "             1.0              0.207285  0.207285       0.236801  0.236801   \n",
       "0.0100       0.0              0.235857  0.235857       0.317228  0.317228   \n",
       "             0.1              0.201628  0.201628       0.314429  0.314429   \n",
       "             0.5              0.217086  0.217086       0.307714  0.307714   \n",
       "             1.0              0.190115  0.190115       0.312886  0.312886   \n",
       "1.0000       0.0              0.197857  0.197857       0.271857  0.271857   \n",
       "             0.1              0.099429  0.099429       0.268086  0.268086   \n",
       "             0.5              0.099886  0.099886       0.120401  0.120401   \n",
       "             1.0              0.100343  0.100343       0.100257  0.100257   \n",
       "\n",
       "                                                                           \n",
       "model__loss                  perceptron           squared_hinge            \n",
       "model__max_iter                    1000      5000          1000      5000  \n",
       "model__alpha model__l1_ratio                                               \n",
       "0.0001       0.0               0.203515  0.203515      0.252714  0.252714  \n",
       "             0.1               0.187199  0.187199      0.244800  0.244800  \n",
       "             0.5               0.183113  0.183113      0.230429  0.230429  \n",
       "             1.0               0.173427  0.173427      0.229744  0.229744  \n",
       "0.0100       0.0               0.213228  0.213228      0.307914  0.310143  \n",
       "             0.1               0.145257  0.145257      0.312429  0.315314  \n",
       "             0.5               0.177285  0.177285      0.303001  0.315629  \n",
       "             1.0               0.184857  0.184857      0.243171  0.276972  \n",
       "1.0000       0.0               0.227886  0.227886      0.123686  0.123058  \n",
       "             0.1               0.098486  0.098486      0.123743  0.125571  \n",
       "             0.5               0.099657  0.099657      0.129542  0.128542  \n",
       "             1.0               0.099400  0.099400      0.157828  0.156999  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model__loss</th>\n",
       "      <th colspan=\"2\" halign=\"left\">hinge</th>\n",
       "      <th colspan=\"2\" halign=\"left\">modified_huber</th>\n",
       "      <th colspan=\"2\" halign=\"left\">perceptron</th>\n",
       "      <th colspan=\"2\" halign=\"left\">squared_hinge</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model__max_iter</th>\n",
       "      <th>1000</th>\n",
       "      <th>5000</th>\n",
       "      <th>1000</th>\n",
       "      <th>5000</th>\n",
       "      <th>1000</th>\n",
       "      <th>5000</th>\n",
       "      <th>1000</th>\n",
       "      <th>5000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model__alpha</th>\n",
       "      <th>model__l1_ratio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0001</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0.224143</td>\n",
       "      <td>0.224143</td>\n",
       "      <td>0.244914</td>\n",
       "      <td>0.244914</td>\n",
       "      <td>0.203515</td>\n",
       "      <td>0.203515</td>\n",
       "      <td>0.252714</td>\n",
       "      <td>0.252714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.194342</td>\n",
       "      <td>0.194342</td>\n",
       "      <td>0.243715</td>\n",
       "      <td>0.243715</td>\n",
       "      <td>0.187199</td>\n",
       "      <td>0.187199</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.232657</td>\n",
       "      <td>0.232657</td>\n",
       "      <td>0.183113</td>\n",
       "      <td>0.183113</td>\n",
       "      <td>0.230429</td>\n",
       "      <td>0.230429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.207285</td>\n",
       "      <td>0.207285</td>\n",
       "      <td>0.236801</td>\n",
       "      <td>0.236801</td>\n",
       "      <td>0.173427</td>\n",
       "      <td>0.173427</td>\n",
       "      <td>0.229744</td>\n",
       "      <td>0.229744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0100</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.235857</td>\n",
       "      <td>0.317228</td>\n",
       "      <td>0.317228</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>0.213228</td>\n",
       "      <td>0.307914</td>\n",
       "      <td>0.310143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.201628</td>\n",
       "      <td>0.201628</td>\n",
       "      <td>0.314429</td>\n",
       "      <td>0.314429</td>\n",
       "      <td>0.145257</td>\n",
       "      <td>0.145257</td>\n",
       "      <td>0.312429</td>\n",
       "      <td>0.315314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.217086</td>\n",
       "      <td>0.217086</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.307714</td>\n",
       "      <td>0.177285</td>\n",
       "      <td>0.177285</td>\n",
       "      <td>0.303001</td>\n",
       "      <td>0.315629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.190115</td>\n",
       "      <td>0.190115</td>\n",
       "      <td>0.312886</td>\n",
       "      <td>0.312886</td>\n",
       "      <td>0.184857</td>\n",
       "      <td>0.184857</td>\n",
       "      <td>0.243171</td>\n",
       "      <td>0.276972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0000</th>\n",
       "      <th>0.0</th>\n",
       "      <td>0.197857</td>\n",
       "      <td>0.197857</td>\n",
       "      <td>0.271857</td>\n",
       "      <td>0.271857</td>\n",
       "      <td>0.227886</td>\n",
       "      <td>0.227886</td>\n",
       "      <td>0.123686</td>\n",
       "      <td>0.123058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.099429</td>\n",
       "      <td>0.099429</td>\n",
       "      <td>0.268086</td>\n",
       "      <td>0.268086</td>\n",
       "      <td>0.098486</td>\n",
       "      <td>0.098486</td>\n",
       "      <td>0.123743</td>\n",
       "      <td>0.125571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.099886</td>\n",
       "      <td>0.099886</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>0.129542</td>\n",
       "      <td>0.128542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.100343</td>\n",
       "      <td>0.100257</td>\n",
       "      <td>0.100257</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.157828</td>\n",
       "      <td>0.156999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:43:23.212859Z",
     "start_time": "2024-06-10T11:43:22.211357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.clustermap(res.pivot_table(\n",
    "    values=['score'], \n",
    "    index=['model__alpha', 'model__l1_ratio'],     # df.columns[:len(df.columns)//2]\n",
    "    columns=['model__loss', 'model__max_iter']                  # df.columns[len(df.columns)//2:]         \n",
    "), annot=True)\n"
   ],
   "id": "15651115c613438d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.matrix.ClusterGrid at 0x7fa49cf79090>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:43:42.834598Z",
     "start_time": "2024-06-10T11:43:42.829612Z"
    }
   },
   "cell_type": "code",
   "source": "grid_search.best_params_",
   "id": "5e0a15a103ee7c51",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.01,\n",
       " 'model__l1_ratio': 0,\n",
       " 'model__loss': 'modified_huber',\n",
       " 'model__max_iter': 1000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "```python\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "grid_search = {\n",
    "        # model config\n",
    "        \"add_bias\": [True, False],\n",
    "        \"dropout\": [0.1, 0.8],\n",
    "        \"embedding_size\": [8, 16],\n",
    "        \"lr\": [0.001, 0.00001],\n",
    "        \n",
    "        # training procedure\n",
    "        \"batch_size\": [50, 200],\n",
    "        \"shuffle\": [True, False],\n",
    "        \"optimizer\": [RMSprop, SGD]\n",
    "}\n",
    "        \n",
    "repeats = 5\n",
    "write_header()\n",
    "for group, config in enumerate(tqdm(ParameterGrid(grid_search))):\n",
    "    for _ in range(repeats):\n",
    "        model = build_model_from_config(**config)\n",
    "        history = train_from_config(model, **config)\n",
    "        stats = compute_stats(history)\n",
    "        write_stats(stats)\n",
    "```"
   ],
   "id": "44f6b47873bf5adc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:07:39.600548Z",
     "start_time": "2024-06-10T12:07:39.596288Z"
    }
   },
   "cell_type": "code",
   "source": "grid_search.best_score_",
   "id": "26130da4e7382c1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3172283466339501"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random search",
   "id": "b18a3d227ce15642"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:53:44.283832Z",
     "start_time": "2024-06-10T11:50:46.291411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "    'model__l1_ratio': [0, 0.1, 0.1, 0.3, 0.5, 1],\n",
    "    'model__max_iter': [1000, 5000, 10000],\n",
    "    'model__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=50, cv=3, n_jobs=-1, verbose=2)\n",
    "random_search.fit(X_train, y_train)"
   ],
   "id": "d6eff23a6db51340",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "24 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'epsilon_insensitive', 'modified_huber', 'huber', 'log_loss', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'modified_huber', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge', 'log_loss', 'huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'log_loss', 'hinge', 'squared_error', 'modified_huber', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'perceptron', 'squared_hinge', 'log_loss', 'squared_epsilon_insensitive', 'modified_huber', 'squared_error', 'epsilon_insensitive', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'huber', 'log_loss', 'modified_huber', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'squared_error', 'perceptron', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'hinge', 'squared_error', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'log_loss', 'modified_huber', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'modified_huber', 'log_loss', 'squared_hinge', 'hinge', 'perceptron', 'epsilon_insensitive', 'squared_error', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'perceptron', 'squared_hinge', 'hinge', 'epsilon_insensitive', 'huber', 'squared_epsilon_insensitive', 'log_loss', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_hinge', 'squared_error', 'modified_huber', 'huber', 'hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'log_loss', 'hinge', 'huber', 'modified_huber', 'squared_error', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'huber', 'log_loss', 'modified_huber', 'squared_error', 'hinge', 'squared_hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'log_loss', 'modified_huber', 'hinge', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'perceptron', 'squared_epsilon_insensitive', 'log_loss', 'squared_error', 'epsilon_insensitive', 'hinge', 'huber', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.20162848 0.24491425 0.21791476 0.29648618 0.12040072 0.23585709\n",
      " 0.30771409        nan 0.1255712  0.14525719 0.14714295 0.30971455\n",
      " 0.30791433 0.12954245 0.2976572  0.22325681 0.22414282        nan\n",
      " 0.1566278  0.3124288  0.17497057 0.30108546 0.21708635 0.3144288\n",
      " 0.3025719  0.18560013        nan 0.2460009         nan 0.23379925\n",
      " 0.20162848        nan 0.22768609 0.23680071        nan 0.15834264\n",
      " 0.21791476 0.17342733 0.29648618 0.31548585 0.31562873 0.26808585\n",
      "        nan 0.23497153        nan 0.18531326 0.28911486 0.20740076\n",
      " 0.21791476 0.30200029]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('preprocessor', None),\n",
       "                                             ('model',\n",
       "                                              SGDClassifier(n_jobs=-1,\n",
       "                                                            penalty='elasticnet',\n",
       "                                                            random_state=42))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'model__alpha': [0.0001, 0.001, 0.01,\n",
       "                                                         0.1, 1],\n",
       "                                        'model__l1_ratio': [0, 0.1, 0.1, 0.3,\n",
       "                                                            0.5, 1],\n",
       "                                        'model__loss': ['hinge', 'log',\n",
       "                                                        'modified_huber',\n",
       "                                                        'squared_hinge',\n",
       "                                                        'perceptron'],\n",
       "                                        'model__max_iter': [1000, 5000, 10000]},\n",
       "                   verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              SGDClassifier(n_jobs=-1,\n",
       "                                                            penalty=&#x27;elasticnet&#x27;,\n",
       "                                                            random_state=42))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;model__alpha&#x27;: [0.0001, 0.001, 0.01,\n",
       "                                                         0.1, 1],\n",
       "                                        &#x27;model__l1_ratio&#x27;: [0, 0.1, 0.1, 0.3,\n",
       "                                                            0.5, 1],\n",
       "                                        &#x27;model__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;,\n",
       "                                                        &#x27;modified_huber&#x27;,\n",
       "                                                        &#x27;squared_hinge&#x27;,\n",
       "                                                        &#x27;perceptron&#x27;],\n",
       "                                        &#x27;model__max_iter&#x27;: [1000, 5000, 10000]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                                             (&#x27;model&#x27;,\n",
       "                                              SGDClassifier(n_jobs=-1,\n",
       "                                                            penalty=&#x27;elasticnet&#x27;,\n",
       "                                                            random_state=42))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;model__alpha&#x27;: [0.0001, 0.001, 0.01,\n",
       "                                                         0.1, 1],\n",
       "                                        &#x27;model__l1_ratio&#x27;: [0, 0.1, 0.1, 0.3,\n",
       "                                                            0.5, 1],\n",
       "                                        &#x27;model__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;,\n",
       "                                                        &#x27;modified_huber&#x27;,\n",
       "                                                        &#x27;squared_hinge&#x27;,\n",
       "                                                        &#x27;perceptron&#x27;],\n",
       "                                        &#x27;model__max_iter&#x27;: [1000, 5000, 10000]},\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                (&#x27;model&#x27;,\n",
       "                 SGDClassifier(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                               random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">None</label><div class=\"sk-toggleable__content fitted\"><pre>None</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:07:08.168835Z",
     "start_time": "2024-06-10T12:07:08.164447Z"
    }
   },
   "cell_type": "code",
   "source": "random_search.best_score_",
   "id": "ba13e164fb9654da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3156287303157702"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:54:44.899227Z",
     "start_time": "2024-06-10T11:54:43.608441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(random_search.cv_results_)\n",
    "res = pd.DataFrame.from_records(df['params'].tolist())\n",
    "res['score'] = df['mean_test_score']\n",
    "\n",
    "sns.clustermap(res.pivot_table(\n",
    "    values=['score'], \n",
    "    index=['model__alpha', 'model__l1_ratio'],     # df.columns[:len(df.columns)//2]\n",
    "    columns=['model__loss', 'model__max_iter']                  # df.columns[len(df.columns)//2:]         \n",
    ").fillna(0), annot=True)"
   ],
   "id": "68869f33f54be2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.matrix.ClusterGrid at 0x7fa4484012d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T11:56:35.186630Z",
     "start_time": "2024-06-10T11:56:35.182219Z"
    }
   },
   "cell_type": "code",
   "source": "random_search.best_params_",
   "id": "d8f9d4660bf1162a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_iter': 5000,\n",
       " 'model__loss': 'squared_hinge',\n",
       " 'model__l1_ratio': 0.5,\n",
       " 'model__alpha': 0.01}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Halving grid search",
   "id": "1819ec69b347f36e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:32:41.475608Z",
     "start_time": "2024-06-10T12:27:22.226579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1],\n",
    "    'model__l1_ratio': [0, 0.1, 0.1, 0.3, 0.5, 1],\n",
    "    'model__max_iter': [1000, 5000, 10000],\n",
    "    'model__loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "}\n",
    "\n",
    "hgs = HalvingGridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, factor=0.8^(-1), cv=5, n_jobs=-1, verbose=2, min_resources=1000\n",
    ")\n",
    "hgs.fit(X_train, y_train)"
   ],
   "id": "8f4f5135c89c853e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 9\n",
      "n_required_iterations: 16\n",
      "n_possible_iterations: 9\n",
      "min_resources_: 1000\n",
      "max_resources_: 35000\n",
      "aggressive_elimination: False\n",
      "factor: 1.5\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 450\n",
      "n_resources: 1000\n",
      "Fitting 5 folds for each of 450 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "450 fits failed out of a total of 2250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'squared_error', 'squared_hinge', 'modified_huber', 'epsilon_insensitive', 'perceptron', 'huber', 'log_loss', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'log_loss', 'squared_error', 'perceptron', 'epsilon_insensitive', 'huber', 'squared_hinge', 'modified_huber', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'hinge', 'perceptron', 'log_loss', 'modified_huber', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'huber', 'log_loss', 'epsilon_insensitive', 'squared_error', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'modified_huber', 'squared_hinge', 'log_loss', 'squared_error', 'huber', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_error', 'epsilon_insensitive', 'hinge', 'perceptron', 'log_loss', 'squared_epsilon_insensitive', 'squared_hinge', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'huber', 'modified_huber', 'log_loss', 'squared_error', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_error', 'perceptron', 'log_loss', 'hinge', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'log_loss', 'huber', 'hinge', 'modified_huber', 'squared_error', 'squared_hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'huber', 'hinge', 'squared_hinge', 'squared_error', 'squared_epsilon_insensitive', 'modified_huber', 'log_loss', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'perceptron', 'log_loss', 'huber', 'hinge', 'squared_error', 'modified_huber', 'squared_epsilon_insensitive', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'log_loss', 'modified_huber', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_epsilon_insensitive', 'squared_hinge', 'epsilon_insensitive', 'modified_huber', 'perceptron', 'squared_error', 'hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'hinge', 'squared_epsilon_insensitive', 'perceptron', 'modified_huber', 'squared_hinge', 'epsilon_insensitive', 'squared_error', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'perceptron', 'modified_huber', 'log_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'log_loss', 'modified_huber', 'squared_error', 'epsilon_insensitive', 'perceptron', 'hinge', 'squared_epsilon_insensitive', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_error', 'perceptron', 'huber', 'log_loss', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'modified_huber', 'huber', 'log_loss', 'hinge', 'squared_error', 'squared_epsilon_insensitive', 'perceptron', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'log_loss', 'squared_error', 'perceptron', 'modified_huber', 'squared_epsilon_insensitive', 'huber', 'squared_hinge', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'log_loss', 'epsilon_insensitive', 'hinge', 'huber', 'squared_epsilon_insensitive', 'perceptron', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'log_loss', 'hinge', 'perceptron', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'huber', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_error', 'squared_hinge', 'modified_huber', 'huber', 'log_loss', 'squared_epsilon_insensitive', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'hinge', 'squared_error', 'squared_epsilon_insensitive', 'huber', 'epsilon_insensitive', 'squared_hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'huber', 'squared_error', 'modified_huber', 'perceptron', 'squared_epsilon_insensitive', 'hinge', 'log_loss', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_error', 'perceptron', 'hinge', 'huber', 'squared_hinge', 'modified_huber', 'log_loss', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'perceptron', 'log_loss', 'epsilon_insensitive', 'squared_hinge', 'squared_error', 'huber', 'hinge', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'huber', 'hinge', 'squared_hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'squared_error', 'log_loss', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_error', 'log_loss', 'huber', 'hinge', 'squared_epsilon_insensitive', 'modified_huber', 'perceptron', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_error', 'huber', 'squared_hinge', 'perceptron', 'log_loss', 'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_hinge', 'hinge', 'squared_error', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'perceptron', 'squared_hinge', 'squared_error', 'epsilon_insensitive', 'modified_huber', 'huber', 'squared_epsilon_insensitive', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge', 'perceptron', 'squared_error', 'modified_huber', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_epsilon_insensitive', 'modified_huber', 'epsilon_insensitive', 'perceptron', 'hinge', 'squared_error', 'huber', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'squared_hinge', 'huber', 'log_loss', 'perceptron', 'epsilon_insensitive', 'modified_huber', 'squared_error', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_epsilon_insensitive', 'squared_hinge', 'hinge', 'log_loss', 'squared_error', 'huber', 'epsilon_insensitive', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'log_loss', 'modified_huber', 'squared_hinge', 'perceptron', 'huber', 'epsilon_insensitive', 'hinge', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_hinge', 'epsilon_insensitive', 'squared_error', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber', 'log_loss', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'log_loss', 'squared_hinge', 'huber', 'squared_epsilon_insensitive', 'perceptron', 'epsilon_insensitive', 'hinge', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_hinge', 'log_loss', 'perceptron', 'modified_huber', 'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'hinge', 'squared_error', 'squared_hinge', 'huber', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'squared_hinge', 'modified_huber', 'hinge', 'huber', 'log_loss', 'perceptron', 'epsilon_insensitive', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'squared_hinge', 'squared_error', 'modified_huber', 'hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'log_loss', 'squared_hinge', 'perceptron', 'epsilon_insensitive', 'hinge', 'huber', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'epsilon_insensitive', 'perceptron', 'hinge', 'modified_huber', 'huber', 'squared_epsilon_insensitive', 'squared_error', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_epsilon_insensitive', 'modified_huber', 'log_loss', 'squared_error', 'hinge', 'perceptron', 'squared_hinge', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'perceptron', 'squared_error', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'hinge', 'squared_hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'log_loss', 'hinge', 'squared_hinge', 'squared_epsilon_insensitive', 'modified_huber', 'squared_error', 'epsilon_insensitive', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'modified_huber', 'squared_error', 'squared_epsilon_insensitive', 'huber', 'squared_hinge', 'perceptron', 'log_loss', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'log_loss', 'modified_huber', 'huber', 'perceptron', 'hinge', 'squared_hinge', 'squared_error', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'squared_error', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'hinge', 'perceptron', 'epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'log_loss', 'huber', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'squared_error', 'log_loss', 'perceptron', 'modified_huber', 'huber', 'squared_hinge', 'epsilon_insensitive', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'huber', 'squared_hinge', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'squared_error', 'squared_epsilon_insensitive', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_hinge', 'squared_error', 'modified_huber', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'squared_error', 'perceptron', 'modified_huber', 'hinge', 'epsilon_insensitive', 'squared_hinge', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'perceptron', 'huber', 'squared_epsilon_insensitive', 'squared_error', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'squared_hinge', 'log_loss', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'modified_huber', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'modified_huber', 'log_loss', 'perceptron', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'log_loss', 'modified_huber', 'squared_error', 'huber', 'squared_hinge', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'perceptron', 'squared_hinge', 'modified_huber', 'huber', 'squared_error', 'hinge', 'log_loss', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'epsilon_insensitive', 'modified_huber', 'squared_error', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'squared_hinge', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'modified_huber', 'log_loss', 'perceptron', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'squared_epsilon_insensitive', 'huber', 'epsilon_insensitive', 'hinge', 'log_loss', 'squared_hinge', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'huber', 'squared_epsilon_insensitive', 'perceptron', 'squared_hinge', 'log_loss', 'squared_error', 'epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'perceptron', 'epsilon_insensitive', 'log_loss', 'squared_hinge', 'squared_epsilon_insensitive', 'hinge', 'huber', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'log_loss', 'huber', 'epsilon_insensitive', 'squared_hinge', 'squared_error', 'hinge', 'modified_huber', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'squared_error', 'epsilon_insensitive', 'perceptron', 'squared_hinge', 'log_loss', 'squared_epsilon_insensitive', 'huber', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
      "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'epsilon_insensitive', 'log_loss', 'squared_error', 'modified_huber', 'perceptron', 'squared_hinge', 'huber', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203 0.203 0.203   nan   nan   nan 0.21  0.21  0.21  0.215 0.215 0.215\n",
      " 0.224 0.224 0.224 0.217 0.217 0.217   nan   nan   nan 0.199 0.199 0.199\n",
      " 0.194 0.194 0.194 0.188 0.188 0.188 0.217 0.217 0.217   nan   nan   nan\n",
      " 0.199 0.199 0.199 0.194 0.194 0.194 0.188 0.188 0.188 0.203 0.203 0.203\n",
      "   nan   nan   nan 0.177 0.177 0.177 0.196 0.196 0.196 0.202 0.202 0.202\n",
      " 0.215 0.215 0.215   nan   nan   nan 0.189 0.189 0.189 0.199 0.199 0.199\n",
      " 0.201 0.201 0.201 0.206 0.206 0.206   nan   nan   nan 0.197 0.197 0.197\n",
      " 0.202 0.202 0.202 0.211 0.211 0.211 0.232 0.232 0.232   nan   nan   nan\n",
      " 0.181 0.181 0.181 0.191 0.191 0.191 0.199 0.199 0.199 0.222 0.222 0.222\n",
      "   nan   nan   nan 0.227 0.227 0.227 0.194 0.194 0.194 0.194 0.194 0.194\n",
      " 0.222 0.222 0.222   nan   nan   nan 0.227 0.227 0.227 0.194 0.194 0.194\n",
      " 0.194 0.194 0.194 0.203 0.203 0.203   nan   nan   nan 0.188 0.188 0.188\n",
      " 0.176 0.176 0.176 0.178 0.178 0.178 0.231 0.231 0.231   nan   nan   nan\n",
      " 0.164 0.164 0.164 0.206 0.206 0.206 0.178 0.178 0.178 0.218 0.218 0.218\n",
      "   nan   nan   nan 0.187 0.187 0.187 0.175 0.175 0.175 0.189 0.189 0.189\n",
      " 0.24  0.24  0.24    nan   nan   nan 0.252 0.252 0.252 0.19  0.211 0.218\n",
      " 0.205 0.205 0.205 0.232 0.232 0.232   nan   nan   nan 0.275 0.274 0.274\n",
      " 0.194 0.213 0.221 0.184 0.184 0.184 0.232 0.232 0.232   nan   nan   nan\n",
      " 0.275 0.274 0.274 0.194 0.213 0.221 0.184 0.184 0.184 0.2   0.2   0.2\n",
      "   nan   nan   nan 0.281 0.281 0.281 0.19  0.208 0.212 0.191 0.191 0.191\n",
      " 0.207 0.207 0.207   nan   nan   nan 0.28  0.281 0.281 0.18  0.206 0.213\n",
      " 0.172 0.172 0.172 0.207 0.207 0.207   nan   nan   nan 0.263 0.269 0.269\n",
      " 0.18  0.181 0.188 0.184 0.184 0.184 0.277 0.277 0.277   nan   nan   nan\n",
      " 0.246 0.246 0.246 0.172 0.173 0.171 0.25  0.25  0.25  0.259 0.259 0.259\n",
      "   nan   nan   nan 0.251 0.251 0.251 0.169 0.165 0.166 0.219 0.219 0.219\n",
      " 0.259 0.259 0.259   nan   nan   nan 0.251 0.251 0.251 0.169 0.165 0.166\n",
      " 0.219 0.219 0.219 0.185 0.185 0.185   nan   nan   nan 0.244 0.244 0.244\n",
      " 0.18  0.177 0.177 0.15  0.15  0.15  0.144 0.144 0.144   nan   nan   nan\n",
      " 0.249 0.249 0.249 0.179 0.176 0.177 0.146 0.146 0.146 0.093 0.093 0.093\n",
      "   nan   nan   nan 0.222 0.212 0.212 0.197 0.179 0.175 0.107 0.107 0.107\n",
      " 0.234 0.234 0.234   nan   nan   nan 0.251 0.251 0.251 0.131 0.132 0.132\n",
      " 0.216 0.216 0.216 0.115 0.115 0.115   nan   nan   nan 0.251 0.251 0.251\n",
      " 0.117 0.117 0.117 0.112 0.112 0.112 0.115 0.115 0.115   nan   nan   nan\n",
      " 0.251 0.251 0.251 0.117 0.117 0.117 0.112 0.112 0.112 0.116 0.116 0.116\n",
      "   nan   nan   nan 0.154 0.154 0.154 0.121 0.122 0.122 0.093 0.093 0.093\n",
      " 0.099 0.099 0.099   nan   nan   nan 0.108 0.108 0.108 0.123 0.123 0.122\n",
      " 0.093 0.093 0.093 0.111 0.111 0.111   nan   nan   nan 0.1   0.1   0.1\n",
      " 0.173 0.174 0.175 0.094 0.094 0.094]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525 0.24525 0.24525     nan     nan     nan 0.25725 0.25725 0.25725\n",
      " 0.2495  0.2495  0.2495  0.26075 0.26075 0.26075 0.26375 0.26375 0.26375\n",
      "     nan     nan     nan 0.2565  0.2565  0.2565  0.2315  0.2315  0.2315\n",
      " 0.2625  0.2625  0.2625  0.26375 0.26375 0.26375     nan     nan     nan\n",
      " 0.2565  0.2565  0.2565  0.2315  0.2315  0.2315  0.2625  0.2625  0.2625\n",
      " 0.2585  0.2585  0.2585      nan     nan     nan 0.2345  0.2345  0.2345\n",
      " 0.241   0.241   0.241   0.2335  0.2335  0.2335  0.26525 0.26525 0.26525\n",
      "     nan     nan     nan 0.24475 0.24475 0.24475 0.248   0.248   0.248\n",
      " 0.226   0.226   0.226   0.2505  0.2505  0.2505      nan     nan     nan\n",
      " 0.23825 0.23825 0.23825 0.247   0.247   0.247   0.2305  0.2305  0.2305\n",
      " 0.28125 0.28125 0.28125     nan     nan     nan 0.24125 0.24125 0.24125\n",
      " 0.21525 0.21525 0.21525 0.24175 0.24175 0.24175 0.2795  0.2795  0.2795\n",
      "     nan     nan     nan 0.27125 0.27125 0.27125 0.2385  0.2385  0.2385\n",
      " 0.24575 0.24575 0.24575 0.2795  0.2795  0.2795      nan     nan     nan\n",
      " 0.27125 0.27125 0.27125 0.2385  0.2385  0.2385  0.24575 0.24575 0.24575\n",
      " 0.265   0.265   0.265       nan     nan     nan 0.2385  0.2385  0.2385\n",
      " 0.217   0.217   0.217   0.21925 0.21925 0.21925 0.2885  0.2885  0.2885\n",
      "     nan     nan     nan 0.23675 0.23675 0.23675 0.23    0.23    0.23\n",
      " 0.2185  0.2185  0.2185  0.26775 0.26775 0.26775     nan     nan     nan\n",
      " 0.2305  0.2305  0.2305  0.231   0.231   0.231   0.227   0.227   0.227\n",
      " 0.32075 0.32075 0.32075     nan     nan     nan 0.33    0.33    0.33\n",
      " 0.23275 0.2785  0.28825 0.26625 0.26625 0.26625 0.286   0.286   0.286\n",
      "     nan     nan     nan 0.3535  0.35325 0.35325 0.23275 0.2805  0.28975\n",
      " 0.235   0.235   0.235   0.286   0.286   0.286       nan     nan     nan\n",
      " 0.3535  0.35325 0.35325 0.23275 0.2805  0.28975 0.235   0.235   0.235\n",
      " 0.27125 0.27125 0.27125     nan     nan     nan 0.35725 0.3575  0.3575\n",
      " 0.22075 0.2735  0.28225 0.2465  0.2465  0.2465  0.25475 0.25475 0.25475\n",
      "     nan     nan     nan 0.35025 0.35125 0.35125 0.2195  0.26525 0.27775\n",
      " 0.21175 0.21175 0.21175 0.264   0.264   0.264       nan     nan     nan\n",
      " 0.33425 0.34225 0.34225 0.212   0.229   0.24725 0.1965  0.1965  0.1965\n",
      " 0.3285  0.3285  0.3285      nan     nan     nan 0.3095  0.3095  0.3095\n",
      " 0.20875 0.20475 0.2025  0.30225 0.30225 0.30225 0.26925 0.26925 0.26925\n",
      "     nan     nan     nan 0.30875 0.30875 0.30875 0.20425 0.20225 0.202\n",
      " 0.24325 0.24325 0.24325 0.26925 0.26925 0.26925     nan     nan     nan\n",
      " 0.30875 0.30875 0.30875 0.20425 0.20225 0.202   0.24325 0.24325 0.24325\n",
      " 0.2015  0.2015  0.2015      nan     nan     nan 0.294   0.294   0.294\n",
      " 0.213   0.2075  0.207   0.1595  0.1595  0.1595  0.15125 0.15125 0.15125\n",
      "     nan     nan     nan 0.28475 0.28475 0.28475 0.2145  0.20975 0.20975\n",
      " 0.1245  0.1245  0.1245  0.11725 0.11725 0.11725     nan     nan     nan\n",
      " 0.22725 0.2225  0.2225  0.24075 0.223   0.2205  0.1085  0.1085  0.1085\n",
      " 0.27275 0.27275 0.27275     nan     nan     nan 0.2955  0.2955  0.2955\n",
      " 0.12575 0.12625 0.12675 0.249   0.249   0.249   0.127   0.127   0.127\n",
      "     nan     nan     nan 0.2505  0.2505  0.2505  0.112   0.112   0.11225\n",
      " 0.13875 0.13875 0.13875 0.127   0.127   0.127       nan     nan     nan\n",
      " 0.2505  0.2505  0.2505  0.112   0.112   0.11225 0.13875 0.13875 0.13875\n",
      " 0.108   0.108   0.108       nan     nan     nan 0.20325 0.20325 0.20325\n",
      " 0.12    0.12    0.12    0.107   0.107   0.107   0.1025  0.1025  0.1025\n",
      "     nan     nan     nan 0.133   0.133   0.133   0.1215  0.1215  0.1215\n",
      " 0.107   0.107   0.107   0.1015  0.1015  0.1015      nan     nan     nan\n",
      " 0.10875 0.10875 0.10875 0.1805  0.17825 0.1795  0.10275 0.10275 0.10275]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 300\n",
      "n_resources: 1500\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   4.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  33.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   7.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203             nan        nan        nan\n",
      " 0.21       0.21       0.21       0.215      0.215      0.215\n",
      " 0.224      0.224      0.224      0.217      0.217      0.217\n",
      "        nan        nan        nan 0.199      0.199      0.199\n",
      " 0.194      0.194      0.194      0.188      0.188      0.188\n",
      " 0.217      0.217      0.217             nan        nan        nan\n",
      " 0.199      0.199      0.199      0.194      0.194      0.194\n",
      " 0.188      0.188      0.188      0.203      0.203      0.203\n",
      "        nan        nan        nan 0.177      0.177      0.177\n",
      " 0.196      0.196      0.196      0.202      0.202      0.202\n",
      " 0.215      0.215      0.215             nan        nan        nan\n",
      " 0.189      0.189      0.189      0.199      0.199      0.199\n",
      " 0.201      0.201      0.201      0.206      0.206      0.206\n",
      "        nan        nan        nan 0.197      0.197      0.197\n",
      " 0.202      0.202      0.202      0.211      0.211      0.211\n",
      " 0.232      0.232      0.232             nan        nan        nan\n",
      " 0.181      0.181      0.181      0.191      0.191      0.191\n",
      " 0.199      0.199      0.199      0.222      0.222      0.222\n",
      "        nan        nan        nan 0.227      0.227      0.227\n",
      " 0.194      0.194      0.194      0.194      0.194      0.194\n",
      " 0.222      0.222      0.222             nan        nan        nan\n",
      " 0.227      0.227      0.227      0.194      0.194      0.194\n",
      " 0.194      0.194      0.194      0.203      0.203      0.203\n",
      "        nan        nan        nan 0.188      0.188      0.188\n",
      " 0.176      0.176      0.176      0.178      0.178      0.178\n",
      " 0.231      0.231      0.231             nan        nan        nan\n",
      " 0.164      0.164      0.164      0.206      0.206      0.206\n",
      " 0.178      0.178      0.178      0.218      0.218      0.218\n",
      "        nan        nan        nan 0.187      0.187      0.187\n",
      " 0.175      0.175      0.175      0.189      0.189      0.189\n",
      " 0.24       0.24       0.24              nan        nan        nan\n",
      " 0.252      0.252      0.252      0.19       0.211      0.218\n",
      " 0.205      0.205      0.205      0.232      0.232      0.232\n",
      "        nan        nan        nan 0.275      0.274      0.274\n",
      " 0.194      0.213      0.221      0.184      0.184      0.184\n",
      " 0.232      0.232      0.232             nan        nan        nan\n",
      " 0.275      0.274      0.274      0.194      0.213      0.221\n",
      " 0.184      0.184      0.184      0.2        0.2        0.2\n",
      "        nan        nan        nan 0.281      0.281      0.281\n",
      " 0.19       0.208      0.212      0.191      0.191      0.191\n",
      " 0.207      0.207      0.207             nan        nan        nan\n",
      " 0.28       0.281      0.281      0.18       0.206      0.213\n",
      " 0.172      0.172      0.172      0.207      0.207      0.207\n",
      "        nan        nan        nan 0.263      0.269      0.269\n",
      " 0.18       0.181      0.188      0.184      0.184      0.184\n",
      " 0.277      0.277      0.277             nan        nan        nan\n",
      " 0.246      0.246      0.246      0.172      0.173      0.171\n",
      " 0.25       0.25       0.25       0.259      0.259      0.259\n",
      "        nan        nan        nan 0.251      0.251      0.251\n",
      " 0.169      0.165      0.166      0.219      0.219      0.219\n",
      " 0.259      0.259      0.259             nan        nan        nan\n",
      " 0.251      0.251      0.251      0.169      0.165      0.166\n",
      " 0.219      0.219      0.219      0.185      0.185      0.185\n",
      "        nan        nan        nan 0.244      0.244      0.244\n",
      " 0.18       0.177      0.177      0.15       0.15       0.15\n",
      " 0.144      0.144      0.144             nan        nan        nan\n",
      " 0.249      0.249      0.249      0.179      0.176      0.177\n",
      " 0.146      0.146      0.146      0.093      0.093      0.093\n",
      "        nan        nan        nan 0.222      0.212      0.212\n",
      " 0.197      0.179      0.175      0.107      0.107      0.107\n",
      " 0.234      0.234      0.234             nan        nan        nan\n",
      " 0.251      0.251      0.251      0.131      0.132      0.132\n",
      " 0.216      0.216      0.216      0.115      0.115      0.115\n",
      "        nan        nan        nan 0.251      0.251      0.251\n",
      " 0.117      0.117      0.117      0.112      0.112      0.112\n",
      " 0.115      0.115      0.115             nan        nan        nan\n",
      " 0.251      0.251      0.251      0.117      0.117      0.117\n",
      " 0.112      0.112      0.112      0.116      0.116      0.116\n",
      "        nan        nan        nan 0.154      0.154      0.154\n",
      " 0.121      0.122      0.122      0.093      0.093      0.093\n",
      " 0.099      0.099      0.099             nan        nan        nan\n",
      " 0.108      0.108      0.108      0.123      0.123      0.122\n",
      " 0.093      0.093      0.093      0.111      0.111      0.111\n",
      "        nan        nan        nan 0.1        0.1        0.1\n",
      " 0.173      0.174      0.175      0.094      0.094      0.094\n",
      " 0.136      0.136      0.136      0.12133333 0.12133333 0.12133333\n",
      " 0.154      0.154      0.154      0.22333333 0.22333333 0.22333333\n",
      " 0.14933333 0.14933333 0.14866667 0.14866667 0.154      0.154\n",
      " 0.14866667 0.142      0.142      0.142      0.15533333 0.148\n",
      " 0.152      0.15466667 0.16533333 0.15466667 0.18266667 0.18266667\n",
      " 0.18266667 0.19333333 0.19333333 0.19333333 0.14933333 0.14866667\n",
      " 0.19533333 0.19533333 0.19533333 0.15       0.14933333 0.178\n",
      " 0.178      0.162      0.162      0.162      0.178      0.16866667\n",
      " 0.15533333 0.152      0.18466667 0.17666667 0.20866667 0.20866667\n",
      " 0.20866667 0.19       0.14733333 0.14733333 0.14733333 0.18066667\n",
      " 0.18066667 0.18066667 0.18066667 0.18066667 0.18066667 0.17733333\n",
      " 0.17733333 0.17733333 0.23066667 0.23066667 0.23066667 0.18533333\n",
      " 0.18533333 0.18533333 0.18533333 0.19       0.18533333 0.18533333\n",
      " 0.21066667 0.21066667 0.21066667 0.18133333 0.18133333 0.18133333\n",
      " 0.18066667 0.18066667 0.18066667 0.18133333 0.18133333 0.19533333\n",
      " 0.19533333 0.19533333 0.176      0.176      0.176      0.19266667\n",
      " 0.19266667 0.19266667 0.19266667 0.178      0.178      0.19266667\n",
      " 0.19266667 0.164      0.164      0.17266667 0.17266667 0.164\n",
      " 0.17266667 0.17266667 0.17266667 0.17266667 0.164      0.164\n",
      " 0.164      0.21066667 0.21066667 0.21066667 0.19666667 0.19666667\n",
      " 0.19666667 0.17466667 0.192      0.192      0.192      0.19133333\n",
      " 0.19133333 0.19333333 0.19333333 0.19133333 0.19133333 0.19133333\n",
      " 0.19133333 0.19333333 0.224      0.224      0.224      0.18066667\n",
      " 0.18066667 0.18066667 0.16533333 0.16533333 0.16533333 0.16533333\n",
      " 0.16533333 0.16533333 0.19533333 0.19533333 0.19533333 0.21\n",
      " 0.21       0.21       0.18666667 0.18666667 0.18666667 0.192\n",
      " 0.192      0.192      0.18466667 0.186      0.186      0.186\n",
      " 0.18466667 0.18466667 0.212      0.21266667 0.19       0.19\n",
      " 0.21266667 0.21266667 0.19       0.21533333 0.21133333 0.21133333\n",
      " 0.21133333 0.168      0.168      0.212      0.168      0.21933333\n",
      " 0.19866667 0.19866667 0.21266667 0.21266667 0.212      0.18533333\n",
      " 0.18533333 0.196      0.196      0.196      0.18533333 0.19266667\n",
      " 0.19266667 0.19266667 0.19866667 0.19866667 0.19866667 0.19866667\n",
      " 0.19866667 0.19866667 0.198      0.21733333 0.198      0.198\n",
      " 0.14533333 0.14533333 0.14533333 0.14533333 0.14533333 0.14533333\n",
      " 0.216      0.216      0.21933333 0.21933333 0.21933333 0.21933333\n",
      " 0.21933333 0.21933333 0.19866667 0.18466667 0.18466667 0.18466667\n",
      " 0.204      0.204      0.204      0.204      0.204      0.204\n",
      " 0.20666667 0.20666667 0.20666667 0.216      0.216      0.216\n",
      " 0.216      0.22266667 0.216      0.22266667 0.216      0.22266667\n",
      " 0.192      0.192      0.192      0.23333333 0.23333333 0.23333333\n",
      " 0.24333333 0.24333333 0.24333333 0.21933333 0.21933333 0.21933333\n",
      " 0.238      0.238      0.238      0.17       0.17       0.17\n",
      " 0.228      0.21266667 0.21266667 0.21266667 0.21266667 0.21266667\n",
      " 0.21266667 0.21333333 0.21333333 0.228      0.228      0.228\n",
      " 0.228      0.228      0.21333333 0.25       0.25       0.25\n",
      " 0.192      0.192      0.192      0.192      0.192      0.192\n",
      " 0.256      0.25466667 0.25466667 0.268      0.268      0.268\n",
      " 0.268      0.268      0.268      0.21333333 0.21333333 0.21333333\n",
      " 0.27466667 0.27666667 0.276      0.27666667 0.27666667 0.27666667]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525           nan        nan        nan\n",
      " 0.25725    0.25725    0.25725    0.2495     0.2495     0.2495\n",
      " 0.26075    0.26075    0.26075    0.26375    0.26375    0.26375\n",
      "        nan        nan        nan 0.2565     0.2565     0.2565\n",
      " 0.2315     0.2315     0.2315     0.2625     0.2625     0.2625\n",
      " 0.26375    0.26375    0.26375           nan        nan        nan\n",
      " 0.2565     0.2565     0.2565     0.2315     0.2315     0.2315\n",
      " 0.2625     0.2625     0.2625     0.2585     0.2585     0.2585\n",
      "        nan        nan        nan 0.2345     0.2345     0.2345\n",
      " 0.241      0.241      0.241      0.2335     0.2335     0.2335\n",
      " 0.26525    0.26525    0.26525           nan        nan        nan\n",
      " 0.24475    0.24475    0.24475    0.248      0.248      0.248\n",
      " 0.226      0.226      0.226      0.2505     0.2505     0.2505\n",
      "        nan        nan        nan 0.23825    0.23825    0.23825\n",
      " 0.247      0.247      0.247      0.2305     0.2305     0.2305\n",
      " 0.28125    0.28125    0.28125           nan        nan        nan\n",
      " 0.24125    0.24125    0.24125    0.21525    0.21525    0.21525\n",
      " 0.24175    0.24175    0.24175    0.2795     0.2795     0.2795\n",
      "        nan        nan        nan 0.27125    0.27125    0.27125\n",
      " 0.2385     0.2385     0.2385     0.24575    0.24575    0.24575\n",
      " 0.2795     0.2795     0.2795            nan        nan        nan\n",
      " 0.27125    0.27125    0.27125    0.2385     0.2385     0.2385\n",
      " 0.24575    0.24575    0.24575    0.265      0.265      0.265\n",
      "        nan        nan        nan 0.2385     0.2385     0.2385\n",
      " 0.217      0.217      0.217      0.21925    0.21925    0.21925\n",
      " 0.2885     0.2885     0.2885            nan        nan        nan\n",
      " 0.23675    0.23675    0.23675    0.23       0.23       0.23\n",
      " 0.2185     0.2185     0.2185     0.26775    0.26775    0.26775\n",
      "        nan        nan        nan 0.2305     0.2305     0.2305\n",
      " 0.231      0.231      0.231      0.227      0.227      0.227\n",
      " 0.32075    0.32075    0.32075           nan        nan        nan\n",
      " 0.33       0.33       0.33       0.23275    0.2785     0.28825\n",
      " 0.26625    0.26625    0.26625    0.286      0.286      0.286\n",
      "        nan        nan        nan 0.3535     0.35325    0.35325\n",
      " 0.23275    0.2805     0.28975    0.235      0.235      0.235\n",
      " 0.286      0.286      0.286             nan        nan        nan\n",
      " 0.3535     0.35325    0.35325    0.23275    0.2805     0.28975\n",
      " 0.235      0.235      0.235      0.27125    0.27125    0.27125\n",
      "        nan        nan        nan 0.35725    0.3575     0.3575\n",
      " 0.22075    0.2735     0.28225    0.2465     0.2465     0.2465\n",
      " 0.25475    0.25475    0.25475           nan        nan        nan\n",
      " 0.35025    0.35125    0.35125    0.2195     0.26525    0.27775\n",
      " 0.21175    0.21175    0.21175    0.264      0.264      0.264\n",
      "        nan        nan        nan 0.33425    0.34225    0.34225\n",
      " 0.212      0.229      0.24725    0.1965     0.1965     0.1965\n",
      " 0.3285     0.3285     0.3285            nan        nan        nan\n",
      " 0.3095     0.3095     0.3095     0.20875    0.20475    0.2025\n",
      " 0.30225    0.30225    0.30225    0.26925    0.26925    0.26925\n",
      "        nan        nan        nan 0.30875    0.30875    0.30875\n",
      " 0.20425    0.20225    0.202      0.24325    0.24325    0.24325\n",
      " 0.26925    0.26925    0.26925           nan        nan        nan\n",
      " 0.30875    0.30875    0.30875    0.20425    0.20225    0.202\n",
      " 0.24325    0.24325    0.24325    0.2015     0.2015     0.2015\n",
      "        nan        nan        nan 0.294      0.294      0.294\n",
      " 0.213      0.2075     0.207      0.1595     0.1595     0.1595\n",
      " 0.15125    0.15125    0.15125           nan        nan        nan\n",
      " 0.28475    0.28475    0.28475    0.2145     0.20975    0.20975\n",
      " 0.1245     0.1245     0.1245     0.11725    0.11725    0.11725\n",
      "        nan        nan        nan 0.22725    0.2225     0.2225\n",
      " 0.24075    0.223      0.2205     0.1085     0.1085     0.1085\n",
      " 0.27275    0.27275    0.27275           nan        nan        nan\n",
      " 0.2955     0.2955     0.2955     0.12575    0.12625    0.12675\n",
      " 0.249      0.249      0.249      0.127      0.127      0.127\n",
      "        nan        nan        nan 0.2505     0.2505     0.2505\n",
      " 0.112      0.112      0.11225    0.13875    0.13875    0.13875\n",
      " 0.127      0.127      0.127             nan        nan        nan\n",
      " 0.2505     0.2505     0.2505     0.112      0.112      0.11225\n",
      " 0.13875    0.13875    0.13875    0.108      0.108      0.108\n",
      "        nan        nan        nan 0.20325    0.20325    0.20325\n",
      " 0.12       0.12       0.12       0.107      0.107      0.107\n",
      " 0.1025     0.1025     0.1025            nan        nan        nan\n",
      " 0.133      0.133      0.133      0.1215     0.1215     0.1215\n",
      " 0.107      0.107      0.107      0.1015     0.1015     0.1015\n",
      "        nan        nan        nan 0.10875    0.10875    0.10875\n",
      " 0.1805     0.17825    0.1795     0.10275    0.10275    0.10275\n",
      " 0.13816667 0.13816667 0.13816667 0.14333333 0.14333333 0.14333333\n",
      " 0.177      0.177      0.177      0.26416667 0.26416667 0.26416667\n",
      " 0.17033333 0.17033333 0.16933333 0.16933333 0.17466667 0.17466667\n",
      " 0.17       0.16266667 0.16266667 0.16266667 0.17533333 0.17183333\n",
      " 0.17233333 0.168      0.18933333 0.16783333 0.21283333 0.21283333\n",
      " 0.21283333 0.21783333 0.21783333 0.21783333 0.17183333 0.17183333\n",
      " 0.2275     0.2275     0.2275     0.17183333 0.17216667 0.21283333\n",
      " 0.21283333 0.19383333 0.19383333 0.19383333 0.21283333 0.1925\n",
      " 0.176      0.17683333 0.21883333 0.20266667 0.23516667 0.23516667\n",
      " 0.23516667 0.218      0.18533333 0.18533333 0.18533333 0.2295\n",
      " 0.2295     0.2295     0.2295     0.2295     0.2295     0.18283333\n",
      " 0.18283333 0.18283333 0.25616667 0.25616667 0.25616667 0.2175\n",
      " 0.2175     0.2175     0.2175     0.22733333 0.2175     0.2175\n",
      " 0.24933333 0.24933333 0.24933333 0.21483333 0.21483333 0.21483333\n",
      " 0.21883333 0.21883333 0.21883333 0.2265     0.21766667 0.213\n",
      " 0.213      0.213      0.211      0.211      0.211      0.22616667\n",
      " 0.22616667 0.22616667 0.22616667 0.22583333 0.22583333 0.22616667\n",
      " 0.22616667 0.19083333 0.19083333 0.22016667 0.22016667 0.19083333\n",
      " 0.22016667 0.22016667 0.22016667 0.22016667 0.19083333 0.19083333\n",
      " 0.19083333 0.22983333 0.22983333 0.22983333 0.2155     0.2155\n",
      " 0.2155     0.2025     0.23383333 0.23383333 0.23383333 0.22816667\n",
      " 0.22816667 0.2335     0.2335     0.22816667 0.22816667 0.22816667\n",
      " 0.22816667 0.2335     0.27183333 0.27183333 0.27183333 0.21283333\n",
      " 0.21283333 0.21283333 0.18983333 0.21933333 0.18983333 0.18983333\n",
      " 0.21933333 0.21933333 0.24683333 0.24683333 0.24683333 0.24216667\n",
      " 0.24216667 0.24216667 0.22583333 0.22583333 0.22583333 0.23766667\n",
      " 0.23766667 0.23766667 0.19616667 0.22016667 0.22016667 0.22016667\n",
      " 0.19616667 0.19616667 0.25716667 0.25016667 0.2205     0.2205\n",
      " 0.25016667 0.25016667 0.2205     0.263      0.2425     0.2425\n",
      " 0.2425     0.2075     0.2075     0.26916667 0.2075     0.2705\n",
      " 0.21183333 0.21183333 0.26633333 0.26633333 0.26416667 0.21666667\n",
      " 0.21666667 0.23883333 0.23883333 0.23883333 0.21666667 0.217\n",
      " 0.217      0.217      0.22433333 0.22433333 0.22433333 0.22433333\n",
      " 0.22433333 0.22433333 0.24216667 0.2815     0.24216667 0.24216667\n",
      " 0.16883333 0.16883333 0.16883333 0.16883333 0.16883333 0.16883333\n",
      " 0.2745     0.2745     0.2605     0.2605     0.2605     0.2605\n",
      " 0.2605     0.2605     0.21183333 0.2145     0.2145     0.2145\n",
      " 0.25216667 0.25216667 0.25216667 0.25216667 0.25216667 0.25216667\n",
      " 0.251      0.251      0.251      0.26366667 0.26366667 0.26366667\n",
      " 0.26366667 0.25466667 0.26366667 0.25466667 0.26366667 0.25466667\n",
      " 0.233      0.233      0.233      0.29183333 0.29183333 0.29183333\n",
      " 0.275      0.275      0.275      0.28066667 0.28066667 0.28066667\n",
      " 0.26533333 0.26533333 0.26533333 0.209      0.209      0.209\n",
      " 0.283      0.22366667 0.22366667 0.22366667 0.22366667 0.22366667\n",
      " 0.22366667 0.24533333 0.24533333 0.283      0.283      0.283\n",
      " 0.283      0.283      0.24533333 0.31066667 0.31066667 0.31066667\n",
      " 0.2125     0.2125     0.2125     0.2125     0.2125     0.2125\n",
      " 0.321      0.3235     0.3235     0.33733333 0.33733333 0.33733333\n",
      " 0.33733333 0.33733333 0.33733333 0.26783333 0.26783333 0.26783333\n",
      " 0.34083333 0.342      0.34033333 0.34216667 0.34216667 0.342     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 2\n",
      "n_candidates: 200\n",
      "n_resources: 2250\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   3.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  12.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   5.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   3.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   7.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   6.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  10.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   5.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  19.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   9.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   5.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   8.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  14.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  34.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  24.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   3.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  33.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  10.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  18.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   5.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   6.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203             nan        nan        nan\n",
      " 0.21       0.21       0.21       0.215      0.215      0.215\n",
      " 0.224      0.224      0.224      0.217      0.217      0.217\n",
      "        nan        nan        nan 0.199      0.199      0.199\n",
      " 0.194      0.194      0.194      0.188      0.188      0.188\n",
      " 0.217      0.217      0.217             nan        nan        nan\n",
      " 0.199      0.199      0.199      0.194      0.194      0.194\n",
      " 0.188      0.188      0.188      0.203      0.203      0.203\n",
      "        nan        nan        nan 0.177      0.177      0.177\n",
      " 0.196      0.196      0.196      0.202      0.202      0.202\n",
      " 0.215      0.215      0.215             nan        nan        nan\n",
      " 0.189      0.189      0.189      0.199      0.199      0.199\n",
      " 0.201      0.201      0.201      0.206      0.206      0.206\n",
      "        nan        nan        nan 0.197      0.197      0.197\n",
      " 0.202      0.202      0.202      0.211      0.211      0.211\n",
      " 0.232      0.232      0.232             nan        nan        nan\n",
      " 0.181      0.181      0.181      0.191      0.191      0.191\n",
      " 0.199      0.199      0.199      0.222      0.222      0.222\n",
      "        nan        nan        nan 0.227      0.227      0.227\n",
      " 0.194      0.194      0.194      0.194      0.194      0.194\n",
      " 0.222      0.222      0.222             nan        nan        nan\n",
      " 0.227      0.227      0.227      0.194      0.194      0.194\n",
      " 0.194      0.194      0.194      0.203      0.203      0.203\n",
      "        nan        nan        nan 0.188      0.188      0.188\n",
      " 0.176      0.176      0.176      0.178      0.178      0.178\n",
      " 0.231      0.231      0.231             nan        nan        nan\n",
      " 0.164      0.164      0.164      0.206      0.206      0.206\n",
      " 0.178      0.178      0.178      0.218      0.218      0.218\n",
      "        nan        nan        nan 0.187      0.187      0.187\n",
      " 0.175      0.175      0.175      0.189      0.189      0.189\n",
      " 0.24       0.24       0.24              nan        nan        nan\n",
      " 0.252      0.252      0.252      0.19       0.211      0.218\n",
      " 0.205      0.205      0.205      0.232      0.232      0.232\n",
      "        nan        nan        nan 0.275      0.274      0.274\n",
      " 0.194      0.213      0.221      0.184      0.184      0.184\n",
      " 0.232      0.232      0.232             nan        nan        nan\n",
      " 0.275      0.274      0.274      0.194      0.213      0.221\n",
      " 0.184      0.184      0.184      0.2        0.2        0.2\n",
      "        nan        nan        nan 0.281      0.281      0.281\n",
      " 0.19       0.208      0.212      0.191      0.191      0.191\n",
      " 0.207      0.207      0.207             nan        nan        nan\n",
      " 0.28       0.281      0.281      0.18       0.206      0.213\n",
      " 0.172      0.172      0.172      0.207      0.207      0.207\n",
      "        nan        nan        nan 0.263      0.269      0.269\n",
      " 0.18       0.181      0.188      0.184      0.184      0.184\n",
      " 0.277      0.277      0.277             nan        nan        nan\n",
      " 0.246      0.246      0.246      0.172      0.173      0.171\n",
      " 0.25       0.25       0.25       0.259      0.259      0.259\n",
      "        nan        nan        nan 0.251      0.251      0.251\n",
      " 0.169      0.165      0.166      0.219      0.219      0.219\n",
      " 0.259      0.259      0.259             nan        nan        nan\n",
      " 0.251      0.251      0.251      0.169      0.165      0.166\n",
      " 0.219      0.219      0.219      0.185      0.185      0.185\n",
      "        nan        nan        nan 0.244      0.244      0.244\n",
      " 0.18       0.177      0.177      0.15       0.15       0.15\n",
      " 0.144      0.144      0.144             nan        nan        nan\n",
      " 0.249      0.249      0.249      0.179      0.176      0.177\n",
      " 0.146      0.146      0.146      0.093      0.093      0.093\n",
      "        nan        nan        nan 0.222      0.212      0.212\n",
      " 0.197      0.179      0.175      0.107      0.107      0.107\n",
      " 0.234      0.234      0.234             nan        nan        nan\n",
      " 0.251      0.251      0.251      0.131      0.132      0.132\n",
      " 0.216      0.216      0.216      0.115      0.115      0.115\n",
      "        nan        nan        nan 0.251      0.251      0.251\n",
      " 0.117      0.117      0.117      0.112      0.112      0.112\n",
      " 0.115      0.115      0.115             nan        nan        nan\n",
      " 0.251      0.251      0.251      0.117      0.117      0.117\n",
      " 0.112      0.112      0.112      0.116      0.116      0.116\n",
      "        nan        nan        nan 0.154      0.154      0.154\n",
      " 0.121      0.122      0.122      0.093      0.093      0.093\n",
      " 0.099      0.099      0.099             nan        nan        nan\n",
      " 0.108      0.108      0.108      0.123      0.123      0.122\n",
      " 0.093      0.093      0.093      0.111      0.111      0.111\n",
      "        nan        nan        nan 0.1        0.1        0.1\n",
      " 0.173      0.174      0.175      0.094      0.094      0.094\n",
      " 0.136      0.136      0.136      0.12133333 0.12133333 0.12133333\n",
      " 0.154      0.154      0.154      0.22333333 0.22333333 0.22333333\n",
      " 0.14933333 0.14933333 0.14866667 0.14866667 0.154      0.154\n",
      " 0.14866667 0.142      0.142      0.142      0.15533333 0.148\n",
      " 0.152      0.15466667 0.16533333 0.15466667 0.18266667 0.18266667\n",
      " 0.18266667 0.19333333 0.19333333 0.19333333 0.14933333 0.14866667\n",
      " 0.19533333 0.19533333 0.19533333 0.15       0.14933333 0.178\n",
      " 0.178      0.162      0.162      0.162      0.178      0.16866667\n",
      " 0.15533333 0.152      0.18466667 0.17666667 0.20866667 0.20866667\n",
      " 0.20866667 0.19       0.14733333 0.14733333 0.14733333 0.18066667\n",
      " 0.18066667 0.18066667 0.18066667 0.18066667 0.18066667 0.17733333\n",
      " 0.17733333 0.17733333 0.23066667 0.23066667 0.23066667 0.18533333\n",
      " 0.18533333 0.18533333 0.18533333 0.19       0.18533333 0.18533333\n",
      " 0.21066667 0.21066667 0.21066667 0.18133333 0.18133333 0.18133333\n",
      " 0.18066667 0.18066667 0.18066667 0.18133333 0.18133333 0.19533333\n",
      " 0.19533333 0.19533333 0.176      0.176      0.176      0.19266667\n",
      " 0.19266667 0.19266667 0.19266667 0.178      0.178      0.19266667\n",
      " 0.19266667 0.164      0.164      0.17266667 0.17266667 0.164\n",
      " 0.17266667 0.17266667 0.17266667 0.17266667 0.164      0.164\n",
      " 0.164      0.21066667 0.21066667 0.21066667 0.19666667 0.19666667\n",
      " 0.19666667 0.17466667 0.192      0.192      0.192      0.19133333\n",
      " 0.19133333 0.19333333 0.19333333 0.19133333 0.19133333 0.19133333\n",
      " 0.19133333 0.19333333 0.224      0.224      0.224      0.18066667\n",
      " 0.18066667 0.18066667 0.16533333 0.16533333 0.16533333 0.16533333\n",
      " 0.16533333 0.16533333 0.19533333 0.19533333 0.19533333 0.21\n",
      " 0.21       0.21       0.18666667 0.18666667 0.18666667 0.192\n",
      " 0.192      0.192      0.18466667 0.186      0.186      0.186\n",
      " 0.18466667 0.18466667 0.212      0.21266667 0.19       0.19\n",
      " 0.21266667 0.21266667 0.19       0.21533333 0.21133333 0.21133333\n",
      " 0.21133333 0.168      0.168      0.212      0.168      0.21933333\n",
      " 0.19866667 0.19866667 0.21266667 0.21266667 0.212      0.18533333\n",
      " 0.18533333 0.196      0.196      0.196      0.18533333 0.19266667\n",
      " 0.19266667 0.19266667 0.19866667 0.19866667 0.19866667 0.19866667\n",
      " 0.19866667 0.19866667 0.198      0.21733333 0.198      0.198\n",
      " 0.14533333 0.14533333 0.14533333 0.14533333 0.14533333 0.14533333\n",
      " 0.216      0.216      0.21933333 0.21933333 0.21933333 0.21933333\n",
      " 0.21933333 0.21933333 0.19866667 0.18466667 0.18466667 0.18466667\n",
      " 0.204      0.204      0.204      0.204      0.204      0.204\n",
      " 0.20666667 0.20666667 0.20666667 0.216      0.216      0.216\n",
      " 0.216      0.22266667 0.216      0.22266667 0.216      0.22266667\n",
      " 0.192      0.192      0.192      0.23333333 0.23333333 0.23333333\n",
      " 0.24333333 0.24333333 0.24333333 0.21933333 0.21933333 0.21933333\n",
      " 0.238      0.238      0.238      0.17       0.17       0.17\n",
      " 0.228      0.21266667 0.21266667 0.21266667 0.21266667 0.21266667\n",
      " 0.21266667 0.21333333 0.21333333 0.228      0.228      0.228\n",
      " 0.228      0.228      0.21333333 0.25       0.25       0.25\n",
      " 0.192      0.192      0.192      0.192      0.192      0.192\n",
      " 0.256      0.25466667 0.25466667 0.268      0.268      0.268\n",
      " 0.268      0.268      0.268      0.21333333 0.21333333 0.21333333\n",
      " 0.27466667 0.27666667 0.276      0.27666667 0.27666667 0.27666667\n",
      " 0.24988864 0.21291759 0.21291759 0.20801782 0.21291759 0.23073497\n",
      " 0.23073497 0.23073497 0.20311804 0.20311804 0.20311804 0.20579065\n",
      " 0.20579065 0.20579065 0.20311804 0.20311804 0.20311804 0.20222717\n",
      " 0.20222717 0.20222717 0.2013363  0.2013363  0.2013363  0.20935412\n",
      " 0.20935412 0.20935412 0.21826281 0.21247216 0.20089087 0.20089087\n",
      " 0.20089087 0.20089087 0.20089087 0.20089087 0.22806236 0.22806236\n",
      " 0.22806236 0.21915367 0.20534521 0.22806236 0.20534521 0.21915367\n",
      " 0.20534521 0.22806236 0.21915367 0.20534521 0.20534521 0.22806236\n",
      " 0.20534521 0.19910913 0.19910913 0.19910913 0.19910913 0.19910913\n",
      " 0.19910913 0.17906459 0.17906459 0.17906459 0.23028953 0.23028953\n",
      " 0.23028953 0.19109131 0.19109131 0.19109131 0.18173719 0.18173719\n",
      " 0.18173719 0.21781737 0.21781737 0.24142539 0.24142539 0.21781737\n",
      " 0.24142539 0.22360802 0.22360802 0.22360802 0.20089087 0.20089087\n",
      " 0.20089087 0.17639198 0.17639198 0.17639198 0.20890869 0.20890869\n",
      " 0.20890869 0.20979955 0.20979955 0.20979955 0.20979955 0.20979955\n",
      " 0.20979955 0.23875278 0.23875278 0.23875278 0.23875278 0.23875278\n",
      " 0.23875278 0.21069042 0.21069042 0.21069042 0.21781737 0.21781737\n",
      " 0.21781737 0.20400891 0.20400891 0.20400891 0.25300668 0.18975501\n",
      " 0.18975501 0.18975501 0.25300668 0.25300668 0.20356347 0.20356347\n",
      " 0.20356347 0.23563474 0.25924276 0.22761693 0.26325167 0.26325167\n",
      " 0.24855234 0.24855234 0.26325167 0.26325167 0.26325167 0.26325167\n",
      " 0.23207127 0.23207127 0.23207127 0.26325167 0.22449889 0.22449889\n",
      " 0.22449889 0.26325167 0.26325167 0.24187082 0.2481069  0.21826281\n",
      " 0.21826281 0.21826281 0.21826281 0.21826281 0.21826281 0.2481069\n",
      " 0.2636971  0.25345212 0.25345212 0.25345212 0.20534521 0.20534521\n",
      " 0.20534521 0.20534521 0.20534521 0.20534521 0.2481069  0.22583519\n",
      " 0.22583519 0.22583519 0.22048998 0.22048998 0.22048998 0.21113586\n",
      " 0.21113586 0.21113586 0.26636971 0.26636971 0.26636971 0.26636971\n",
      " 0.26636971 0.26636971 0.23385301 0.23385301 0.23385301 0.21826281\n",
      " 0.21826281 0.21826281 0.27082405 0.27082405 0.27082405 0.27171492\n",
      " 0.27171492 0.27171492 0.28685969 0.28685969 0.28685969 0.28463252\n",
      " 0.28463252 0.27884187 0.28285078 0.28285078 0.28285078 0.28285078\n",
      " 0.28285078 0.28285078 0.29443207 0.28685969 0.28685969 0.29443207\n",
      " 0.28685969 0.29443207]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525           nan        nan        nan\n",
      " 0.25725    0.25725    0.25725    0.2495     0.2495     0.2495\n",
      " 0.26075    0.26075    0.26075    0.26375    0.26375    0.26375\n",
      "        nan        nan        nan 0.2565     0.2565     0.2565\n",
      " 0.2315     0.2315     0.2315     0.2625     0.2625     0.2625\n",
      " 0.26375    0.26375    0.26375           nan        nan        nan\n",
      " 0.2565     0.2565     0.2565     0.2315     0.2315     0.2315\n",
      " 0.2625     0.2625     0.2625     0.2585     0.2585     0.2585\n",
      "        nan        nan        nan 0.2345     0.2345     0.2345\n",
      " 0.241      0.241      0.241      0.2335     0.2335     0.2335\n",
      " 0.26525    0.26525    0.26525           nan        nan        nan\n",
      " 0.24475    0.24475    0.24475    0.248      0.248      0.248\n",
      " 0.226      0.226      0.226      0.2505     0.2505     0.2505\n",
      "        nan        nan        nan 0.23825    0.23825    0.23825\n",
      " 0.247      0.247      0.247      0.2305     0.2305     0.2305\n",
      " 0.28125    0.28125    0.28125           nan        nan        nan\n",
      " 0.24125    0.24125    0.24125    0.21525    0.21525    0.21525\n",
      " 0.24175    0.24175    0.24175    0.2795     0.2795     0.2795\n",
      "        nan        nan        nan 0.27125    0.27125    0.27125\n",
      " 0.2385     0.2385     0.2385     0.24575    0.24575    0.24575\n",
      " 0.2795     0.2795     0.2795            nan        nan        nan\n",
      " 0.27125    0.27125    0.27125    0.2385     0.2385     0.2385\n",
      " 0.24575    0.24575    0.24575    0.265      0.265      0.265\n",
      "        nan        nan        nan 0.2385     0.2385     0.2385\n",
      " 0.217      0.217      0.217      0.21925    0.21925    0.21925\n",
      " 0.2885     0.2885     0.2885            nan        nan        nan\n",
      " 0.23675    0.23675    0.23675    0.23       0.23       0.23\n",
      " 0.2185     0.2185     0.2185     0.26775    0.26775    0.26775\n",
      "        nan        nan        nan 0.2305     0.2305     0.2305\n",
      " 0.231      0.231      0.231      0.227      0.227      0.227\n",
      " 0.32075    0.32075    0.32075           nan        nan        nan\n",
      " 0.33       0.33       0.33       0.23275    0.2785     0.28825\n",
      " 0.26625    0.26625    0.26625    0.286      0.286      0.286\n",
      "        nan        nan        nan 0.3535     0.35325    0.35325\n",
      " 0.23275    0.2805     0.28975    0.235      0.235      0.235\n",
      " 0.286      0.286      0.286             nan        nan        nan\n",
      " 0.3535     0.35325    0.35325    0.23275    0.2805     0.28975\n",
      " 0.235      0.235      0.235      0.27125    0.27125    0.27125\n",
      "        nan        nan        nan 0.35725    0.3575     0.3575\n",
      " 0.22075    0.2735     0.28225    0.2465     0.2465     0.2465\n",
      " 0.25475    0.25475    0.25475           nan        nan        nan\n",
      " 0.35025    0.35125    0.35125    0.2195     0.26525    0.27775\n",
      " 0.21175    0.21175    0.21175    0.264      0.264      0.264\n",
      "        nan        nan        nan 0.33425    0.34225    0.34225\n",
      " 0.212      0.229      0.24725    0.1965     0.1965     0.1965\n",
      " 0.3285     0.3285     0.3285            nan        nan        nan\n",
      " 0.3095     0.3095     0.3095     0.20875    0.20475    0.2025\n",
      " 0.30225    0.30225    0.30225    0.26925    0.26925    0.26925\n",
      "        nan        nan        nan 0.30875    0.30875    0.30875\n",
      " 0.20425    0.20225    0.202      0.24325    0.24325    0.24325\n",
      " 0.26925    0.26925    0.26925           nan        nan        nan\n",
      " 0.30875    0.30875    0.30875    0.20425    0.20225    0.202\n",
      " 0.24325    0.24325    0.24325    0.2015     0.2015     0.2015\n",
      "        nan        nan        nan 0.294      0.294      0.294\n",
      " 0.213      0.2075     0.207      0.1595     0.1595     0.1595\n",
      " 0.15125    0.15125    0.15125           nan        nan        nan\n",
      " 0.28475    0.28475    0.28475    0.2145     0.20975    0.20975\n",
      " 0.1245     0.1245     0.1245     0.11725    0.11725    0.11725\n",
      "        nan        nan        nan 0.22725    0.2225     0.2225\n",
      " 0.24075    0.223      0.2205     0.1085     0.1085     0.1085\n",
      " 0.27275    0.27275    0.27275           nan        nan        nan\n",
      " 0.2955     0.2955     0.2955     0.12575    0.12625    0.12675\n",
      " 0.249      0.249      0.249      0.127      0.127      0.127\n",
      "        nan        nan        nan 0.2505     0.2505     0.2505\n",
      " 0.112      0.112      0.11225    0.13875    0.13875    0.13875\n",
      " 0.127      0.127      0.127             nan        nan        nan\n",
      " 0.2505     0.2505     0.2505     0.112      0.112      0.11225\n",
      " 0.13875    0.13875    0.13875    0.108      0.108      0.108\n",
      "        nan        nan        nan 0.20325    0.20325    0.20325\n",
      " 0.12       0.12       0.12       0.107      0.107      0.107\n",
      " 0.1025     0.1025     0.1025            nan        nan        nan\n",
      " 0.133      0.133      0.133      0.1215     0.1215     0.1215\n",
      " 0.107      0.107      0.107      0.1015     0.1015     0.1015\n",
      "        nan        nan        nan 0.10875    0.10875    0.10875\n",
      " 0.1805     0.17825    0.1795     0.10275    0.10275    0.10275\n",
      " 0.13816667 0.13816667 0.13816667 0.14333333 0.14333333 0.14333333\n",
      " 0.177      0.177      0.177      0.26416667 0.26416667 0.26416667\n",
      " 0.17033333 0.17033333 0.16933333 0.16933333 0.17466667 0.17466667\n",
      " 0.17       0.16266667 0.16266667 0.16266667 0.17533333 0.17183333\n",
      " 0.17233333 0.168      0.18933333 0.16783333 0.21283333 0.21283333\n",
      " 0.21283333 0.21783333 0.21783333 0.21783333 0.17183333 0.17183333\n",
      " 0.2275     0.2275     0.2275     0.17183333 0.17216667 0.21283333\n",
      " 0.21283333 0.19383333 0.19383333 0.19383333 0.21283333 0.1925\n",
      " 0.176      0.17683333 0.21883333 0.20266667 0.23516667 0.23516667\n",
      " 0.23516667 0.218      0.18533333 0.18533333 0.18533333 0.2295\n",
      " 0.2295     0.2295     0.2295     0.2295     0.2295     0.18283333\n",
      " 0.18283333 0.18283333 0.25616667 0.25616667 0.25616667 0.2175\n",
      " 0.2175     0.2175     0.2175     0.22733333 0.2175     0.2175\n",
      " 0.24933333 0.24933333 0.24933333 0.21483333 0.21483333 0.21483333\n",
      " 0.21883333 0.21883333 0.21883333 0.2265     0.21766667 0.213\n",
      " 0.213      0.213      0.211      0.211      0.211      0.22616667\n",
      " 0.22616667 0.22616667 0.22616667 0.22583333 0.22583333 0.22616667\n",
      " 0.22616667 0.19083333 0.19083333 0.22016667 0.22016667 0.19083333\n",
      " 0.22016667 0.22016667 0.22016667 0.22016667 0.19083333 0.19083333\n",
      " 0.19083333 0.22983333 0.22983333 0.22983333 0.2155     0.2155\n",
      " 0.2155     0.2025     0.23383333 0.23383333 0.23383333 0.22816667\n",
      " 0.22816667 0.2335     0.2335     0.22816667 0.22816667 0.22816667\n",
      " 0.22816667 0.2335     0.27183333 0.27183333 0.27183333 0.21283333\n",
      " 0.21283333 0.21283333 0.18983333 0.21933333 0.18983333 0.18983333\n",
      " 0.21933333 0.21933333 0.24683333 0.24683333 0.24683333 0.24216667\n",
      " 0.24216667 0.24216667 0.22583333 0.22583333 0.22583333 0.23766667\n",
      " 0.23766667 0.23766667 0.19616667 0.22016667 0.22016667 0.22016667\n",
      " 0.19616667 0.19616667 0.25716667 0.25016667 0.2205     0.2205\n",
      " 0.25016667 0.25016667 0.2205     0.263      0.2425     0.2425\n",
      " 0.2425     0.2075     0.2075     0.26916667 0.2075     0.2705\n",
      " 0.21183333 0.21183333 0.26633333 0.26633333 0.26416667 0.21666667\n",
      " 0.21666667 0.23883333 0.23883333 0.23883333 0.21666667 0.217\n",
      " 0.217      0.217      0.22433333 0.22433333 0.22433333 0.22433333\n",
      " 0.22433333 0.22433333 0.24216667 0.2815     0.24216667 0.24216667\n",
      " 0.16883333 0.16883333 0.16883333 0.16883333 0.16883333 0.16883333\n",
      " 0.2745     0.2745     0.2605     0.2605     0.2605     0.2605\n",
      " 0.2605     0.2605     0.21183333 0.2145     0.2145     0.2145\n",
      " 0.25216667 0.25216667 0.25216667 0.25216667 0.25216667 0.25216667\n",
      " 0.251      0.251      0.251      0.26366667 0.26366667 0.26366667\n",
      " 0.26366667 0.25466667 0.26366667 0.25466667 0.26366667 0.25466667\n",
      " 0.233      0.233      0.233      0.29183333 0.29183333 0.29183333\n",
      " 0.275      0.275      0.275      0.28066667 0.28066667 0.28066667\n",
      " 0.26533333 0.26533333 0.26533333 0.209      0.209      0.209\n",
      " 0.283      0.22366667 0.22366667 0.22366667 0.22366667 0.22366667\n",
      " 0.22366667 0.24533333 0.24533333 0.283      0.283      0.283\n",
      " 0.283      0.283      0.24533333 0.31066667 0.31066667 0.31066667\n",
      " 0.2125     0.2125     0.2125     0.2125     0.2125     0.2125\n",
      " 0.321      0.3235     0.3235     0.33733333 0.33733333 0.33733333\n",
      " 0.33733333 0.33733333 0.33733333 0.26783333 0.26783333 0.26783333\n",
      " 0.34083333 0.342      0.34033333 0.34216667 0.34216667 0.342\n",
      " 0.27026126 0.23413007 0.23413007 0.24313508 0.23413007 0.26781545\n",
      " 0.26781545 0.26781545 0.22323513 0.22323513 0.22323513 0.2311284\n",
      " 0.2311284  0.2311284  0.22323513 0.22323513 0.22323513 0.22568093\n",
      " 0.22568093 0.22568093 0.22657032 0.22657032 0.22657032 0.22534742\n",
      " 0.22534742 0.22534742 0.25013897 0.24535853 0.20478043 0.20478043\n",
      " 0.20478043 0.20478043 0.20478043 0.20478043 0.24035575 0.24035575\n",
      " 0.24035575 0.24602557 0.22679266 0.24035575 0.21812118 0.24602557\n",
      " 0.21812118 0.24035575 0.24602557 0.22679266 0.22679266 0.24035575\n",
      " 0.21812118 0.23079489 0.23079489 0.23079489 0.23079489 0.23079489\n",
      " 0.23079489 0.19566426 0.19566426 0.19566426 0.25714286 0.25714286\n",
      " 0.25714286 0.21256253 0.21256253 0.21256253 0.20188994 0.20188994\n",
      " 0.20188994 0.24880489 0.24880489 0.24624792 0.24624792 0.24880489\n",
      " 0.24624792 0.23357421 0.23357421 0.23357421 0.21934408 0.21934408\n",
      " 0.21934408 0.21823235 0.21823235 0.21823235 0.22223457 0.22223457\n",
      " 0.22223457 0.23957754 0.23957754 0.23957754 0.23957754 0.23957754\n",
      " 0.23957754 0.25558644 0.25558644 0.25558644 0.25558644 0.25558644\n",
      " 0.25558644 0.23101723 0.23101723 0.23101723 0.241801   0.241801\n",
      " 0.241801   0.21912173 0.21912173 0.21912173 0.27092829 0.22523624\n",
      " 0.22523624 0.22523624 0.27092829 0.27092829 0.22568093 0.22568093\n",
      " 0.22568093 0.27737632 0.29527515 0.26659255 0.26748193 0.26748193\n",
      " 0.29105058 0.29105058 0.26748193 0.26748193 0.26748193 0.26748193\n",
      " 0.24369094 0.24369094 0.24369094 0.28549194 0.26203446 0.26203446\n",
      " 0.26203446 0.28549194 0.28549194 0.27815453 0.29560867 0.2459144\n",
      " 0.2459144  0.2459144  0.2459144  0.2459144  0.2459144  0.29560867\n",
      " 0.29994441 0.30950528 0.30950528 0.30950528 0.2340189  0.2340189\n",
      " 0.2340189  0.2340189  0.2340189  0.2340189  0.28715953 0.25325181\n",
      " 0.25325181 0.25325181 0.24991662 0.24991662 0.24991662 0.23590884\n",
      " 0.23590884 0.23590884 0.30494719 0.30494719 0.30494719 0.30494719\n",
      " 0.30494719 0.30494719 0.26247916 0.26247916 0.26247916 0.25591996\n",
      " 0.25591996 0.25591996 0.28993885 0.28993885 0.28993885 0.29327404\n",
      " 0.29327404 0.29327404 0.33018344 0.33018344 0.33018344 0.32562535\n",
      " 0.32562535 0.3200667  0.32462479 0.32462479 0.32462479 0.32462479\n",
      " 0.32462479 0.32462479 0.33985548 0.33229572 0.33229572 0.33985548\n",
      " 0.33229572 0.33985548]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 3\n",
      "n_candidates: 134\n",
      "n_resources: 3375\n",
      "Fitting 5 folds for each of 134 candidates, totalling 670 fits\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   4.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   9.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  18.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   5.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   6.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   3.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  11.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   2.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  28.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  16.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  15.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  25.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   7.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   3.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   9.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  28.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   7.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  18.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   3.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  20.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  12.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   6.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  30.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  11.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  18.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  13.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   3.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  17.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  24.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  11.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  23.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  10.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   8.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  20.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  10.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  12.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  12.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   8.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   8.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  23.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   4.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   3.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  10.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  20.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  19.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   9.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   3.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   8.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  19.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   6.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  18.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  17.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  19.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  10.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   3.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203     0.203     0.203     ... 0.2717037 0.2717037 0.2717037]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525    ... 0.32066667 0.32066667 0.32066667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 4\n",
      "n_candidates: 90\n",
      "n_resources: 5062\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  24.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   9.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  18.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  12.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   8.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   4.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  23.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   8.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   3.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  14.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   3.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   6.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  10.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  22.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   7.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  12.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  11.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  29.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  13.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   3.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   3.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   4.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   6.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  14.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  33.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  18.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  18.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  28.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  13.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  13.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  16.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   7.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  15.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  12.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   6.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   3.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   3.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  13.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  19.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   7.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  10.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  17.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  22.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  12.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  13.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  11.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   3.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  11.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  33.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  17.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  18.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   3.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   5.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  13.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  20.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   4.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  34.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  10.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  12.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   3.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   7.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  10.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  10.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  25.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  14.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  18.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   6.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   6.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  10.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  10.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  12.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  19.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   4.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   6.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  21.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  29.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   3.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203      ... 0.28221344 0.28221344 0.28221344]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525    ... 0.28303285 0.28303285 0.28303285]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 5\n",
      "n_candidates: 60\n",
      "n_resources: 7593\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  20.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   8.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   6.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  13.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  11.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  15.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   4.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   4.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   4.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   4.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   4.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   7.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  22.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  14.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   4.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   3.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  11.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  34.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  13.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  16.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=  12.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   4.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   9.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   7.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   3.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  21.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   9.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  33.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  14.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  19.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  17.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  10.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  19.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   7.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  10.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  15.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   3.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   4.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   3.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   4.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  17.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  25.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  11.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  28.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  13.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  20.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  11.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  13.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   4.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  21.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   3.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   8.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  24.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  10.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  12.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  13.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   7.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  10.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  34.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  10.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   3.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   4.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   7.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   4.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   3.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203      ... 0.30052701 0.30052701 0.30052701]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525    ... 0.31224893 0.31224893 0.31224893]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 6\n",
      "n_candidates: 40\n",
      "n_resources: 11390\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   6.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  12.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   3.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   6.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  20.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   6.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  20.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  30.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   3.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  12.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   6.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  11.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  19.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  28.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   6.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  22.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   3.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   4.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  23.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   4.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  13.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  10.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  34.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  18.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   6.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   4.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   8.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   9.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   4.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  13.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  21.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   8.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  15.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  27.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   8.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   8.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  29.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  22.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=  12.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   3.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   6.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  17.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   5.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  18.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  18.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  20.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   5.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  16.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   5.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   3.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  21.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   4.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  25.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   4.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   5.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  20.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  28.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  10.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  11.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   3.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  24.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  21.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   3.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   9.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   3.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  13.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  11.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  15.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=  13.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   5.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   5.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=  11.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   8.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  12.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   4.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   9.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   4.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  17.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   2.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   8.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   9.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  14.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   3.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  22.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  10.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  18.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   9.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  33.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  14.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   3.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   2.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   4.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   4.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   4.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   6.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   3.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  20.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   8.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  19.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=  11.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   3.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  12.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  22.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  22.3s\n",
      "----------\n",
      "iter: 7\n",
      "n_candidates: 27\n",
      "n_resources: 17085\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203      ... 0.30790167 0.30790167 0.30790167]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525    ... 0.31637401 0.31637401 0.31637401]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   3.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  11.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   4.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=  24.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.6s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   9.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=10000; total time=   0.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  12.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   5.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   4.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   8.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   7.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   3.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   5.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  12.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   3.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  13.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=  34.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  11.4s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   0.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  14.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  22.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   6.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  14.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   6.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   5.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   6.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   1.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   2.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   6.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   2.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   2.0s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   7.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  15.8s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  10.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  21.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   6.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   6.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   2.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   8.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:723: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203      ... 0.31630085 0.31630085 0.31630085]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525    0.24525    0.24525    ... 0.31518876 0.31518876 0.31518876]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 8\n",
      "n_candidates: 18\n",
      "n_resources: 25628\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=perceptron, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   9.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.5s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   2.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.2s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   3.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   0.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  34.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=   9.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=perceptron, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=hinge, model__max_iter=1000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.0s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  10.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   2.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.2s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=10000; total time=   0.7s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  21.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=hinge, model__max_iter=1000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=  19.0s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   4.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   7.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   3.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   4.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=modified_huber, model__max_iter=1000; total time=   7.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=1000; total time=   8.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=5000; total time=  21.5s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   0.3s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=1000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=10000; total time=   0.4s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=1000; total time=   0.2s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=5000; total time=   0.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=log, model__max_iter=5000; total time=   0.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=   5.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=5000; total time=   1.8s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=1000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=1000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=log, model__max_iter=10000; total time=   0.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   3.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=1000; total time=   4.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=1, model__loss=perceptron, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0, model__loss=perceptron, model__max_iter=10000; total time=   1.6s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.9s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=1000; total time=   1.8s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  10.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=perceptron, model__max_iter=1000; total time=   0.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=10000; total time=  32.5s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0, model__loss=squared_hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=1000; total time=   1.9s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=1000; total time=   0.7s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0, model__loss=hinge, model__max_iter=5000; total time=   0.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=1000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  13.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   1.1s\n",
      "[CV] END model__alpha=0.0001, model__l1_ratio=0.1, model__loss=perceptron, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=1, model__loss=squared_hinge, model__max_iter=10000; total time=  15.9s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=hinge, model__max_iter=5000; total time=   1.4s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   0.9s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=hinge, model__max_iter=5000; total time=   0.8s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0, model__loss=hinge, model__max_iter=10000; total time=   1.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   1.0s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=hinge, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=squared_hinge, model__max_iter=10000; total time=  20.1s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   1.3s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.3, model__loss=squared_hinge, model__max_iter=10000; total time=   1.5s\n",
      "[CV] END model__alpha=1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=squared_hinge, model__max_iter=5000; total time=  17.6s\n",
      "[CV] END model__alpha=0.001, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   1.7s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0, model__loss=modified_huber, model__max_iter=10000; total time=   5.1s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=1000; total time=   6.0s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=1000; total time=   4.7s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=   1.6s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=5000; total time=   7.6s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.1s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.3, model__loss=modified_huber, model__max_iter=5000; total time=   2.3s\n",
      "[CV] END model__alpha=0.1, model__l1_ratio=0.1, model__loss=modified_huber, model__max_iter=5000; total time=  13.2s\n",
      "[CV] END model__alpha=0.01, model__l1_ratio=0.5, model__loss=modified_huber, model__max_iter=10000; total time=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.203      0.203      0.203      ... 0.30552195 0.30552195 0.30552195]\n",
      "  warnings.warn(\n",
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the train scores are non-finite: [0.24525   0.24525   0.24525   ... 0.3078724 0.3078724 0.3078724]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HalvingGridSearchCV(estimator=Pipeline(steps=[('preprocessor', None),\n",
       "                                              ('model',\n",
       "                                               SGDClassifier(n_jobs=-1,\n",
       "                                                             penalty='elasticnet',\n",
       "                                                             random_state=42))]),\n",
       "                    factor=1.5, min_resources=1000, n_jobs=-1,\n",
       "                    param_grid={'model__alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                                'model__l1_ratio': [0, 0.1, 0.1, 0.3, 0.5, 1],\n",
       "                                'model__loss': ['hinge', 'log',\n",
       "                                                'modified_huber',\n",
       "                                                'squared_hinge', 'perceptron'],\n",
       "                                'model__max_iter': [1000, 5000, 10000]},\n",
       "                    verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               SGDClassifier(n_jobs=-1,\n",
       "                                                             penalty=&#x27;elasticnet&#x27;,\n",
       "                                                             random_state=42))]),\n",
       "                    factor=1.5, min_resources=1000, n_jobs=-1,\n",
       "                    param_grid={&#x27;model__alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                                &#x27;model__l1_ratio&#x27;: [0, 0.1, 0.1, 0.3, 0.5, 1],\n",
       "                                &#x27;model__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;,\n",
       "                                                &#x27;modified_huber&#x27;,\n",
       "                                                &#x27;squared_hinge&#x27;, &#x27;perceptron&#x27;],\n",
       "                                &#x27;model__max_iter&#x27;: [1000, 5000, 10000]},\n",
       "                    verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;HalvingGridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html\">?<span>Documentation for HalvingGridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>HalvingGridSearchCV(estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                                              (&#x27;model&#x27;,\n",
       "                                               SGDClassifier(n_jobs=-1,\n",
       "                                                             penalty=&#x27;elasticnet&#x27;,\n",
       "                                                             random_state=42))]),\n",
       "                    factor=1.5, min_resources=1000, n_jobs=-1,\n",
       "                    param_grid={&#x27;model__alpha&#x27;: [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                                &#x27;model__l1_ratio&#x27;: [0, 0.1, 0.1, 0.3, 0.5, 1],\n",
       "                                &#x27;model__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;,\n",
       "                                                &#x27;modified_huber&#x27;,\n",
       "                                                &#x27;squared_hinge&#x27;, &#x27;perceptron&#x27;],\n",
       "                                &#x27;model__max_iter&#x27;: [1000, 5000, 10000]},\n",
       "                    verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;, None),\n",
       "                (&#x27;model&#x27;,\n",
       "                 SGDClassifier(n_jobs=-1, penalty=&#x27;elasticnet&#x27;,\n",
       "                               random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">None</label><div class=\"sk-toggleable__content fitted\"><pre>None</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SGDClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.SGDClassifier.html\">?<span>Documentation for SGDClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SGDClassifier(n_jobs=-1, penalty=&#x27;elasticnet&#x27;, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:32:42.503041Z",
     "start_time": "2024-06-10T12:32:41.478989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = pd.DataFrame(hgs.cv_results_)\n",
    "results[\"params_str\"] = results.params.apply(str)\n",
    "results.drop_duplicates(subset=(\"params_str\", \"iter\"), inplace=True)\n",
    "mean_scores = results.pivot(\n",
    "    index=\"iter\", columns=\"params_str\", values=\"mean_test_score\"\n",
    ")\n",
    "ax = mean_scores.plot(legend=False, alpha=0.6, figsize=(15, 6))\n",
    "\n",
    "labels = [\n",
    "    f\"iter={i}\\nn_samples={hgs.n_resources_[i]}\\nn_candidates={hgs.n_candidates_[i]}\"\n",
    "    for i in range(hgs.n_iterations_)\n",
    "]\n",
    "\n",
    "ax.set_xticks(range(hgs.n_iterations_))\n",
    "ax.set_xticklabels(labels, rotation=45, multialignment=\"left\")\n",
    "ax.set_title(\"Scores of candidates over iterations\")\n",
    "ax.set_ylabel(\"mean test score\", fontsize=15)\n",
    "ax.set_xlabel(\"iterations\", fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "295b3d0199d99afe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:32:59.048379Z",
     "start_time": "2024-06-10T12:32:59.043989Z"
    }
   },
   "cell_type": "code",
   "source": "hgs.best_params_",
   "id": "58de82080b6113ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__alpha': 0.1,\n",
       " 'model__l1_ratio': 0.1,\n",
       " 'model__loss': 'modified_huber',\n",
       " 'model__max_iter': 1000}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:32:51.584201Z",
     "start_time": "2024-06-10T12:32:51.579845Z"
    }
   },
   "cell_type": "code",
   "source": "hgs.best_score_",
   "id": "3a4407afefa3b191",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3162536585365854"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:04:08.479189Z",
     "start_time": "2024-06-10T14:04:08.475183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": np.random.randint(1, 6, 3),\n",
    "    \"min_samples_split\": np.random.randint(2, 11, 3),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "rf_hgs = HalvingGridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, factor=0.8**(-1), cv=5, n_jobs=-1, verbose=2, min_resources=1000\n",
    ")\n",
    "rf_hgs.fit(X_train, y_train)\n",
    "print(rf_hgs.best_params_)\n",
    "print(rf_hgs.best_score_)"
   ],
   "id": "9f565d9ce36d66a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 5, 'min_samples_split': 4}\n",
      "0.7238916256157635\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multiple models",
   "id": "e33cf0f7cb1118fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:33:53.556623Z",
     "start_time": "2024-06-10T12:33:37.654067Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install git+https://github.com/hyperopt/hyperopt-sklearn ",
   "id": "ef973152f0c19622",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting git+https://github.com/hyperopt/hyperopt-sklearn\r\n",
      "  Cloning https://github.com/hyperopt/hyperopt-sklearn to /tmp/pip-req-build-taclu2d8\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/hyperopt/hyperopt-sklearn /tmp/pip-req-build-taclu2d8\r\n",
      "  Resolved https://github.com/hyperopt/hyperopt-sklearn to commit 4bc286479677a0bfd2178dac4546ea268b3f3b77\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.11.2 in ./envs/sentiocx/lib/python3.10/site-packages (from hpsklearn==1.0.3) (1.12.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in ./envs/sentiocx/lib/python3.10/site-packages (from hpsklearn==1.0.3) (1.4.1.post1)\r\n",
      "Collecting hyperopt>=0.2.6\r\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m8.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.26.0 in ./envs/sentiocx/lib/python3.10/site-packages (from hpsklearn==1.0.3) (1.26.4)\r\n",
      "Collecting py4j\r\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m200.5/200.5 KB\u001B[0m \u001B[31m230.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting future\r\n",
      "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m491.3/491.3 KB\u001B[0m \u001B[31m187.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting cloudpickle\r\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: six in ./envs/sentiocx/lib/python3.10/site-packages (from hyperopt>=0.2.6->hpsklearn==1.0.3) (1.16.0)\r\n",
      "Requirement already satisfied: networkx>=2.2 in ./envs/sentiocx/lib/python3.10/site-packages (from hyperopt>=0.2.6->hpsklearn==1.0.3) (3.3)\r\n",
      "Collecting tqdm\r\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 KB\u001B[0m \u001B[31m175.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-learn>=1.3.0->hpsklearn==1.0.3) (3.4.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-learn>=1.3.0->hpsklearn==1.0.3) (1.3.2)\r\n",
      "Building wheels for collected packages: hpsklearn\r\n",
      "  Building wheel for hpsklearn (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for hpsklearn: filename=hpsklearn-1.0.3-py3-none-any.whl size=135342 sha256=4e5345e6e33cc04758f425adea802f76d53564efda2d357821682141e3693647\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sx4ind6d/wheels/01/e8/01/ad06c89501e4845c988d4e846f45f3485d9b60be0b9ebea43b\r\n",
      "Successfully built hpsklearn\r\n",
      "Installing collected packages: py4j, tqdm, future, cloudpickle, hyperopt, hpsklearn\r\n",
      "Successfully installed cloudpickle-3.0.0 future-1.0.0 hpsklearn-1.0.3 hyperopt-0.2.7 py4j-0.10.9.7 tqdm-4.66.4\r\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from hpsklearn import HyperoptEstimator\n",
    "from hyperopt import tpe\n",
    "from hyperopt import hp\n",
    "\n",
    "estim = HyperoptEstimator(\n",
    "    classifier=hp.choice('classifier_type', [\n",
    "        {\n",
    "            'type': 'naive_bayes',\n",
    "        },\n",
    "        {\n",
    "            'type': 'svm',\n",
    "            'C': hp.lognormal('svm_C', 0, 1),\n",
    "            'kernel': hp.choice('svm_kernel', [\n",
    "                {'ktype': 'linear'},\n",
    "                {'ktype': 'RBF', 'width': hp.lognormal('svm_rbf_width', 0, 1)},\n",
    "            ]),\n",
    "        },\n",
    "        {\n",
    "            'type': 'dtree',\n",
    "            'criterion': hp.choice('dtree_criterion', ['gini', 'entropy']),\n",
    "            'max_depth': hp.choice('dtree_max_depth',\n",
    "                                   [None, hp.qlognormal('dtree_max_depth_int', 3, 1, 1)]),\n",
    "            'min_samples_split': hp.qlognormal('dtree_min_samples_split', 2, 1, 1),\n",
    "        },\n",
    "    ]),\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trial_timeout=120,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print(estim.best_model())"
   ],
   "id": "78b0cde1ac163a83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:59:03.436117Z",
     "start_time": "2024-06-10T13:40:06.924077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, all_classifiers\n",
    "from hyperopt import tpe\n",
    "import numpy as np\n",
    "from hyperopt import hp\n",
    "\n",
    "from hpsklearn import random_forest_classifier, \\\n",
    "    extra_tree_classifier, \\\n",
    "    ada_boost_classifier, \\\n",
    "    sgd_classifier, \\\n",
    "    k_neighbors_classifier, \\\n",
    "    svc\n",
    "    \n",
    "name = 'my_clf'\n",
    "\n",
    "# Instantiate a HyperoptEstimator with the search space and number of evaluations\n",
    "estim = HyperoptEstimator(\n",
    "        classifier=hp.choice(name, [\n",
    "            svc(name + \".svc\"),\n",
    "            k_neighbors_classifier(name + \".knn\"),\n",
    "            random_forest_classifier(name + \".random_forest\"),\n",
    "            extra_tree_classifier(name + \".extra_trees\"),\n",
    "            ada_boost_classifier(name + \".ada_boost\"),\n",
    "            sgd_classifier(name + \".sgd\")\n",
    "        ]),\n",
    "        preprocessing=any_preprocessing(\"my_pre\"),\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=100,\n",
    "        trial_timeout=60, \n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    ")\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print(estim.best_model())"
   ],
   "id": "dd1795200c514fe8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=60) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 32                       \n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_features=0.1475703439756273,\n",
      "                    max_leaf_nodes=10, random_state=1) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)       \n",
      "OK trial with accuracy 9.7 +- 0.4                    \n",
      "100%|██████████| 1/1 [00:00<00:00,  3.36trial/s, best loss: 0.9025714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False, with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner SVC(C=0.770609665789906, coef0=0.06916037692393207,\n",
      "    decision_function_shape='ovo', degree=1, kernel='poly', random_state=1,\n",
      "    tol=5.968456120068723e-05) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)       \n",
      "OK trial with accuracy 39.3 +- 0.6                   \n",
      "100%|██████████| 2/2 [00:44<00:00, 44.94s/trial, best loss: 0.6068571428571429]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=24, whiten=True) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 24                       \n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner ExtraTreeClassifier(random_state=0, splitter='best') on X/EX of dimension (28000, 24)\n",
      "Scoring on X/EX validation of shape (7000, 24)       \n",
      "OK trial with accuracy 41.6 +- 0.6                   \n",
      "100%|██████████| 3/3 [00:00<00:00,  1.05trial/s, best loss: 0.5842857142857143]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='max') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner SVC(C=1.1830214703216164, coef0=0.4451370923009773,\n",
      "    decision_function_shape='ovo', degree=5, random_state=1, shrinking=False,\n",
      "    tol=0.0005358506160847799) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)       \n",
      "OK trial with accuracy 65.6 +- 0.6                   \n",
      "100%|██████████| 4/4 [00:34<00:00, 34.70s/trial, best loss: 0.34371428571428575]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=24) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 24                       \n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner SGDClassifier(alpha=4.298271767622309e-06, eta0=0.03582339966028315,\n",
      "              l1_ratio=0.0005063023018242653,\n",
      "              loss='squared_epsilon_insensitive', max_iter=1008, n_jobs=-1,\n",
      "              power_t=0.9305795051587188, random_state=0,\n",
      "              tol=1.4221134593967302e-05) on X/EX of dimension (28000, 24)\n",
      "Scoring on X/EX validation of shape (7000, 24)       \n",
      "OK trial with accuracy 10.4 +- 0.4                   \n",
      "100%|██████████| 5/5 [00:04<00:00,  4.27s/trial, best loss: 0.34371428571428575]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner SVC(C=1.0923717200362424, coef0=0.21443518481961177,\n",
      "    decision_function_shape='ovo', random_state=3, tol=0.00018637236982031472) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)       \n",
      "OK trial with accuracy 63.6 +- 0.6                   \n",
      "100%|██████████| 6/6 [00:41<00:00, 41.29s/trial, best loss: 0.34371428571428575]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 4                        \n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner ExtraTreeClassifier(random_state=2) on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)        \n",
      "OK trial with accuracy 40.0 +- 0.6                   \n",
      "100%|██████████| 7/7 [00:00<00:00,  2.80trial/s, best loss: 0.34371428571428575]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=12) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 12                       \n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner KNeighborsClassifier(leaf_size=34, n_jobs=-1, n_neighbors=10,\n",
      "                     p=2.584744610354795) on X/EX of dimension (28000, 12)\n",
      "Scoring on X/EX validation of shape (7000, 12)       \n",
      "OK trial with accuracy 66.6 +- 0.6                   \n",
      "100%|██████████| 8/8 [00:02<00:00,  2.62s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=12, whiten=True) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 12                       \n",
      "Transforming Xfit (28000, 32)                        \n",
      "Transforming Xval (7000, 32)                         \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       criterion='entropy', max_features=0.5703008433271176,\n",
      "                       max_leaf_nodes=10, min_samples_leaf=45,\n",
      "                       n_estimators=2503, n_jobs=-1, random_state=1,\n",
      "                       verbose=False) on X/EX of dimension (28000, 12)\n",
      "Scoring on X/EX validation of shape (7000, 12)       \n",
      "OK trial with accuracy 39.2 +- 0.6                   \n",
      "100%|██████████| 9/9 [00:18<00:00, 18.95s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(clip=True, feature_range=(0.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                         \n",
      "Transforming Xval (7000, 32)                          \n",
      "Training learner SGDClassifier(alpha=0.05833879124819908, eta0=0.0012913521005092083,\n",
      "              l1_ratio=0.543651047778723, loss='modified_huber', max_iter=842,\n",
      "              n_iter_no_change=6, n_jobs=-1, penalty='l1',\n",
      "              power_t=0.7414735012316886, random_state=1,\n",
      "              tol=0.0038406305722730417) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)        \n",
      "OK trial with accuracy 10.4 +- 0.4                    \n",
      "100%|██████████| 10/10 [00:00<00:00,  2.77trial/s, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 4                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_depth=3,\n",
      "                    max_features=0.16912560924573294, max_leaf_nodes=5,\n",
      "                    random_state=1) on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)          \n",
      "OK trial with accuracy 10.0 +- 0.4                     \n",
      "100%|██████████| 11/11 [00:00<00:00,  2.12trial/s, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=40, whiten=True) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 32                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_features=None, random_state=2,\n",
      "                    splitter='best') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 57.5 +- 0.6                     \n",
      "100%|██████████| 12/12 [00:03<00:00,  3.56s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(learning_rate=0.600210258903341, n_estimators=114,\n",
      "                   random_state=4) on X/EX of dimension (28000, 32)\n",
      " 92%|█████████▏| 12/13 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 35.7 +- 0.6                     \n",
      "100%|██████████| 13/13 [00:16<00:00, 16.07s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(clip=True, feature_range=(-1.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=1.217473545642486, coef0=0.6775637996894184, degree=4, kernel='linear',\n",
      "    random_state=1, shrinking=False, tol=2.369319234228764e-05) on X/EX of dimension (28000, 32)\n",
      "TERMINATING DUE TO TIME-OUT.                           \n",
      "100%|██████████| 14/14 [01:00<00:00, 60.11s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='max') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(algorithm='SAMME', learning_rate=0.0031154523618010673,\n",
      "                   n_estimators=13, random_state=0) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 15/15 [00:02<00:00,  2.00s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(learning_rate=0.004256852454027261, n_estimators=24,\n",
      "                   random_state=1) on X/EX of dimension (28000, 32)\n",
      " 94%|█████████▍| 15/16 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 16/16 [00:03<00:00,  3.49s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=0.6369482694083042, coef0=0.46110449355030303,\n",
      "    decision_function_shape='ovo', degree=1, kernel='poly', random_state=2,\n",
      "    tol=1.5074745896550188e-05) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 39.2 +- 0.6                     \n",
      "100%|██████████| 17/17 [00:43<00:00, 43.27s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(feature_range=(-1.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(algorithm='SAMME', learning_rate=0.0002383691061903919,\n",
      "                   n_estimators=202, random_state=2) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 18/18 [00:27<00:00, 27.89s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='l1') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=0.9456287670455238, coef0=0.6500408264264611,\n",
      "    decision_function_shape='ovo', degree=2, kernel='linear', random_state=3,\n",
      "    tol=0.00080287771263604) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 38.8 +- 0.6                     \n",
      "100%|██████████| 19/19 [00:39<00:00, 39.71s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_features='log2', max_leaf_nodes=5,\n",
      "                    random_state=2) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 10.0 +- 0.4                     \n",
      "100%|██████████| 20/20 [00:00<00:00,  7.41trial/s, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='max') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(leaf_size=36, n_jobs=-1, n_neighbors=11,\n",
      "                     p=2.3455055732800933) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 56.7 +- 0.6                     \n",
      "100%|██████████| 21/21 [00:08<00:00,  8.61s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='max') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='ball_tree', leaf_size=21, n_jobs=-1,\n",
      "                     n_neighbors=1, p=4.975513830870652) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 44.6 +- 0.6                     \n",
      "100%|██████████| 22/22 [00:14<00:00, 14.12s/trial, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='max') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(leaf_size=39, metric='l1', n_jobs=-1, n_neighbors=14,\n",
      "                     p=1.094791128790619, weights='distance') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 62.0 +- 0.6                     \n",
      "100%|██████████| 23/23 [00:00<00:00,  1.30trial/s, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='l1') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced', max_depth=3,\n",
      "                       max_features='log2', min_impurity_decrease=0.02,\n",
      "                       n_estimators=10, n_jobs=-1, random_state=4,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 21.3 +- 0.5                     \n",
      "100%|██████████| 24/24 [00:00<00:00,  3.92trial/s, best loss: 0.3341428571428572]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='kd_tree', leaf_size=27, metric='manhattan',\n",
      "                     n_jobs=-1, n_neighbors=4, p=4.275967251848517) on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 67.2 +- 0.6                     \n",
      "100%|██████████| 25/25 [00:02<00:00,  2.11s/trial, best loss: 0.32799999999999996]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='kd_tree', leaf_size=28, metric='manhattan',\n",
      "                     n_jobs=-1, n_neighbors=4, p=4.137586366990257) on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 67.2 +- 0.6                     \n",
      "100%|██████████| 26/26 [00:02<00:00,  2.56s/trial, best loss: 0.32799999999999996]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='kd_tree', leaf_size=25, metric='manhattan',\n",
      "                     n_jobs=-1, n_neighbors=3, p=4.665573785866695) on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 65.1 +- 0.6                     \n",
      "100%|██████████| 27/27 [00:01<00:00,  1.58s/trial, best loss: 0.32799999999999996]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 4                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='kd_tree', leaf_size=28, metric='manhattan',\n",
      "                     n_jobs=-1, p=3.9898847341741543) on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)          \n",
      "OK trial with accuracy 51.5 +- 0.6                     \n",
      "100%|██████████| 28/28 [00:01<00:00,  1.04s/trial, best loss: 0.32799999999999996]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='kd_tree', metric='euclidean', n_jobs=-1,\n",
      "                     p=3.75352203060027) on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 67.5 +- 0.6                     \n",
      "100%|██████████| 29/29 [00:01<00:00,  1.93s/trial, best loss: 0.32471428571428573]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=32, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=7, p=3.526700061287638,\n",
      "                     weights='distance') on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 69.4 +- 0.6                     \n",
      "100%|██████████| 30/30 [00:00<00:00,  1.50trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(feature_range=(0.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=0.06675102246649749, eta0=1.277346228274741e-05,\n",
      "              l1_ratio=2.2647778216140951e-07, learning_rate='adaptive',\n",
      "              loss='log_loss', max_iter=1247, n_iter_no_change=4, n_jobs=-1,\n",
      "              penalty='elasticnet', power_t=0.03373839071286522, random_state=3,\n",
      "              tol=1.1364782314178373e-05) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 26.9 +- 0.5                     \n",
      "100%|██████████| 31/31 [00:02<00:00,  2.67s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 4                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=33, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=8, p=3.43257663526983,\n",
      "                     weights='distance') on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)          \n",
      "OK trial with accuracy 53.9 +- 0.6                     \n",
      "100%|██████████| 32/32 [00:00<00:00,  1.93trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=112) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 32                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, max_depth=4, max_features=None,\n",
      "                       max_leaf_nodes=5, min_impurity_decrease=0.05,\n",
      "                       min_samples_split=3, n_estimators=104, n_jobs=-1,\n",
      "                       random_state=0, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 9.7 +- 0.4                      \n",
      "100%|██████████| 33/33 [00:00<00:00,  1.07trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=16, whiten=True) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 16                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=32, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=7, p=3.450807281300317,\n",
      "                     weights='distance') on X/EX of dimension (28000, 16)\n",
      "Scoring on X/EX validation of shape (7000, 16)         \n",
      "OK trial with accuracy 43.9 +- 0.6                     \n",
      "100%|██████████| 34/34 [00:00<00:00,  1.43trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=31, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=7, p=3.069398323541822,\n",
      "                     weights='distance') on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 69.4 +- 0.6                     \n",
      "100%|██████████| 35/35 [00:00<00:00,  1.35trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=1.0092600036982123e-06, eta0=1.9883033715078654e-05,\n",
      "              l1_ratio=1.6680527823299313e-07, learning_rate='constant',\n",
      "              loss='huber', max_iter=1236, n_jobs=-1,\n",
      "              power_t=0.1316301908294114, random_state=4,\n",
      "              tol=0.009005376471111172) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 29.4 +- 0.5                     \n",
      "100%|██████████| 36/36 [00:00<00:00,  3.40trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 4                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=31, metric='l2', n_jobs=-1,\n",
      "                     n_neighbors=9, p=1.8840865429633806, weights='distance') on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)          \n",
      "OK trial with accuracy 54.1 +- 0.6                     \n",
      "100%|██████████| 37/37 [00:00<00:00,  1.61trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(clip=True, feature_range=(0.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=2, max_leaf_nodes=15,\n",
      "                       min_impurity_decrease=0.01, min_samples_leaf=2,\n",
      "                       n_estimators=1984, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 37.0 +- 0.6                     \n",
      "100%|██████████| 38/38 [00:06<00:00,  6.82s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=20) to X of shape (28000, 32) \n",
      "Limited PCA n_components at 20                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=38, metric='cityblock',\n",
      "                     n_jobs=-1, n_neighbors=12, p=2.9408545990243073,\n",
      "                     weights='distance') on X/EX of dimension (28000, 20)\n",
      "Scoring on X/EX validation of shape (7000, 20)         \n",
      "OK trial with accuracy 63.0 +- 0.6                     \n",
      "100%|██████████| 39/39 [00:01<00:00,  1.09s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=36) to X of shape (28000, 32) \n",
      "Limited PCA n_components at 32                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=0.00035446092196387153, eta0=0.057448272250064186,\n",
      "              l1_ratio=0.4719751987329207, learning_rate='invscaling',\n",
      "              loss='squared_hinge', max_iter=762, n_iter_no_change=6, n_jobs=-1,\n",
      "              penalty='l1', power_t=0.41252722425331284, random_state=2,\n",
      "              tol=0.00026905740356161133) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 28.0 +- 0.5                     \n",
      "100%|██████████| 40/40 [00:00<00:00,  1.14trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=12, whiten=True) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 12                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(max_depth=2, max_features=0.9960966818929018,\n",
      "                    max_leaf_nodes=15, random_state=3, splitter='best') on X/EX of dimension (28000, 12)\n",
      "Scoring on X/EX validation of shape (7000, 12)         \n",
      "OK trial with accuracy 22.3 +- 0.5                     \n",
      "100%|██████████| 41/41 [00:00<00:00,  1.85trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=23, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=8, p=3.157383209661603,\n",
      "                     weights='distance') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 50.2 +- 0.6                     \n",
      "100%|██████████| 42/42 [00:00<00:00,  2.04trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 4                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, max_features=0.010320272723666701,\n",
      "                       min_samples_leaf=48, n_estimators=13, n_jobs=-1,\n",
      "                       random_state=2, verbose=False) on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)          \n",
      "OK trial with accuracy 52.0 +- 0.6                     \n",
      "100%|██████████| 43/43 [00:00<00:00,  1.93trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(feature_range=(-1.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=0.9353280727975904, coef0=0.9889332391068864, gamma='auto',\n",
      "    kernel='sigmoid', random_state=4, shrinking=False,\n",
      "    tol=0.006709246634844924) on X/EX of dimension (28000, 32)\n",
      "TERMINATING DUE TO TIME-OUT.                           \n",
      "100%|██████████| 44/44 [01:00<00:00, 60.13s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=8) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 8                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(algorithm='SAMME', learning_rate=0.043252077293413724,\n",
      "                   n_estimators=816, random_state=3) on X/EX of dimension (28000, 8)\n",
      "Scoring on X/EX validation of shape (7000, 8)          \n",
      "OK trial with accuracy 26.4 +- 0.5                     \n",
      "100%|██████████| 45/45 [00:31<00:00, 31.46s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=4) to X of shape (28000, 32)  \n",
      "Limited PCA n_components at 4                          \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(max_depth=4, max_features=0.9603385512710056,\n",
      "                    random_state=4, splitter='best') on X/EX of dimension (28000, 4)\n",
      "Scoring on X/EX validation of shape (7000, 4)          \n",
      "OK trial with accuracy 29.7 +- 0.5                     \n",
      "100%|██████████| 46/46 [00:00<00:00,  1.53trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False, with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=0.000756542482229944, eta0=0.0004793454777538612,\n",
      "              l1_ratio=0.00019940526998906883, max_iter=1009,\n",
      "              n_iter_no_change=4, n_jobs=-1, penalty='elasticnet',\n",
      "              power_t=0.42483829647489946, random_state=1,\n",
      "              tol=0.000253189993060976) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 22.9 +- 0.5                     \n",
      "100%|██████████| 47/47 [00:00<00:00,  1.03trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(clip=True, feature_range=(0.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='ball_tree', leaf_size=31, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=7, p=1.8070377528224983,\n",
      "                     weights='distance') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 48.2 +- 0.6                     \n",
      "100%|██████████| 48/48 [00:06<00:00,  6.20s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=12, whiten=True) to X of shape (28000, 32)\n",
      "Limited PCA n_components at 12                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=1.4343952143517982, coef0=0.9989065565108899, degree=4, gamma='auto',\n",
      "    kernel='sigmoid', random_state=0, shrinking=False,\n",
      "    tol=0.008306145307490506) on X/EX of dimension (28000, 12)\n",
      "Scoring on X/EX validation of shape (7000, 12)         \n",
      "OK trial with accuracy 14.9 +- 0.4                     \n",
      "100%|██████████| 49/49 [00:56<00:00, 56.82s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=32) to X of shape (28000, 32) \n",
      "Limited PCA n_components at 32                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(learning_rate=0.02620606534017963, n_estimators=941,\n",
      "                   random_state=4) on X/EX of dimension (28000, 32)\n",
      " 98%|█████████▊| 49/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERMINATING DUE TO TIME-OUT.                           \n",
      "100%|██████████| 50/50 [01:00<00:00, 60.14s/trial, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False, with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner KNeighborsClassifier(algorithm='brute', leaf_size=36, metric='euclidean',\n",
      "                     n_jobs=-1, n_neighbors=9, p=2.4590441394222617,\n",
      "                     weights='distance') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 62.2 +- 0.6                     \n",
      "100%|██████████| 51/51 [00:00<00:00,  2.22trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(feature_range=(-1.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(max_features=0.5606193308396278, random_state=4,\n",
      "                    splitter='best') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 57.6 +- 0.6                     \n",
      "100%|██████████| 52/52 [00:00<00:00,  1.05trial/s, best loss: 0.3064285714285714]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting PCA(n_components=52) to X of shape (28000, 32) \n",
      "Limited PCA n_components at 32                         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.9797260099482059, n_estimators=369,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.5 +- 0.5                     \n",
      "100%|██████████| 53/53 [00:15<00:00, 15.75s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.9336211678349827, n_estimators=451,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 71.1 +- 0.5                     \n",
      "100%|██████████| 54/54 [00:24<00:00, 24.52s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.9930739599223178, n_estimators=397,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 70.9 +- 0.5                     \n",
      "100%|██████████| 55/55 [00:22<00:00, 22.89s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.9691763999558314, n_estimators=341,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 70.9 +- 0.5                     \n",
      "100%|██████████| 56/56 [00:20<00:00, 20.17s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.7558742652671329, n_estimators=159,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 71.4 +- 0.5                     \n",
      "100%|██████████| 57/57 [00:07<00:00,  7.65s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.6591687217950397, n_estimators=89,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 71.3 +- 0.5                     \n",
      "100%|██████████| 58/58 [00:05<00:00,  5.06s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='l1') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.7637441351663496, n_estimators=41,\n",
      "                       n_jobs=-1, random_state=4, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 70.5 +- 0.5                     \n",
      "100%|██████████| 59/59 [00:03<00:00,  3.57s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_features=0.27418218174679343, n_estimators=1224,\n",
      "                       n_jobs=-1, random_state=1, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.1 +- 0.5                     \n",
      "100%|██████████| 60/60 [00:20<00:00, 20.62s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       n_estimators=929, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.2 +- 0.5                     \n",
      "100%|██████████| 61/61 [00:12<00:00, 12.18s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer(norm='l1') to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(criterion='entropy', n_estimators=798, n_jobs=-1,\n",
      "                       random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 71.7 +- 0.5                     \n",
      "100%|██████████| 62/62 [00:08<00:00,  8.50s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting Normalizer() to X of shape (28000, 32)         \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       n_estimators=922, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.1 +- 0.5                     \n",
      "100%|██████████| 63/63 [00:09<00:00, 10.00s/trial, best loss: 0.2745714285714286]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=285,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.2 +- 0.5                     \n",
      "100%|██████████| 64/64 [00:03<00:00,  3.26s/trial, best loss: 0.26842857142857146]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=0.8192347321710143, coef0=0.008923609530145593, degree=2, gamma='auto',\n",
      "    kernel='sigmoid', random_state=2, tol=0.001956450241023885) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 18.9 +- 0.5                     \n",
      "100%|██████████| 65/65 [00:58<00:00, 59.00s/trial, best loss: 0.26842857142857146]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=234,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.0 +- 0.5                     \n",
      "100%|██████████| 66/66 [00:02<00:00,  2.67s/trial, best loss: 0.26842857142857146]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=240,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.2 +- 0.5                     \n",
      "100%|██████████| 67/67 [00:02<00:00,  2.65s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=192,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.1 +- 0.5                     \n",
      "100%|██████████| 68/68 [00:02<00:00,  2.19s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=44,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.4 +- 0.5                     \n",
      "100%|██████████| 69/69 [00:00<00:00,  1.15trial/s, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=147,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.0 +- 0.5                     \n",
      "100%|██████████| 70/70 [00:01<00:00,  1.93s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(learning_rate=0.0008123543575667963, n_estimators=38,\n",
      "                   random_state=3) on X/EX of dimension (28000, 32)\n",
      " 99%|█████████▊| 70/71 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 71/71 [00:05<00:00,  5.74s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       min_samples_leaf=6, n_estimators=62, n_jobs=-1,\n",
      "                       random_state=0, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.0 +- 0.5                     \n",
      "100%|██████████| 72/72 [00:00<00:00,  1.21trial/s, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=1.3497533953300677e-05, eta0=0.002346260437417725,\n",
      "              l1_ratio=0.0008040860099754708, learning_rate='constant',\n",
      "              loss='perceptron', max_iter=1135, n_jobs=-1,\n",
      "              power_t=0.9457065057114971, random_state=2,\n",
      "              tol=0.0017936543953786968) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 14.9 +- 0.4                     \n",
      "100%|██████████| 73/73 [00:00<00:00,  3.86trial/s, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', n_estimators=210,\n",
      "                       n_jobs=-1, random_state=2, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.1 +- 0.5                     \n",
      "100%|██████████| 74/74 [00:02<00:00,  2.47s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced_subsample', max_depth=4,\n",
      "                       n_estimators=566, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 49.9 +- 0.6                     \n",
      "100%|██████████| 75/75 [00:04<00:00,  4.53s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_features=0.554427154376953,\n",
      "                    random_state=0) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 56.9 +- 0.6                     \n",
      "100%|██████████| 76/76 [00:00<00:00,  3.68trial/s, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=1.0627544740389, coef0=0.7827090586935708, degree=5, gamma='auto',\n",
      "    random_state=0, shrinking=False, tol=0.00010830956418808205) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 63.6 +- 0.6                     \n",
      "100%|██████████| 77/77 [00:44<00:00, 44.83s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(algorithm='SAMME', learning_rate=0.11328994099878287,\n",
      "                   n_estimators=352, random_state=1) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 30.9 +- 0.6                     \n",
      "100%|██████████| 78/78 [00:50<00:00, 50.62s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(max_depth=2, n_estimators=265, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 34.5 +- 0.6                     \n",
      "100%|██████████| 79/79 [00:01<00:00,  1.07s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=0.004145764221923341, eta0=0.00011076309391785195,\n",
      "              l1_ratio=6.675881063143049e-06, learning_rate='invscaling',\n",
      "              loss='squared_error', max_iter=865, n_jobs=-1, penalty='l1',\n",
      "              power_t=0.6525651621098401, random_state=3,\n",
      "              tol=4.695764119825215e-05) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 29.1 +- 0.5                     \n",
      "100%|██████████| 80/80 [00:06<00:00,  6.83s/trial, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(class_weight='balanced', max_depth=3,\n",
      "                       min_samples_leaf=12, n_estimators=26, n_jobs=-1,\n",
      "                       random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 44.2 +- 0.6                     \n",
      "100%|██████████| 81/81 [00:00<00:00,  2.69trial/s, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_depth=2, max_features=None,\n",
      "                    random_state=3) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 18.6 +- 0.5                     \n",
      "100%|██████████| 82/82 [00:00<00:00,  5.89trial/s, best loss: 0.2681428571428571]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       n_estimators=111, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.7 +- 0.5                     \n",
      "100%|██████████| 83/83 [00:01<00:00,  1.47s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False, with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=0.8619585440671456, coef0=0.24449442331804933,\n",
      "    decision_function_shape='ovo', degree=2, gamma='auto', kernel='poly',\n",
      "    random_state=4, shrinking=False, tol=0.0026176217760777746) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 61.1 +- 0.6                     \n",
      "100%|██████████| 84/84 [00:33<00:00, 33.05s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(clip=True, feature_range=(0.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(algorithm='SAMME', learning_rate=0.011750455834938911,\n",
      "                   n_estimators=53, random_state=0) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 85/85 [00:07<00:00,  7.41s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       max_features='log2', n_estimators=88, n_jobs=-1,\n",
      "                       random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.6 +- 0.5                     \n",
      "100%|██████████| 86/86 [00:01<00:00,  1.29s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=5.231176710469716e-05, eta0=0.014826650180281535,\n",
      "              l1_ratio=0.029803894835434563, loss='modified_huber',\n",
      "              max_iter=1127, n_jobs=-1, power_t=0.20404931038230445,\n",
      "              random_state=0, tol=0.0011671573942534019) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 19.6 +- 0.5                     \n",
      "100%|██████████| 87/87 [00:01<00:00,  1.04s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       max_features='log2', max_leaf_nodes=10,\n",
      "                       min_samples_leaf=2, n_estimators=97, n_jobs=-1,\n",
      "                       random_state=2, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 48.2 +- 0.6                     \n",
      "100%|██████████| 88/88 [00:00<00:00,  1.50trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(feature_range=(-1.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(max_depth=3, random_state=0, splitter='best') on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 27.4 +- 0.5                     \n",
      "100%|██████████| 89/89 [00:00<00:00,  4.45trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       max_features='log2', n_estimators=29, n_jobs=-1,\n",
      "                       random_state=4, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 72.6 +- 0.5                     \n",
      "100%|██████████| 90/90 [00:00<00:00,  1.18trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False, with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
      "                       max_features='log2', n_estimators=65, n_jobs=-1,\n",
      "                       random_state=0, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.1 +- 0.5                     \n",
      "100%|██████████| 91/91 [00:01<00:00,  1.09s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SVC(C=1.2055704674079735, coef0=0.8737037801947335, degree=5, gamma='auto',\n",
      "    kernel='linear', random_state=3, tol=6.443614241378048e-05) on X/EX of dimension (28000, 32)\n",
      "TERMINATING DUE TO TIME-OUT.                           \n",
      "100%|██████████| 92/92 [01:00<00:00, 60.13s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(clip=True, feature_range=(0.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner AdaBoostClassifier(learning_rate=0.0015049433835189802, n_estimators=11,\n",
      "                   random_state=2) on X/EX of dimension (28000, 32)\n",
      " 99%|█████████▉| 92/93 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 93/93 [00:01<00:00,  1.70s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, max_features='log2', n_estimators=112,\n",
      "                       n_jobs=-1, random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 73.6 +- 0.5                     \n",
      "100%|██████████| 94/94 [00:01<00:00,  1.56s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner SGDClassifier(alpha=0.006073275514641383, eta0=7.980698776193845e-05,\n",
      "              l1_ratio=7.514548795568541e-06, loss='epsilon_insensitive',\n",
      "              max_iter=904, n_iter_no_change=4, n_jobs=-1, penalty='elasticnet',\n",
      "              power_t=0.27523171988981476, random_state=4,\n",
      "              tol=6.261259080659302e-05) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 19.9 +- 0.5                     \n",
      "100%|██████████| 95/95 [00:00<00:00,  1.59trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_mean=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, max_depth=3, max_features='log2',\n",
      "                       min_samples_leaf=16, n_estimators=127, n_jobs=-1,\n",
      "                       random_state=4, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 43.3 +- 0.6                     \n",
      "100%|██████████| 96/96 [00:00<00:00,  1.56trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting MinMaxScaler(feature_range=(-1.0, 1.0)) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner ExtraTreeClassifier(criterion='entropy', max_features='log2', random_state=4) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 49.3 +- 0.6                     \n",
      "100%|██████████| 97/97 [00:00<00:00,  4.50trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler(with_std=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, max_features='log2', max_leaf_nodes=15,\n",
      "                       min_impurity_decrease=0.01, n_estimators=18, n_jobs=-1,\n",
      "                       random_state=3, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 35.8 +- 0.6                     \n",
      "100%|██████████| 98/98 [00:00<00:00,  1.85trial/s, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation\n",
      "Fitting StandardScaler() to X of shape (28000, 32)     \n",
      "Transforming Xfit (28000, 32)                          \n",
      "Transforming Xval (7000, 32)                           \n",
      "Training learner RandomForestClassifier(bootstrap=False, max_depth=4, max_features=None,\n",
      "                       min_impurity_decrease=0.02, n_estimators=66, n_jobs=-1,\n",
      "                       random_state=0, verbose=False) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)         \n",
      "OK trial with accuracy 17.6 +- 0.5                     \n",
      "100%|██████████| 99/99 [00:01<00:00,  1.02s/trial, best loss: 0.263]\n",
      "Will use the last 0.2 portion of samples for validation \n",
      "Fitting StandardScaler(with_mean=False) to X of shape (28000, 32)\n",
      "Transforming Xfit (28000, 32)                           \n",
      "Transforming Xval (7000, 32)                            \n",
      "Training learner SVC(C=1.0348687766207403, coef0=0.3087680018379645, kernel='sigmoid',\n",
      "    random_state=4, tol=1.1090959143259745e-05) on X/EX of dimension (28000, 32)\n",
      "Scoring on X/EX validation of shape (7000, 32)          \n",
      "TERMINATING DUE TO TIME-OUT.                            \n",
      "100%|██████████| 100/100 [01:00<00:00, 60.13s/trial, best loss: 0.263]\n",
      "Fitting StandardScaler() to X of shape (35000, 32)\n",
      "Transforming Xfit (35000, 32)\n",
      "Training learner RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       n_estimators=111, n_jobs=-1, random_state=3,\n",
      "                       verbose=False) on X/EX of dimension (35000, 32)\n",
      "Fitting StandardScaler() to X of shape (7500, 32)\n",
      "Transforming Xfit (7500, 32)\n",
      "0.7508\n",
      "{'learner': RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       n_estimators=111, n_jobs=-1, random_state=3,\n",
      "                       verbose=False), 'preprocs': (StandardScaler(),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:01:41.006476Z",
     "start_time": "2024-06-10T14:01:40.852717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Show the results\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print(estim.best_model())\n",
    "\n",
    "y_pred = estim.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ],
   "id": "5ac0189041df8fff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting StandardScaler() to X of shape (7500, 32)\n",
      "Transforming Xfit (7500, 32)\n",
      "0.7508\n",
      "{'learner': RandomForestClassifier(bootstrap=False, class_weight='balanced_subsample',\n",
      "                       n_estimators=111, n_jobs=-1, random_state=3,\n",
      "                       verbose=False), 'preprocs': (StandardScaler(),), 'ex_preprocs': ()}\n",
      "Fitting StandardScaler() to X of shape (7500, 32)\n",
      "Transforming Xfit (7500, 32)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76       780\n",
      "           1       0.74      0.77      0.75       782\n",
      "           2       0.73      0.68      0.70       764\n",
      "           3       0.73      0.76      0.74       736\n",
      "           4       0.74      0.65      0.69       729\n",
      "           5       0.82      0.82      0.82       755\n",
      "           6       0.75      0.81      0.78       768\n",
      "           7       0.75      0.72      0.73       732\n",
      "           8       0.81      0.82      0.82       713\n",
      "           9       0.75      0.72      0.73       741\n",
      "\n",
      "    accuracy                           0.75      7500\n",
      "   macro avg       0.76      0.75      0.75      7500\n",
      "weighted avg       0.75      0.75      0.75      7500\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:04:25.762337Z",
     "start_time": "2024-05-29T13:04:25.756860Z"
    }
   },
   "cell_type": "code",
   "source": "rsh.best_params_",
   "id": "6a21b9f52cac1624",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 3,\n",
       " 'max_features': 3,\n",
       " 'min_samples_split': 6}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:17:36.712006Z",
     "start_time": "2024-05-29T13:17:36.705925Z"
    }
   },
   "cell_type": "code",
   "source": "rsh.best_score_",
   "id": "d68228795aef4852",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8545454545454545"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FLAML",
   "id": "a2fa06cb3e53155a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:06:23.199891Z",
     "start_time": "2024-06-10T14:06:19.521298Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install flaml",
   "id": "7a8bd6c28675d04c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting flaml\r\n",
      "  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m296.7/296.7 KB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: NumPy>=1.17 in ./envs/sentiocx/lib/python3.10/site-packages (from flaml) (1.26.4)\r\n",
      "Installing collected packages: flaml\r\n",
      "Successfully installed flaml-2.1.2\r\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[FLAML](https://microsoft.github.io/FLAML/docs/getting-started)",
   "id": "7cec4e579b29f66c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Automatically searches all possible hiperparameters and models.\n",
    "* It uses custom objects (flaml internal)\n",
    "* It defines built-in search spaces for each type of model\n",
    "* Runs on a predefined time budget"
   ],
   "id": "b13c2b6f71559674"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "https://www.microsoft.com/en-us/research/uploads/prod/2021/03/MLSys21FLAML.pdf\n",
    "\n"
   ],
   "id": "3ad74c31fbcda11d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:09:18.560989Z",
     "start_time": "2024-06-10T14:07:01.753748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from flaml import AutoML\n",
    "from flaml.automl.model import RandomForestEstimator, XGBoostEstimator, LightGBMEstimator, CatBoostEstimator\n",
    "\n",
    "automl = AutoML()\n",
    "automl.add_learner('rf', RandomForestEstimator)\n",
    "automl.add_learner('xgboost', XGBoostEstimator)\n",
    "\n",
    "settings = {\n",
    "    \"time_budget\": 180,  # total running time in seconds\n",
    "    # \"metric\": custom_metric,\n",
    "    \"metric\": 'accuracy',\n",
    "    \"estimator_list\": ['rf'],\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"log_file_name\": 'flaml_experiment.log',  # flaml log file\n",
    "    \"X_val\": X_val,\n",
    "    \"y_val\": y_val,\n",
    "    \"verbose\": 10,\n",
    "}\n",
    "\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "print('Best hyper-parmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1 - automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ],
   "id": "f1caeb6a4495f8f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-10 14:07:01] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 06-10 14:07:01] {1688} INFO - Data split method: stratified\n",
      "[flaml.automl.logger: 06-10 14:07:01] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 06-10 14:07:01] {1789} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 06-10 14:07:01] {1901} INFO - List of ML learners in AutoML Run: ['rf']\n",
      "[flaml.automl.logger: 06-10 14:07:01] {2219} INFO - iteration 0, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:01] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:02] {202} INFO - result: {'pred_time': 2.1066665649414063e-06, 'wall_clock_time': 0.3543701171875, 'metric_for_logging': {'pred_time': 2.1066665649414063e-06}, 'val_loss': 0.7163999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42417541c0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.3338446617126465}\n",
      "[flaml.tune.tune: 06-10 14:07:02] {202} INFO - result: {'pred_time': 2.1066665649414063e-06, 'wall_clock_time': 0.3543701171875, 'metric_for_logging': {'pred_time': 2.1066665649414063e-06}, 'val_loss': 0.7163999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42417541c0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.334486722946167}\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2345} INFO - Estimated sufficient time budget=3373s. Estimated necessary time budget=3s.\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2392} INFO -  at 0.4s,\testimator rf's best error=0.7164,\tbest estimator rf's best error=0.7164\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2219} INFO - iteration 1, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:02] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:02] {202} INFO - result: {'pred_time': 2.0856857299804686e-06, 'wall_clock_time': 0.5666661262512207, 'metric_for_logging': {'pred_time': 2.0856857299804686e-06}, 'val_loss': 0.6106666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3d4a30>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624973, 'config/max_leaves': 12, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.20777463912963867}\n",
      "[flaml.tune.tune: 06-10 14:07:02] {202} INFO - result: {'pred_time': 2.0856857299804686e-06, 'wall_clock_time': 0.5666661262512207, 'metric_for_logging': {'pred_time': 2.0856857299804686e-06}, 'val_loss': 0.6106666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3d4a30>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624973, 'config/max_leaves': 12, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2084963321685791}\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2392} INFO -  at 0.6s,\testimator rf's best error=0.6107,\tbest estimator rf's best error=0.6107\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2219} INFO - iteration 2, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:02] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:02] {202} INFO - result: {'pred_time': 2.0922342936197916e-06, 'wall_clock_time': 0.7464468479156494, 'metric_for_logging': {'pred_time': 2.0922342936197916e-06}, 'val_loss': 0.7196, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7d90>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17618966102600098}\n",
      "[flaml.tune.tune: 06-10 14:07:02] {202} INFO - result: {'pred_time': 2.0922342936197916e-06, 'wall_clock_time': 0.7464468479156494, 'metric_for_logging': {'pred_time': 2.0922342936197916e-06}, 'val_loss': 0.7196, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7d90>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17675495147705078}\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2392} INFO -  at 0.7s,\testimator rf's best error=0.6107,\tbest estimator rf's best error=0.6107\n",
      "[flaml.automl.logger: 06-10 14:07:02] {2219} INFO - iteration 3, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:02] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:03] {202} INFO - result: {'pred_time': 2.2049585978190103e-06, 'wall_clock_time': 1.2192368507385254, 'metric_for_logging': {'pred_time': 2.2049585978190103e-06}, 'val_loss': 0.5831999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6cb0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.11297795568850721, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4698662757873535}\n",
      "[flaml.tune.tune: 06-10 14:07:03] {202} INFO - result: {'pred_time': 2.2049585978190103e-06, 'wall_clock_time': 1.2192368507385254, 'metric_for_logging': {'pred_time': 2.2049585978190103e-06}, 'val_loss': 0.5831999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6cb0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.11297795568850721, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4707062244415283}\n",
      "[flaml.automl.logger: 06-10 14:07:03] {2392} INFO -  at 1.2s,\testimator rf's best error=0.5832,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:07:03] {2219} INFO - iteration 4, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:03] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17133249602624967, 'max_leaves': 12, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:03] {202} INFO - result: {'pred_time': 2.0548502604166665e-06, 'wall_clock_time': 1.6604728698730469, 'metric_for_logging': {'pred_time': 2.0548502604166665e-06}, 'val_loss': 0.6150666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f424147c8b0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624967, 'max_leaves': 12, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624967, 'config/max_leaves': 12, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4375419616699219}\n",
      "[flaml.tune.tune: 06-10 14:07:03] {202} INFO - result: {'pred_time': 2.0548502604166665e-06, 'wall_clock_time': 1.6604728698730469, 'metric_for_logging': {'pred_time': 2.0548502604166665e-06}, 'val_loss': 0.6150666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f424147c8b0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624967, 'max_leaves': 12, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624967, 'config/max_leaves': 12, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.43833088874816895}\n",
      "[flaml.automl.logger: 06-10 14:07:03] {2392} INFO -  at 1.7s,\testimator rf's best error=0.5832,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:07:03] {2219} INFO - iteration 5, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:03] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.11262915120101383, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:03] {202} INFO - result: {'pred_time': 2.5150299072265625e-06, 'wall_clock_time': 2.1090521812438965, 'metric_for_logging': {'pred_time': 2.5150299072265625e-06}, 'val_loss': 0.6009333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd8c70>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.11262915120101383, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.11262915120101383, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.44539356231689453}\n",
      "[flaml.tune.tune: 06-10 14:07:03] {202} INFO - result: {'pred_time': 2.5150299072265625e-06, 'wall_clock_time': 2.1090521812438965, 'metric_for_logging': {'pred_time': 2.5150299072265625e-06}, 'val_loss': 0.6009333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd8c70>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.11262915120101383, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.11262915120101383, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4461202621459961}\n",
      "[flaml.automl.logger: 06-10 14:07:03] {2392} INFO -  at 2.1s,\testimator rf's best error=0.5832,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:07:03] {2219} INFO - iteration 6, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:03] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.1133278403987422, 'max_leaves': 17, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:04] {202} INFO - result: {'pred_time': 2.0357449849446615e-06, 'wall_clock_time': 2.286778211593628, 'metric_for_logging': {'pred_time': 2.0357449849446615e-06}, 'val_loss': 0.5473333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3ab2e0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.1133278403987422, 'max_leaves': 17, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.1133278403987422, 'config/max_leaves': 17, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17449331283569336}\n",
      "[flaml.tune.tune: 06-10 14:07:04] {202} INFO - result: {'pred_time': 2.0357449849446615e-06, 'wall_clock_time': 2.286778211593628, 'metric_for_logging': {'pred_time': 2.0357449849446615e-06}, 'val_loss': 0.5473333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3ab2e0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.1133278403987422, 'max_leaves': 17, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.1133278403987422, 'config/max_leaves': 17, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17518186569213867}\n",
      "[flaml.automl.logger: 06-10 14:07:04] {2392} INFO -  at 2.3s,\testimator rf's best error=0.5473,\tbest estimator rf's best error=0.5473\n",
      "[flaml.automl.logger: 06-10 14:07:04] {2219} INFO - iteration 7, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:04] {811} INFO - trial 1 config: {'n_estimators': 11, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:04] {202} INFO - result: {'pred_time': 2.3511886596679686e-06, 'wall_clock_time': 2.8641936779022217, 'metric_for_logging': {'pred_time': 2.3511886596679686e-06}, 'val_loss': 0.47053333333333336, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6b90>, 'training_iteration': 0, 'config': {'n_estimators': 11, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy'}, 'config/n_estimators': 11, 'config/max_features': 0.1, 'config/max_leaves': 31, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.573906660079956}\n",
      "[flaml.tune.tune: 06-10 14:07:04] {202} INFO - result: {'pred_time': 2.3511886596679686e-06, 'wall_clock_time': 2.8641936779022217, 'metric_for_logging': {'pred_time': 2.3511886596679686e-06}, 'val_loss': 0.47053333333333336, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6b90>, 'training_iteration': 1, 'config': {'n_estimators': 11, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy'}, 'config/n_estimators': 11, 'config/max_features': 0.1, 'config/max_leaves': 31, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5746092796325684}\n",
      "[flaml.automl.logger: 06-10 14:07:04] {2392} INFO -  at 2.9s,\testimator rf's best error=0.4705,\tbest estimator rf's best error=0.4705\n",
      "[flaml.automl.logger: 06-10 14:07:04] {2219} INFO - iteration 8, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:04] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.11781054620852233, 'max_leaves': 17, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:04] {202} INFO - result: {'pred_time': 2.1068572998046876e-06, 'wall_clock_time': 3.2055797576904297, 'metric_for_logging': {'pred_time': 2.1068572998046876e-06}, 'val_loss': 0.5502666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd70a0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.11781054620852233, 'max_leaves': 17, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.11781054620852233, 'config/max_leaves': 17, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.33797550201416016}\n",
      "[flaml.tune.tune: 06-10 14:07:04] {202} INFO - result: {'pred_time': 2.1068572998046876e-06, 'wall_clock_time': 3.2055797576904297, 'metric_for_logging': {'pred_time': 2.1068572998046876e-06}, 'val_loss': 0.5502666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd70a0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.11781054620852233, 'max_leaves': 17, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.11781054620852233, 'config/max_leaves': 17, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.33859848976135254}\n",
      "[flaml.automl.logger: 06-10 14:07:04] {2392} INFO -  at 3.2s,\testimator rf's best error=0.4705,\tbest estimator rf's best error=0.4705\n",
      "[flaml.automl.logger: 06-10 14:07:04] {2219} INFO - iteration 9, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:04] {811} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.10944307631566913, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:05] {202} INFO - result: {'pred_time': 2.508544921875e-06, 'wall_clock_time': 3.6937360763549805, 'metric_for_logging': {'pred_time': 2.508544921875e-06}, 'val_loss': 0.6028, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd8d30>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_features': 0.10944307631566913, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.10944307631566913, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.48525071144104004}\n",
      "[flaml.tune.tune: 06-10 14:07:05] {202} INFO - result: {'pred_time': 2.508544921875e-06, 'wall_clock_time': 3.6937360763549805, 'metric_for_logging': {'pred_time': 2.508544921875e-06}, 'val_loss': 0.6028, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd8d30>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_features': 0.10944307631566913, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.10944307631566913, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4859590530395508}\n",
      "[flaml.automl.logger: 06-10 14:07:05] {2392} INFO -  at 3.7s,\testimator rf's best error=0.4705,\tbest estimator rf's best error=0.4705\n",
      "[flaml.automl.logger: 06-10 14:07:05] {2219} INFO - iteration 10, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:05] {811} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.1, 'max_leaves': 158, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:05] {202} INFO - result: {'pred_time': 2.3534774780273437e-06, 'wall_clock_time': 4.070562362670898, 'metric_for_logging': {'pred_time': 2.3534774780273437e-06}, 'val_loss': 0.3845333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756c50>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_features': 0.1, 'max_leaves': 158, 'criterion': 'gini'}, 'config/n_estimators': 9, 'config/max_features': 0.1, 'config/max_leaves': 158, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.37372708320617676}\n",
      "[flaml.tune.tune: 06-10 14:07:05] {202} INFO - result: {'pred_time': 2.3534774780273437e-06, 'wall_clock_time': 4.070562362670898, 'metric_for_logging': {'pred_time': 2.3534774780273437e-06}, 'val_loss': 0.3845333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756c50>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_features': 0.1, 'max_leaves': 158, 'criterion': 'gini'}, 'config/n_estimators': 9, 'config/max_features': 0.1, 'config/max_leaves': 158, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3744363784790039}\n",
      "[flaml.automl.logger: 06-10 14:07:05] {2392} INFO -  at 4.1s,\testimator rf's best error=0.3845,\tbest estimator rf's best error=0.3845\n",
      "[flaml.automl.logger: 06-10 14:07:05] {2219} INFO - iteration 11, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:05] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.1, 'max_leaves': 116, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:06] {202} INFO - result: {'pred_time': 2.487945556640625e-06, 'wall_clock_time': 4.77758526802063, 'metric_for_logging': {'pred_time': 2.487945556640625e-06}, 'val_loss': 0.41946666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3a9210>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.1, 'max_leaves': 116, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.1, 'config/max_leaves': 116, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7031996250152588}\n",
      "[flaml.tune.tune: 06-10 14:07:06] {202} INFO - result: {'pred_time': 2.487945556640625e-06, 'wall_clock_time': 4.77758526802063, 'metric_for_logging': {'pred_time': 2.487945556640625e-06}, 'val_loss': 0.41946666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3a9210>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.1, 'max_leaves': 116, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.1, 'config/max_leaves': 116, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7039046287536621}\n",
      "[flaml.automl.logger: 06-10 14:07:06] {2392} INFO -  at 4.8s,\testimator rf's best error=0.3845,\tbest estimator rf's best error=0.3845\n",
      "[flaml.automl.logger: 06-10 14:07:06] {2219} INFO - iteration 12, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:06] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:06] {202} INFO - result: {'pred_time': 2.6048978169759115e-06, 'wall_clock_time': 5.18817663192749, 'metric_for_logging': {'pred_time': 2.6048978169759115e-06}, 'val_loss': 0.3606666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd8370>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.40758371353149414}\n",
      "[flaml.tune.tune: 06-10 14:07:06] {202} INFO - result: {'pred_time': 2.6048978169759115e-06, 'wall_clock_time': 5.18817663192749, 'metric_for_logging': {'pred_time': 2.6048978169759115e-06}, 'val_loss': 0.3606666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd8370>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4083070755004883}\n",
      "[flaml.automl.logger: 06-10 14:07:06] {2392} INFO -  at 5.2s,\testimator rf's best error=0.3607,\tbest estimator rf's best error=0.3607\n",
      "[flaml.automl.logger: 06-10 14:07:06] {2219} INFO - iteration 13, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:06] {811} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.12716512254425438, 'max_leaves': 387, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:07] {202} INFO - result: {'pred_time': 2.1740595499674478e-06, 'wall_clock_time': 5.683415651321411, 'metric_for_logging': {'pred_time': 2.1740595499674478e-06}, 'val_loss': 0.3406666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd7b80>, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_features': 0.12716512254425438, 'max_leaves': 387, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.12716512254425438, 'config/max_leaves': 387, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4917030334472656}\n",
      "[flaml.tune.tune: 06-10 14:07:07] {202} INFO - result: {'pred_time': 2.1740595499674478e-06, 'wall_clock_time': 5.683415651321411, 'metric_for_logging': {'pred_time': 2.1740595499674478e-06}, 'val_loss': 0.3406666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd7b80>, 'training_iteration': 1, 'config': {'n_estimators': 6, 'max_features': 0.12716512254425438, 'max_leaves': 387, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.12716512254425438, 'config/max_leaves': 387, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.49253416061401367}\n",
      "[flaml.automl.logger: 06-10 14:07:07] {2392} INFO -  at 5.7s,\testimator rf's best error=0.3407,\tbest estimator rf's best error=0.3407\n",
      "[flaml.automl.logger: 06-10 14:07:07] {2219} INFO - iteration 14, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:07] {811} INFO - trial 1 config: {'n_estimators': 16, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:08] {202} INFO - result: {'pred_time': 2.5828997294108072e-06, 'wall_clock_time': 6.4750072956085205, 'metric_for_logging': {'pred_time': 2.5828997294108072e-06}, 'val_loss': 0.358, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7160>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'entropy'}, 'config/n_estimators': 16, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.78763747215271}\n",
      "[flaml.tune.tune: 06-10 14:07:08] {202} INFO - result: {'pred_time': 2.5828997294108072e-06, 'wall_clock_time': 6.4750072956085205, 'metric_for_logging': {'pred_time': 2.5828997294108072e-06}, 'val_loss': 0.358, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7160>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'entropy'}, 'config/n_estimators': 16, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7884559631347656}\n",
      "[flaml.automl.logger: 06-10 14:07:08] {2392} INFO -  at 6.5s,\testimator rf's best error=0.3407,\tbest estimator rf's best error=0.3407\n",
      "[flaml.automl.logger: 06-10 14:07:08] {2219} INFO - iteration 15, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:08] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.14782443610163173, 'max_leaves': 1328, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:08] {202} INFO - result: {'pred_time': 2.1123568216959636e-06, 'wall_clock_time': 7.027597188949585, 'metric_for_logging': {'pred_time': 2.1123568216959636e-06}, 'val_loss': 0.32399999999999995, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a60b0>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.14782443610163173, 'max_leaves': 1328, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.14782443610163173, 'config/max_leaves': 1328, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5494029521942139}\n",
      "[flaml.tune.tune: 06-10 14:07:08] {202} INFO - result: {'pred_time': 2.1123568216959636e-06, 'wall_clock_time': 7.027597188949585, 'metric_for_logging': {'pred_time': 2.1123568216959636e-06}, 'val_loss': 0.32399999999999995, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a60b0>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.14782443610163173, 'max_leaves': 1328, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.14782443610163173, 'config/max_leaves': 1328, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5501232147216797}\n",
      "[flaml.automl.logger: 06-10 14:07:08] {2392} INFO -  at 7.0s,\testimator rf's best error=0.3240,\tbest estimator rf's best error=0.3240\n",
      "[flaml.automl.logger: 06-10 14:07:08] {2219} INFO - iteration 16, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:08] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.12716512254425436, 'max_leaves': 387, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:09] {202} INFO - result: {'pred_time': 2.2620201110839845e-06, 'wall_clock_time': 8.086440563201904, 'metric_for_logging': {'pred_time': 2.2620201110839845e-06}, 'val_loss': 0.33986666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd7760>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.12716512254425436, 'max_leaves': 387, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.12716512254425436, 'config/max_leaves': 387, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0552175045013428}\n",
      "[flaml.tune.tune: 06-10 14:07:09] {202} INFO - result: {'pred_time': 2.2620201110839845e-06, 'wall_clock_time': 8.086440563201904, 'metric_for_logging': {'pred_time': 2.2620201110839845e-06}, 'val_loss': 0.33986666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd7760>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.12716512254425436, 'max_leaves': 387, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.12716512254425436, 'config/max_leaves': 387, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0559661388397217}\n",
      "[flaml.automl.logger: 06-10 14:07:09] {2392} INFO -  at 8.1s,\testimator rf's best error=0.3240,\tbest estimator rf's best error=0.3240\n",
      "[flaml.automl.logger: 06-10 14:07:09] {2219} INFO - iteration 17, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:09] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.10827489540854032, 'max_leaves': 1725, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:10] {202} INFO - result: {'pred_time': 2.1240234375e-06, 'wall_clock_time': 8.407941341400146, 'metric_for_logging': {'pred_time': 2.1240234375e-06}, 'val_loss': 0.3586666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3a8790>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.10827489540854032, 'max_leaves': 1725, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.10827489540854032, 'config/max_leaves': 1725, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3180861473083496}\n",
      "[flaml.tune.tune: 06-10 14:07:10] {202} INFO - result: {'pred_time': 2.1240234375e-06, 'wall_clock_time': 8.407941341400146, 'metric_for_logging': {'pred_time': 2.1240234375e-06}, 'val_loss': 0.3586666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3a8790>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.10827489540854032, 'max_leaves': 1725, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.10827489540854032, 'config/max_leaves': 1725, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3188209533691406}\n",
      "[flaml.automl.logger: 06-10 14:07:10] {2392} INFO -  at 8.4s,\testimator rf's best error=0.3240,\tbest estimator rf's best error=0.3240\n",
      "[flaml.automl.logger: 06-10 14:07:10] {2219} INFO - iteration 18, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:10] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.20182022643673495, 'max_leaves': 1023, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:11] {202} INFO - result: {'pred_time': 2.451292673746745e-06, 'wall_clock_time': 10.127752542495728, 'metric_for_logging': {'pred_time': 2.451292673746745e-06}, 'val_loss': 0.2838666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756650>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.20182022643673495, 'max_leaves': 1023, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.20182022643673495, 'config/max_leaves': 1023, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7164795398712158}\n",
      "[flaml.tune.tune: 06-10 14:07:11] {202} INFO - result: {'pred_time': 2.451292673746745e-06, 'wall_clock_time': 10.127752542495728, 'metric_for_logging': {'pred_time': 2.451292673746745e-06}, 'val_loss': 0.2838666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756650>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.20182022643673495, 'max_leaves': 1023, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.20182022643673495, 'config/max_leaves': 1023, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.717236042022705}\n",
      "[flaml.automl.logger: 06-10 14:07:11] {2392} INFO -  at 10.1s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:11] {2219} INFO - iteration 19, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:11] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.31172361069439525, 'max_leaves': 1537, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:14] {202} INFO - result: {'pred_time': 2.4981816609700522e-06, 'wall_clock_time': 12.713007926940918, 'metric_for_logging': {'pred_time': 2.4981816609700522e-06}, 'val_loss': 0.2845333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a65f0>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.31172361069439525, 'max_leaves': 1537, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.31172361069439525, 'config/max_leaves': 1537, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.5816197395324707}\n",
      "[flaml.tune.tune: 06-10 14:07:14] {202} INFO - result: {'pred_time': 2.4981816609700522e-06, 'wall_clock_time': 12.713007926940918, 'metric_for_logging': {'pred_time': 2.4981816609700522e-06}, 'val_loss': 0.2845333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a65f0>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.31172361069439525, 'max_leaves': 1537, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.31172361069439525, 'config/max_leaves': 1537, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.5826330184936523}\n",
      "[flaml.automl.logger: 06-10 14:07:14] {2392} INFO -  at 12.7s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:14] {2219} INFO - iteration 20, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:14] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.13066512256880933, 'max_leaves': 681, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:15] {202} INFO - result: {'pred_time': 2.284558614095052e-06, 'wall_clock_time': 13.280803442001343, 'metric_for_logging': {'pred_time': 2.284558614095052e-06}, 'val_loss': 0.30746666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756aa0>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.13066512256880933, 'max_leaves': 681, 'criterion': 'gini'}, 'config/n_estimators': 10, 'config/max_features': 0.13066512256880933, 'config/max_leaves': 681, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5643153190612793}\n",
      "[flaml.tune.tune: 06-10 14:07:15] {202} INFO - result: {'pred_time': 2.284558614095052e-06, 'wall_clock_time': 13.280803442001343, 'metric_for_logging': {'pred_time': 2.284558614095052e-06}, 'val_loss': 0.30746666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756aa0>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.13066512256880933, 'max_leaves': 681, 'criterion': 'gini'}, 'config/n_estimators': 10, 'config/max_features': 0.13066512256880933, 'config/max_leaves': 681, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5650303363800049}\n",
      "[flaml.automl.logger: 06-10 14:07:15] {2392} INFO -  at 13.3s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:15] {2219} INFO - iteration 21, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:15] {811} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.21273986984697202, 'max_leaves': 708, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:16] {202} INFO - result: {'pred_time': 2.4299303690592446e-06, 'wall_clock_time': 15.041945457458496, 'metric_for_logging': {'pred_time': 2.4299303690592446e-06}, 'val_loss': 0.28959999999999997, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6e30>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.21273986984697202, 'max_leaves': 708, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.21273986984697202, 'config/max_leaves': 708, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7579383850097656}\n",
      "[flaml.tune.tune: 06-10 14:07:16] {202} INFO - result: {'pred_time': 2.4299303690592446e-06, 'wall_clock_time': 15.041945457458496, 'metric_for_logging': {'pred_time': 2.4299303690592446e-06}, 'val_loss': 0.28959999999999997, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6e30>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.21273986984697202, 'max_leaves': 708, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 0.21273986984697202, 'config/max_leaves': 708, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7587151527404785}\n",
      "[flaml.automl.logger: 06-10 14:07:16] {2392} INFO -  at 15.0s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:16] {2219} INFO - iteration 22, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:16] {811} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.19146107322653658, 'max_leaves': 1478, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:17] {202} INFO - result: {'pred_time': 2.245775858561198e-06, 'wall_clock_time': 15.879297494888306, 'metric_for_logging': {'pred_time': 2.245775858561198e-06}, 'val_loss': 0.29066666666666663, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241755c00>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.19146107322653658, 'max_leaves': 1478, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.19146107322653658, 'config/max_leaves': 1478, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8340072631835938}\n",
      "[flaml.tune.tune: 06-10 14:07:17] {202} INFO - result: {'pred_time': 2.245775858561198e-06, 'wall_clock_time': 15.879297494888306, 'metric_for_logging': {'pred_time': 2.245775858561198e-06}, 'val_loss': 0.29066666666666663, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241755c00>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.19146107322653658, 'max_leaves': 1478, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.19146107322653658, 'config/max_leaves': 1478, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.8348574638366699}\n",
      "[flaml.automl.logger: 06-10 14:07:17] {2392} INFO -  at 15.9s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:17] {2219} INFO - iteration 23, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:17] {811} INFO - trial 1 config: {'n_estimators': 21, 'max_features': 0.170514547558736, 'max_leaves': 748, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:18] {202} INFO - result: {'pred_time': 2.7341842651367187e-06, 'wall_clock_time': 16.680429935455322, 'metric_for_logging': {'pred_time': 2.7341842651367187e-06}, 'val_loss': 0.2886666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241755330>, 'training_iteration': 0, 'config': {'n_estimators': 21, 'max_features': 0.170514547558736, 'max_leaves': 748, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.170514547558736, 'config/max_leaves': 748, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7976257801055908}\n",
      "[flaml.tune.tune: 06-10 14:07:18] {202} INFO - result: {'pred_time': 2.7341842651367187e-06, 'wall_clock_time': 16.680429935455322, 'metric_for_logging': {'pred_time': 2.7341842651367187e-06}, 'val_loss': 0.2886666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241755330>, 'training_iteration': 1, 'config': {'n_estimators': 21, 'max_features': 0.170514547558736, 'max_leaves': 748, 'criterion': 'gini'}, 'config/n_estimators': 21, 'config/max_features': 0.170514547558736, 'config/max_leaves': 748, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.798405647277832}\n",
      "[flaml.automl.logger: 06-10 14:07:18] {2392} INFO -  at 16.7s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:18] {2219} INFO - iteration 24, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:18] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.23887348253933874, 'max_leaves': 1400, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:20] {202} INFO - result: {'pred_time': 2.237701416015625e-06, 'wall_clock_time': 18.546231508255005, 'metric_for_logging': {'pred_time': 2.237701416015625e-06}, 'val_loss': 0.30413333333333337, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241022f80>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.23887348253933874, 'max_leaves': 1400, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.23887348253933874, 'config/max_leaves': 1400, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.8627331256866455}\n",
      "[flaml.tune.tune: 06-10 14:07:20] {202} INFO - result: {'pred_time': 2.237701416015625e-06, 'wall_clock_time': 18.546231508255005, 'metric_for_logging': {'pred_time': 2.237701416015625e-06}, 'val_loss': 0.30413333333333337, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241022f80>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.23887348253933874, 'max_leaves': 1400, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.23887348253933874, 'config/max_leaves': 1400, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.863462209701538}\n",
      "[flaml.automl.logger: 06-10 14:07:20] {2392} INFO -  at 18.5s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:20] {2219} INFO - iteration 25, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:20] {811} INFO - trial 1 config: {'n_estimators': 14, 'max_features': 0.1375329528586463, 'max_leaves': 738, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:21] {202} INFO - result: {'pred_time': 2.41702397664388e-06, 'wall_clock_time': 19.82117509841919, 'metric_for_logging': {'pred_time': 2.41702397664388e-06}, 'val_loss': 0.3010666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241b6b2b0>, 'training_iteration': 0, 'config': {'n_estimators': 14, 'max_features': 0.1375329528586463, 'max_leaves': 738, 'criterion': 'entropy'}, 'config/n_estimators': 14, 'config/max_features': 0.1375329528586463, 'config/max_leaves': 738, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2717082500457764}\n",
      "[flaml.tune.tune: 06-10 14:07:21] {202} INFO - result: {'pred_time': 2.41702397664388e-06, 'wall_clock_time': 19.82117509841919, 'metric_for_logging': {'pred_time': 2.41702397664388e-06}, 'val_loss': 0.3010666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241b6b2b0>, 'training_iteration': 1, 'config': {'n_estimators': 14, 'max_features': 0.1375329528586463, 'max_leaves': 738, 'criterion': 'entropy'}, 'config/n_estimators': 14, 'config/max_features': 0.1375329528586463, 'config/max_leaves': 738, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2725512981414795}\n",
      "[flaml.automl.logger: 06-10 14:07:21] {2392} INFO -  at 19.8s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:21] {2219} INFO - iteration 26, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:21] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.29615741502211407, 'max_leaves': 1417, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:22] {202} INFO - result: {'pred_time': 2.2602081298828126e-06, 'wall_clock_time': 20.94843077659607, 'metric_for_logging': {'pred_time': 2.2602081298828126e-06}, 'val_loss': 0.29133333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241021db0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.29615741502211407, 'max_leaves': 1417, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.29615741502211407, 'config/max_leaves': 1417, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1238324642181396}\n",
      "[flaml.tune.tune: 06-10 14:07:22] {202} INFO - result: {'pred_time': 2.2602081298828126e-06, 'wall_clock_time': 20.94843077659607, 'metric_for_logging': {'pred_time': 2.2602081298828126e-06}, 'val_loss': 0.29133333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241021db0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.29615741502211407, 'max_leaves': 1417, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.29615741502211407, 'config/max_leaves': 1417, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1245670318603516}\n",
      "[flaml.automl.logger: 06-10 14:07:22] {2392} INFO -  at 20.9s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:22] {2219} INFO - iteration 27, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:22] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.23758723030995235, 'max_leaves': 301, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:24] {202} INFO - result: {'pred_time': 2.6170730590820314e-06, 'wall_clock_time': 22.706482887268066, 'metric_for_logging': {'pred_time': 2.6170730590820314e-06}, 'val_loss': 0.31720000000000004, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3d64a0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.23758723030995235, 'max_leaves': 301, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.23758723030995235, 'config/max_leaves': 301, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.754854440689087}\n",
      "[flaml.tune.tune: 06-10 14:07:24] {202} INFO - result: {'pred_time': 2.6170730590820314e-06, 'wall_clock_time': 22.706482887268066, 'metric_for_logging': {'pred_time': 2.6170730590820314e-06}, 'val_loss': 0.31720000000000004, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3d64a0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.23758723030995235, 'max_leaves': 301, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.23758723030995235, 'config/max_leaves': 301, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.7555842399597168}\n",
      "[flaml.automl.logger: 06-10 14:07:24] {2392} INFO -  at 22.7s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:24] {2219} INFO - iteration 28, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:24] {811} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.17143768099757487, 'max_leaves': 3475, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:25] {202} INFO - result: {'pred_time': 2.201398213704427e-06, 'wall_clock_time': 23.464519500732422, 'metric_for_logging': {'pred_time': 2.201398213704427e-06}, 'val_loss': 0.3102666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42410215a0>, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_features': 0.17143768099757487, 'max_leaves': 3475, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.17143768099757487, 'config/max_leaves': 3475, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.754697322845459}\n",
      "[flaml.tune.tune: 06-10 14:07:25] {202} INFO - result: {'pred_time': 2.201398213704427e-06, 'wall_clock_time': 23.464519500732422, 'metric_for_logging': {'pred_time': 2.201398213704427e-06}, 'val_loss': 0.3102666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42410215a0>, 'training_iteration': 1, 'config': {'n_estimators': 6, 'max_features': 0.17143768099757487, 'max_leaves': 3475, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.17143768099757487, 'config/max_leaves': 3475, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.7554152011871338}\n",
      "[flaml.automl.logger: 06-10 14:07:25] {2392} INFO -  at 23.5s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:25] {2219} INFO - iteration 29, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:25] {811} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.2676444020110844, 'max_leaves': 826, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:27] {202} INFO - result: {'pred_time': 2.2019068400065106e-06, 'wall_clock_time': 25.566715002059937, 'metric_for_logging': {'pred_time': 2.2019068400065106e-06}, 'val_loss': 0.2878666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd73d0>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_features': 0.2676444020110844, 'max_leaves': 826, 'criterion': 'entropy'}, 'config/n_estimators': 9, 'config/max_features': 0.2676444020110844, 'config/max_leaves': 826, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.0989701747894287}\n",
      "[flaml.tune.tune: 06-10 14:07:27] {202} INFO - result: {'pred_time': 2.2019068400065106e-06, 'wall_clock_time': 25.566715002059937, 'metric_for_logging': {'pred_time': 2.2019068400065106e-06}, 'val_loss': 0.2878666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd73d0>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_features': 0.2676444020110844, 'max_leaves': 826, 'criterion': 'entropy'}, 'config/n_estimators': 9, 'config/max_features': 0.2676444020110844, 'config/max_leaves': 826, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 2.0997490882873535}\n",
      "[flaml.automl.logger: 06-10 14:07:27] {2392} INFO -  at 25.6s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:27] {2219} INFO - iteration 30, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:27] {811} INFO - trial 1 config: {'n_estimators': 11, 'max_features': 0.15218477761133253, 'max_leaves': 1268, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:27] {202} INFO - result: {'pred_time': 2.363745371500651e-06, 'wall_clock_time': 26.195735692977905, 'metric_for_logging': {'pred_time': 2.363745371500651e-06}, 'val_loss': 0.2985333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6bc0>, 'training_iteration': 0, 'config': {'n_estimators': 11, 'max_features': 0.15218477761133253, 'max_leaves': 1268, 'criterion': 'gini'}, 'config/n_estimators': 11, 'config/max_features': 0.15218477761133253, 'config/max_leaves': 1268, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6259176731109619}\n",
      "[flaml.tune.tune: 06-10 14:07:27] {202} INFO - result: {'pred_time': 2.363745371500651e-06, 'wall_clock_time': 26.195735692977905, 'metric_for_logging': {'pred_time': 2.363745371500651e-06}, 'val_loss': 0.2985333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a6bc0>, 'training_iteration': 1, 'config': {'n_estimators': 11, 'max_features': 0.15218477761133253, 'max_leaves': 1268, 'criterion': 'gini'}, 'config/n_estimators': 11, 'config/max_features': 0.15218477761133253, 'config/max_leaves': 1268, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6266727447509766}\n",
      "[flaml.automl.logger: 06-10 14:07:27] {2392} INFO -  at 26.2s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:27] {2219} INFO - iteration 31, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:27] {811} INFO - trial 1 config: {'n_estimators': 17, 'max_features': 0.28239554557601143, 'max_leaves': 538, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:29] {202} INFO - result: {'pred_time': 2.5759696960449217e-06, 'wall_clock_time': 27.298866987228394, 'metric_for_logging': {'pred_time': 2.5759696960449217e-06}, 'val_loss': 0.2864, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756230>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_features': 0.28239554557601143, 'max_leaves': 538, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.28239554557601143, 'config/max_leaves': 538, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.0994699001312256}\n",
      "[flaml.tune.tune: 06-10 14:07:29] {202} INFO - result: {'pred_time': 2.5759696960449217e-06, 'wall_clock_time': 27.298866987228394, 'metric_for_logging': {'pred_time': 2.5759696960449217e-06}, 'val_loss': 0.2864, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241756230>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_features': 0.28239554557601143, 'max_leaves': 538, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.28239554557601143, 'config/max_leaves': 538, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.1002936363220215}\n",
      "[flaml.automl.logger: 06-10 14:07:29] {2392} INFO -  at 27.3s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:29] {2219} INFO - iteration 32, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:29] {811} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.14423529137435148, 'max_leaves': 1944, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:30] {202} INFO - result: {'pred_time': 2.248954772949219e-06, 'wall_clock_time': 28.539628982543945, 'metric_for_logging': {'pred_time': 2.248954772949219e-06}, 'val_loss': 0.3116, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241757f10>, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_features': 0.14423529137435148, 'max_leaves': 1944, 'criterion': 'entropy'}, 'config/n_estimators': 6, 'config/max_features': 0.14423529137435148, 'config/max_leaves': 1944, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2376885414123535}\n",
      "[flaml.tune.tune: 06-10 14:07:30] {202} INFO - result: {'pred_time': 2.248954772949219e-06, 'wall_clock_time': 28.539628982543945, 'metric_for_logging': {'pred_time': 2.248954772949219e-06}, 'val_loss': 0.3116, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241757f10>, 'training_iteration': 1, 'config': {'n_estimators': 6, 'max_features': 0.14423529137435148, 'max_leaves': 1944, 'criterion': 'entropy'}, 'config/n_estimators': 6, 'config/max_features': 0.14423529137435148, 'config/max_leaves': 1944, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2384090423583984}\n",
      "[flaml.automl.logger: 06-10 14:07:30] {2392} INFO -  at 28.5s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:30] {2219} INFO - iteration 33, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:30] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.2994538198747455, 'max_leaves': 538, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:31] {202} INFO - result: {'pred_time': 2.1995226542154946e-06, 'wall_clock_time': 29.599575519561768, 'metric_for_logging': {'pred_time': 2.1995226542154946e-06}, 'val_loss': 0.3037333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7ac0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.2994538198747455, 'max_leaves': 538, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.2994538198747455, 'config/max_leaves': 538, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.056596279144287}\n",
      "[flaml.tune.tune: 06-10 14:07:31] {202} INFO - result: {'pred_time': 2.1995226542154946e-06, 'wall_clock_time': 29.599575519561768, 'metric_for_logging': {'pred_time': 2.1995226542154946e-06}, 'val_loss': 0.3037333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7ac0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.2994538198747455, 'max_leaves': 538, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.2994538198747455, 'config/max_leaves': 538, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 1.0573675632476807}\n",
      "[flaml.automl.logger: 06-10 14:07:31] {2392} INFO -  at 29.6s,\testimator rf's best error=0.2839,\tbest estimator rf's best error=0.2839\n",
      "[flaml.automl.logger: 06-10 14:07:31] {2219} INFO - iteration 34, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:31] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.13601898221238903, 'max_leaves': 1945, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:32] {202} INFO - result: {'pred_time': 2.5654792785644533e-06, 'wall_clock_time': 30.897793769836426, 'metric_for_logging': {'pred_time': 2.5654792785644533e-06}, 'val_loss': 0.2806666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd89d0>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.13601898221238903, 'max_leaves': 1945, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.13601898221238903, 'config/max_leaves': 1945, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2948696613311768}\n",
      "[flaml.tune.tune: 06-10 14:07:32] {202} INFO - result: {'pred_time': 2.5654792785644533e-06, 'wall_clock_time': 30.897793769836426, 'metric_for_logging': {'pred_time': 2.5654792785644533e-06}, 'val_loss': 0.2806666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd89d0>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.13601898221238903, 'max_leaves': 1945, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.13601898221238903, 'config/max_leaves': 1945, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2956185340881348}\n",
      "[flaml.automl.logger: 06-10 14:07:32] {2392} INFO -  at 30.9s,\testimator rf's best error=0.2807,\tbest estimator rf's best error=0.2807\n",
      "[flaml.automl.logger: 06-10 14:07:32] {2219} INFO - iteration 35, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:32] {811} INFO - trial 1 config: {'n_estimators': 68, 'max_features': 0.17377529728386, 'max_leaves': 1245, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:34] {202} INFO - result: {'pred_time': 7.05560048421224e-06, 'wall_clock_time': 32.90021729469299, 'metric_for_logging': {'pred_time': 7.05560048421224e-06}, 'val_loss': 0.26626666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7dc0>, 'training_iteration': 0, 'config': {'n_estimators': 68, 'max_features': 0.17377529728386, 'max_leaves': 1245, 'criterion': 'entropy'}, 'config/n_estimators': 68, 'config/max_features': 0.17377529728386, 'config/max_leaves': 1245, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9986555576324463}\n",
      "[flaml.tune.tune: 06-10 14:07:34] {202} INFO - result: {'pred_time': 7.05560048421224e-06, 'wall_clock_time': 32.90021729469299, 'metric_for_logging': {'pred_time': 7.05560048421224e-06}, 'val_loss': 0.26626666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7dc0>, 'training_iteration': 1, 'config': {'n_estimators': 68, 'max_features': 0.17377529728386, 'max_leaves': 1245, 'criterion': 'entropy'}, 'config/n_estimators': 68, 'config/max_features': 0.17377529728386, 'config/max_leaves': 1245, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.9998161792755127}\n",
      "[flaml.automl.logger: 06-10 14:07:34] {2392} INFO -  at 32.9s,\testimator rf's best error=0.2663,\tbest estimator rf's best error=0.2663\n",
      "[flaml.automl.logger: 06-10 14:07:34] {2219} INFO - iteration 36, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:34] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.13601898221238903, 'max_leaves': 1945, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:35] {202} INFO - result: {'pred_time': 2.6442845662434897e-06, 'wall_clock_time': 33.59585165977478, 'metric_for_logging': {'pred_time': 2.6442845662434897e-06}, 'val_loss': 0.2864, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7400>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.13601898221238903, 'max_leaves': 1945, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.13601898221238903, 'config/max_leaves': 1945, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6896190643310547}\n",
      "[flaml.tune.tune: 06-10 14:07:35] {202} INFO - result: {'pred_time': 2.6442845662434897e-06, 'wall_clock_time': 33.59585165977478, 'metric_for_logging': {'pred_time': 2.6442845662434897e-06}, 'val_loss': 0.2864, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42419a7400>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.13601898221238903, 'max_leaves': 1945, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.13601898221238903, 'config/max_leaves': 1945, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.6908237934112549}\n",
      "[flaml.automl.logger: 06-10 14:07:35] {2392} INFO -  at 33.6s,\testimator rf's best error=0.2663,\tbest estimator rf's best error=0.2663\n",
      "[flaml.automl.logger: 06-10 14:07:35] {2219} INFO - iteration 37, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:35] {811} INFO - trial 1 config: {'n_estimators': 26, 'max_features': 0.11887860413416503, 'max_leaves': 1853, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:07:36] {202} INFO - result: {'pred_time': 2.808221181233724e-06, 'wall_clock_time': 34.81705069541931, 'metric_for_logging': {'pred_time': 2.808221181233724e-06}, 'val_loss': 0.2897333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd7dc0>, 'training_iteration': 0, 'config': {'n_estimators': 26, 'max_features': 0.11887860413416503, 'max_leaves': 1853, 'criterion': 'entropy'}, 'config/n_estimators': 26, 'config/max_features': 0.11887860413416503, 'config/max_leaves': 1853, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2170848846435547}\n",
      "[flaml.tune.tune: 06-10 14:07:36] {202} INFO - result: {'pred_time': 2.808221181233724e-06, 'wall_clock_time': 34.81705069541931, 'metric_for_logging': {'pred_time': 2.808221181233724e-06}, 'val_loss': 0.2897333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bd7dc0>, 'training_iteration': 1, 'config': {'n_estimators': 26, 'max_features': 0.11887860413416503, 'max_leaves': 1853, 'criterion': 'entropy'}, 'config/n_estimators': 26, 'config/max_features': 0.11887860413416503, 'config/max_leaves': 1853, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.2178254127502441}\n",
      "[flaml.automl.logger: 06-10 14:07:36] {2392} INFO -  at 34.8s,\testimator rf's best error=0.2663,\tbest estimator rf's best error=0.2663\n",
      "[flaml.automl.logger: 06-10 14:07:36] {2219} INFO - iteration 38, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:36] {811} INFO - trial 1 config: {'n_estimators': 177, 'max_features': 0.2540226154742948, 'max_leaves': 836, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:07:39] {202} INFO - result: {'pred_time': 1.1440499623616536e-05, 'wall_clock_time': 37.423182010650635, 'metric_for_logging': {'pred_time': 1.1440499623616536e-05}, 'val_loss': 0.26493333333333335, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3a87c0>, 'training_iteration': 0, 'config': {'n_estimators': 177, 'max_features': 0.2540226154742948, 'max_leaves': 836, 'criterion': 'gini'}, 'config/n_estimators': 177, 'config/max_features': 0.2540226154742948, 'config/max_leaves': 836, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.6030266284942627}\n",
      "[flaml.tune.tune: 06-10 14:07:39] {202} INFO - result: {'pred_time': 1.1440499623616536e-05, 'wall_clock_time': 37.423182010650635, 'metric_for_logging': {'pred_time': 1.1440499623616536e-05}, 'val_loss': 0.26493333333333335, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b3a87c0>, 'training_iteration': 1, 'config': {'n_estimators': 177, 'max_features': 0.2540226154742948, 'max_leaves': 836, 'criterion': 'gini'}, 'config/n_estimators': 177, 'config/max_features': 0.2540226154742948, 'config/max_leaves': 836, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 2.604966640472412}\n",
      "[flaml.automl.logger: 06-10 14:07:39] {2392} INFO -  at 37.4s,\testimator rf's best error=0.2649,\tbest estimator rf's best error=0.2649\n",
      "[flaml.automl.logger: 06-10 14:07:39] {2219} INFO - iteration 39, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:07:39] {811} INFO - trial 1 config: {'n_estimators': 1273, 'max_features': 0.6327945777804539, 'max_leaves': 1774, 'criterion': 'entropy'}\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   3.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   3.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   4.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   3.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   4.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   4.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   6.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   6.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   6.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   6.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   7.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   7.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   7.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   7.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   7.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   7.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   7.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   4.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   4.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   4.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   4.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   5.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   4.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   5.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   7.0s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   7.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   8.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   8.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   8.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   8.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   8.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   8.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   9.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   9.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   4.9s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   4.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   5.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   5.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   5.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   5.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   5.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   5.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   5.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   5.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   2.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   3.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   5.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   5.2s\n",
      "[flaml.tune.tune: 06-10 14:08:36] {202} INFO - result: {'pred_time': 5.4023551940917966e-05, 'wall_clock_time': 94.41615343093872, 'metric_for_logging': {'pred_time': 5.4023551940917966e-05}, 'val_loss': 0.2513333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b39da80>, 'training_iteration': 0, 'config': {'n_estimators': 1273, 'max_features': 0.6327945777804539, 'max_leaves': 1774, 'criterion': 'entropy'}, 'config/n_estimators': 1273, 'config/max_features': 0.6327945777804539, 'config/max_leaves': 1774, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 56.98538422584534}\n",
      "[flaml.tune.tune: 06-10 14:08:36] {202} INFO - result: {'pred_time': 5.4023551940917966e-05, 'wall_clock_time': 94.41615343093872, 'metric_for_logging': {'pred_time': 5.4023551940917966e-05}, 'val_loss': 0.2513333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402b39da80>, 'training_iteration': 1, 'config': {'n_estimators': 1273, 'max_features': 0.6327945777804539, 'max_leaves': 1774, 'criterion': 'entropy'}, 'config/n_estimators': 1273, 'config/max_features': 0.6327945777804539, 'config/max_leaves': 1774, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 56.98652529716492}\n",
      "[flaml.automl.logger: 06-10 14:08:36] {2392} INFO -  at 94.4s,\testimator rf's best error=0.2513,\tbest estimator rf's best error=0.2513\n",
      "[flaml.automl.logger: 06-10 14:08:36] {2219} INFO - iteration 40, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:08:36] {811} INFO - trial 1 config: {'n_estimators': 177, 'max_features': 0.2540226154742947, 'max_leaves': 836, 'criterion': 'entropy'}\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   9.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   9.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=1, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   2.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   5.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   9.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.0s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.7s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   9.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=1, min_samples_split=2; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=3, max_features=5, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=1, min_samples_split=2; total time=   0.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.1s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=3, max_features=5, min_samples_split=4; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=None, max_features=5, min_samples_split=2; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=None, max_features=5, min_samples_split=4; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   1.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   2.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=2; total time=   3.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=   5.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=None, max_features=5, min_samples_split=4; total time=  10.0s\n",
      "[flaml.tune.tune: 06-10 14:08:41] {202} INFO - result: {'pred_time': 1.2243366241455079e-05, 'wall_clock_time': 99.29151272773743, 'metric_for_logging': {'pred_time': 1.2243366241455079e-05}, 'val_loss': 0.26746666666666663, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bdb0d0>, 'training_iteration': 0, 'config': {'n_estimators': 177, 'max_features': 0.2540226154742947, 'max_leaves': 836, 'criterion': 'entropy'}, 'config/n_estimators': 177, 'config/max_features': 0.2540226154742947, 'config/max_leaves': 836, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.8692920207977295}\n",
      "[flaml.tune.tune: 06-10 14:08:41] {202} INFO - result: {'pred_time': 1.2243366241455079e-05, 'wall_clock_time': 99.29151272773743, 'metric_for_logging': {'pred_time': 1.2243366241455079e-05}, 'val_loss': 0.26746666666666663, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241bdb0d0>, 'training_iteration': 1, 'config': {'n_estimators': 177, 'max_features': 0.2540226154742947, 'max_leaves': 836, 'criterion': 'entropy'}, 'config/n_estimators': 177, 'config/max_features': 0.2540226154742947, 'config/max_leaves': 836, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 4.870694637298584}\n",
      "[flaml.automl.logger: 06-10 14:08:41] {2392} INFO -  at 99.3s,\testimator rf's best error=0.2513,\tbest estimator rf's best error=0.2513\n",
      "[flaml.automl.logger: 06-10 14:08:41] {2219} INFO - iteration 41, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:08:41] {811} INFO - trial 1 config: {'n_estimators': 2047, 'max_features': 0.3481635024968786, 'max_leaves': 10, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:09:03] {202} INFO - result: {'pred_time': 7.270164489746093e-05, 'wall_clock_time': 122.13113951683044, 'metric_for_logging': {'pred_time': 7.270164489746093e-05}, 'val_loss': 0.5510666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241582500>, 'training_iteration': 0, 'config': {'n_estimators': 2047, 'max_features': 0.3481635024968786, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 2047, 'config/max_features': 0.3481635024968786, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 22.833807229995728}\n",
      "[flaml.tune.tune: 06-10 14:09:03] {202} INFO - result: {'pred_time': 7.270164489746093e-05, 'wall_clock_time': 122.13113951683044, 'metric_for_logging': {'pred_time': 7.270164489746093e-05}, 'val_loss': 0.5510666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4241582500>, 'training_iteration': 1, 'config': {'n_estimators': 2047, 'max_features': 0.3481635024968786, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 2047, 'config/max_features': 0.3481635024968786, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 22.835847854614258}\n",
      "[flaml.automl.logger: 06-10 14:09:03] {2392} INFO -  at 122.1s,\testimator rf's best error=0.2513,\tbest estimator rf's best error=0.2513\n",
      "[flaml.automl.logger: 06-10 14:09:03] {2219} INFO - iteration 42, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:09:03] {811} INFO - trial 1 config: {'n_estimators': 299, 'max_features': 1.0, 'max_leaves': 17499, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:09:18] {202} INFO - result: {'pred_time': 1.5897814432779948e-05, 'wall_clock_time': 136.76343035697937, 'metric_for_logging': {'pred_time': 1.5897814432779948e-05}, 'val_loss': 0.2554666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f424102ca30>, 'training_iteration': 0, 'config': {'n_estimators': 299, 'max_features': 1.0, 'max_leaves': 17499, 'criterion': 'gini'}, 'config/n_estimators': 299, 'config/max_features': 1.0, 'config/max_leaves': 17499, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 14.623213768005371}\n",
      "[flaml.tune.tune: 06-10 14:09:18] {202} INFO - result: {'pred_time': 1.5897814432779948e-05, 'wall_clock_time': 136.76343035697937, 'metric_for_logging': {'pred_time': 1.5897814432779948e-05}, 'val_loss': 0.2554666666666666, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f424102ca30>, 'training_iteration': 1, 'config': {'n_estimators': 299, 'max_features': 1.0, 'max_leaves': 17499, 'criterion': 'gini'}, 'config/n_estimators': 299, 'config/max_features': 1.0, 'config/max_leaves': 17499, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 14.625090599060059}\n",
      "[flaml.automl.logger: 06-10 14:09:18] {2392} INFO -  at 136.8s,\testimator rf's best error=0.2513,\tbest estimator rf's best error=0.2513\n",
      "[flaml.automl.logger: 06-10 14:09:18] {2494} INFO - selected model: RandomForestClassifier(criterion='entropy', max_features=0.6327945777804539,\n",
      "                       max_leaf_nodes=1774, n_estimators=1273, n_jobs=-1,\n",
      "                       random_state=12032022)\n",
      "[flaml.automl.logger: 06-10 14:09:18] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-10 14:09:18] {1932} INFO - Time taken to find the best model: 94.41615343093872\n",
      "Best hyper-parmeter config: {'n_estimators': 1273, 'max_features': 0.6327945777804539, 'max_leaves': 1774, 'criterion': 'entropy'}\n",
      "Best accuracy on validation data: 0.7487\n",
      "Training duration of best run: 56.99 s\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:17:00.357648Z",
     "start_time": "2024-06-10T14:13:51.922923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from flaml import AutoML\n",
    "from flaml.automl.model import RandomForestEstimator, XGBoostEstimator\n",
    "\n",
    "automl = AutoML()\n",
    "# automl.add_learner('rf', RandomForestEstimator)\n",
    "# automl.add_learner('xgboost', XGBoostEstimator)\n",
    "\n",
    "settings = {\n",
    "    \"time_budget\": 180,  # total running time in seconds\n",
    "    # \"metric\": custom_metric,\n",
    "    \"metric\": 'accuracy',\n",
    "    \"estimator_list\": ['rf', 'xgboost', 'extra_tree', 'lrl1'],\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"log_file_name\": 'flaml_experiment.log',  # flaml log file\n",
    "    \"X_val\": X_val,\n",
    "    \"y_val\": y_val,\n",
    "    \"verbose\": 10,\n",
    "}\n",
    "\n",
    "automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "print('Best hyper-parmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1 - automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ],
   "id": "980699727e6f0b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 06-10 14:13:51] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 06-10 14:13:51] {1688} INFO - Data split method: stratified\n",
      "[flaml.automl.logger: 06-10 14:13:51] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 06-10 14:13:51] {1789} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 06-10 14:13:51] {1901} INFO - List of ML learners in AutoML Run: ['rf', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl.logger: 06-10 14:13:51] {2219} INFO - iteration 0, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:13:51] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 2.068964640299479e-06, 'wall_clock_time': 0.36884593963623047, 'metric_for_logging': {'pred_time': 2.068964640299479e-06}, 'val_loss': 0.7163999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b00d0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.35088443756103516}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 2.068964640299479e-06, 'wall_clock_time': 0.36884593963623047, 'metric_for_logging': {'pred_time': 2.068964640299479e-06}, 'val_loss': 0.7163999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b00d0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.3516364097595215}\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2345} INFO - Estimated sufficient time budget=3535s. Estimated necessary time budget=29s.\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2392} INFO -  at 0.4s,\testimator rf's best error=0.7164,\tbest estimator rf's best error=0.7164\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2219} INFO - iteration 1, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:52] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 3.0221939086914064e-07, 'wall_clock_time': 0.8511574268341064, 'metric_for_logging': {'pred_time': 3.0221939086914064e-07}, 'val_loss': 0.6074666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b0220>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.09999999999999995, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 0.47738075256347656}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 3.0221939086914064e-07, 'wall_clock_time': 0.8511574268341064, 'metric_for_logging': {'pred_time': 3.0221939086914064e-07}, 'val_loss': 0.6074666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b0220>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.9999999999999993, 'config/learning_rate': 0.09999999999999995, 'config/subsample': 1.0, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 1.0, 'experiment_tag': 'exp', 'time_total_s': 0.4783210754394531}\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2392} INFO -  at 0.9s,\testimator xgboost's best error=0.6075,\tbest estimator xgboost's best error=0.6075\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2219} INFO - iteration 2, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:13:52] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 2.1651585896809896e-06, 'wall_clock_time': 0.9450867176055908, 'metric_for_logging': {'pred_time': 2.1651585896809896e-06}, 'val_loss': 0.7942666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b2d10>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.08924221992492676}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 2.1651585896809896e-06, 'wall_clock_time': 0.9450867176055908, 'metric_for_logging': {'pred_time': 2.1651585896809896e-06}, 'val_loss': 0.7942666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b2d10>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.08986353874206543}\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2392} INFO -  at 0.9s,\testimator extra_tree's best error=0.7943,\tbest estimator xgboost's best error=0.6075\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2219} INFO - iteration 3, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:13:52] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 2.033360799153646e-06, 'wall_clock_time': 1.04329514503479, 'metric_for_logging': {'pred_time': 2.033360799153646e-06}, 'val_loss': 0.6737333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d39d0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624973, 'config/max_leaves': 12, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.0944509506225586}\n",
      "[flaml.tune.tune: 06-10 14:13:52] {202} INFO - result: {'pred_time': 2.033360799153646e-06, 'wall_clock_time': 1.04329514503479, 'metric_for_logging': {'pred_time': 2.033360799153646e-06}, 'val_loss': 0.6737333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d39d0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624973, 'config/max_leaves': 12, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.09502267837524414}\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2392} INFO -  at 1.0s,\testimator extra_tree's best error=0.6737,\tbest estimator xgboost's best error=0.6075\n",
      "[flaml.automl.logger: 06-10 14:13:52] {2219} INFO - iteration 4, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:13:52] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.0709355672200523e-06, 'wall_clock_time': 1.1310021877288818, 'metric_for_logging': {'pred_time': 2.0709355672200523e-06}, 'val_loss': 0.7641333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240963eb0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.08463048934936523}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.0709355672200523e-06, 'wall_clock_time': 1.1310021877288818, 'metric_for_logging': {'pred_time': 2.0709355672200523e-06}, 'val_loss': 0.7641333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240963eb0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.08523368835449219}\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2392} INFO -  at 1.1s,\testimator extra_tree's best error=0.6737,\tbest estimator xgboost's best error=0.6075\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2219} INFO - iteration 5, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:13:53] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.1177927652994793e-06, 'wall_clock_time': 1.360778570175171, 'metric_for_logging': {'pred_time': 2.1177927652994793e-06}, 'val_loss': 0.6106666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b3d60>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624973, 'config/max_leaves': 12, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.22656607627868652}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.1177927652994793e-06, 'wall_clock_time': 1.360778570175171, 'metric_for_logging': {'pred_time': 2.1177927652994793e-06}, 'val_loss': 0.6106666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b3d60>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624973, 'max_leaves': 12, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624973, 'config/max_leaves': 12, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2272024154663086}\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2392} INFO -  at 1.4s,\testimator rf's best error=0.6107,\tbest estimator xgboost's best error=0.6075\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2219} INFO - iteration 6, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:13:53] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.169958750406901e-06, 'wall_clock_time': 1.5400545597076416, 'metric_for_logging': {'pred_time': 2.169958750406901e-06}, 'val_loss': 0.7196, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409d1000>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17617201805114746}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.169958750406901e-06, 'wall_clock_time': 1.5400545597076416, 'metric_for_logging': {'pred_time': 2.169958750406901e-06}, 'val_loss': 0.7196, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409d1000>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17677669529663687, 'max_leaves': 4, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.17677669529663687, 'config/max_leaves': 4, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17681074142456055}\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2392} INFO -  at 1.5s,\testimator rf's best error=0.6107,\tbest estimator xgboost's best error=0.6075\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2219} INFO - iteration 7, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:13:53] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.3049354553222657e-06, 'wall_clock_time': 2.024233102798462, 'metric_for_logging': {'pred_time': 2.3049354553222657e-06}, 'val_loss': 0.5831999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240962740>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.11297795568850721, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.48108959197998047}\n",
      "[flaml.tune.tune: 06-10 14:13:53] {202} INFO - result: {'pred_time': 2.3049354553222657e-06, 'wall_clock_time': 2.024233102798462, 'metric_for_logging': {'pred_time': 2.3049354553222657e-06}, 'val_loss': 0.5831999999999999, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240962740>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.11297795568850721, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4818458557128906}\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2392} INFO -  at 2.0s,\testimator rf's best error=0.5832,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:13:53] {2219} INFO - iteration 8, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:13:53] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.17133249602624967, 'max_leaves': 12, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:13:54] {202} INFO - result: {'pred_time': 2.0592053731282552e-06, 'wall_clock_time': 2.469054937362671, 'metric_for_logging': {'pred_time': 2.0592053731282552e-06}, 'val_loss': 0.6150666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409bd9f0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624967, 'max_leaves': 12, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624967, 'config/max_leaves': 12, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4408848285675049}\n",
      "[flaml.tune.tune: 06-10 14:13:54] {202} INFO - result: {'pred_time': 2.0592053731282552e-06, 'wall_clock_time': 2.469054937362671, 'metric_for_logging': {'pred_time': 2.0592053731282552e-06}, 'val_loss': 0.6150666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409bd9f0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.17133249602624967, 'max_leaves': 12, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.17133249602624967, 'config/max_leaves': 12, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.44162917137145996}\n",
      "[flaml.automl.logger: 06-10 14:13:54] {2392} INFO -  at 2.5s,\testimator rf's best error=0.5832,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:13:54] {2219} INFO - iteration 9, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:13:54] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.11262915120101383, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:13:54] {202} INFO - result: {'pred_time': 2.539698282877604e-06, 'wall_clock_time': 2.9197030067443848, 'metric_for_logging': {'pred_time': 2.539698282877604e-06}, 'val_loss': 0.6009333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409d0130>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.11262915120101383, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.11262915120101383, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.44766998291015625}\n",
      "[flaml.tune.tune: 06-10 14:13:54] {202} INFO - result: {'pred_time': 2.539698282877604e-06, 'wall_clock_time': 2.9197030067443848, 'metric_for_logging': {'pred_time': 2.539698282877604e-06}, 'val_loss': 0.6009333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409d0130>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.11262915120101383, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.11262915120101383, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.44843578338623047}\n",
      "[flaml.automl.logger: 06-10 14:13:54] {2392} INFO -  at 2.9s,\testimator rf's best error=0.5832,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:13:54] {2219} INFO - iteration 10, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:54] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}\n",
      "[flaml.tune.tune: 06-10 14:13:54] {202} INFO - result: {'pred_time': 3.0962626139322916e-07, 'wall_clock_time': 3.0033557415008545, 'metric_for_logging': {'pred_time': 3.0962626139322916e-07}, 'val_loss': 0.6094666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1f60>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.03859136192132085, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 0.08035397529602051}\n",
      "[flaml.tune.tune: 06-10 14:13:54] {202} INFO - result: {'pred_time': 3.0962626139322916e-07, 'wall_clock_time': 3.0033557415008545, 'metric_for_logging': {'pred_time': 3.0962626139322916e-07}, 'val_loss': 0.6094666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1f60>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 3.815612027960909, 'learning_rate': 0.03859136192132085, 'subsample': 1.0, 'colsample_bylevel': 0.8148474110627004, 'colsample_bytree': 0.9777234800442423, 'reg_alpha': 0.0009765625, 'reg_lambda': 5.525802807180917}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 3.815612027960909, 'config/learning_rate': 0.03859136192132085, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8148474110627004, 'config/colsample_bytree': 0.9777234800442423, 'config/reg_alpha': 0.0009765625, 'config/reg_lambda': 5.525802807180917, 'experiment_tag': 'exp', 'time_total_s': 0.08122897148132324}\n",
      "[flaml.automl.logger: 06-10 14:13:54] {2392} INFO -  at 3.0s,\testimator xgboost's best error=0.6075,\tbest estimator rf's best error=0.5832\n",
      "[flaml.automl.logger: 06-10 14:13:54] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:54] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.376007080078125e-07, 'wall_clock_time': 3.085754871368408, 'metric_for_logging': {'pred_time': 3.376007080078125e-07}, 'val_loss': 0.5714666666666667, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1c90>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25912534572860507, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 0.078369140625}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.376007080078125e-07, 'wall_clock_time': 3.085754871368408, 'metric_for_logging': {'pred_time': 3.376007080078125e-07}, 'val_loss': 0.5714666666666667, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1c90>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25912534572860507, 'subsample': 0.9266743941610592, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292954}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25912534572860507, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292954, 'experiment_tag': 'exp', 'time_total_s': 0.07928013801574707}\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2392} INFO -  at 3.1s,\testimator xgboost's best error=0.5715,\tbest estimator xgboost's best error=0.5715\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:55] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.1458536783854164e-07, 'wall_clock_time': 3.1687753200531006, 'metric_for_logging': {'pred_time': 3.1458536783854164e-07}, 'val_loss': 0.5609333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b2da0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 0.07894611358642578}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.1458536783854164e-07, 'wall_clock_time': 3.1687753200531006, 'metric_for_logging': {'pred_time': 3.1458536783854164e-07}, 'val_loss': 0.5609333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b2da0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 1.8630223791106992, 'learning_rate': 1.0, 'subsample': 0.8513627344387318, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.946138073111236, 'reg_alpha': 0.0018311776973217071, 'reg_lambda': 0.27901659190538414}, 'config/n_estimators': 4, 'config/max_leaves': 4, 'config/min_child_weight': 1.8630223791106992, 'config/learning_rate': 1.0, 'config/subsample': 0.8513627344387318, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.946138073111236, 'config/reg_alpha': 0.0018311776973217071, 'config/reg_lambda': 0.27901659190538414, 'experiment_tag': 'exp', 'time_total_s': 0.07987213134765625}\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2392} INFO -  at 3.2s,\testimator xgboost's best error=0.5609,\tbest estimator xgboost's best error=0.5609\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:55] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.1916300455729167e-07, 'wall_clock_time': 3.2923829555511475, 'metric_for_logging': {'pred_time': 3.1916300455729167e-07}, 'val_loss': 0.4736, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b3b50>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 0.11972928047180176}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.1916300455729167e-07, 'wall_clock_time': 3.2923829555511475, 'metric_for_logging': {'pred_time': 3.1916300455729167e-07}, 'val_loss': 0.4736, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b3b50>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144255, 'reg_lambda': 0.18096917948292968}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144255, 'config/reg_lambda': 0.18096917948292968, 'experiment_tag': 'exp', 'time_total_s': 0.12055206298828125}\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2392} INFO -  at 3.3s,\testimator xgboost's best error=0.4736,\tbest estimator xgboost's best error=0.4736\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2219} INFO - iteration 14, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:55] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.1458536783854164e-07, 'wall_clock_time': 3.4086461067199707, 'metric_for_logging': {'pred_time': 3.1458536783854164e-07}, 'val_loss': 0.47173333333333334, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b3eb0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.13674064538052125, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.735249880070874, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.4131495174987749, 'experiment_tag': 'exp', 'time_total_s': 0.11226987838745117}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.1458536783854164e-07, 'wall_clock_time': 3.4086461067199707, 'metric_for_logging': {'pred_time': 3.1458536783854164e-07}, 'val_loss': 0.47173333333333334, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b3eb0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_leaves': 8, 'min_child_weight': 0.08262716617929555, 'learning_rate': 0.13674064538052125, 'subsample': 0.8885937069868678, 'colsample_bylevel': 0.735249880070874, 'colsample_bytree': 0.8648827061331837, 'reg_alpha': 0.0018753066867999496, 'reg_lambda': 0.4131495174987749}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/min_child_weight': 0.08262716617929555, 'config/learning_rate': 0.13674064538052125, 'config/subsample': 0.8885937069868678, 'config/colsample_bylevel': 0.735249880070874, 'config/colsample_bytree': 0.8648827061331837, 'config/reg_alpha': 0.0018753066867999496, 'config/reg_lambda': 0.4131495174987749, 'experiment_tag': 'exp', 'time_total_s': 0.11314630508422852}\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2392} INFO -  at 3.4s,\testimator xgboost's best error=0.4717,\tbest estimator xgboost's best error=0.4717\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2219} INFO - iteration 15, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:55] {811} INFO - trial 1 config: {'n_estimators': 12, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.494580586751302e-07, 'wall_clock_time': 3.710733652114868, 'metric_for_logging': {'pred_time': 3.494580586751302e-07}, 'val_loss': 0.41613333333333336, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1450>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}, 'config/n_estimators': 12, 'config/max_leaves': 8, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292982, 'experiment_tag': 'exp', 'time_total_s': 0.2982149124145508}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 3.494580586751302e-07, 'wall_clock_time': 3.710733652114868, 'metric_for_logging': {'pred_time': 3.494580586751302e-07}, 'val_loss': 0.41613333333333336, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1450>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_leaves': 8, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9266743941610592, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292982}, 'config/n_estimators': 12, 'config/max_leaves': 8, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9266743941610592, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292982, 'experiment_tag': 'exp', 'time_total_s': 0.2991347312927246}\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2392} INFO -  at 3.7s,\testimator xgboost's best error=0.4161,\tbest estimator xgboost's best error=0.4161\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2219} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:13:55] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 2.2757212320963543e-06, 'wall_clock_time': 3.8358805179595947, 'metric_for_logging': {'pred_time': 2.2757212320963543e-06}, 'val_loss': 0.6905333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b2bc0>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.11297795568850721, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.12110233306884766}\n",
      "[flaml.tune.tune: 06-10 14:13:55] {202} INFO - result: {'pred_time': 2.2757212320963543e-06, 'wall_clock_time': 3.8358805179595947, 'metric_for_logging': {'pred_time': 2.2757212320963543e-06}, 'val_loss': 0.6905333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b2bc0>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.11297795568850721, 'max_leaves': 10, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.11297795568850721, 'config/max_leaves': 10, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.12181496620178223}\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2392} INFO -  at 3.8s,\testimator extra_tree's best error=0.6737,\tbest estimator xgboost's best error=0.4161\n",
      "[flaml.automl.logger: 06-10 14:13:55] {2219} INFO - iteration 17, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:55] {811} INFO - trial 1 config: {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}\n",
      "[flaml.tune.tune: 06-10 14:13:56] {202} INFO - result: {'pred_time': 3.902435302734375e-07, 'wall_clock_time': 4.24640679359436, 'metric_for_logging': {'pred_time': 3.902435302734375e-07}, 'val_loss': 0.3658666666666667, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d2860>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}, 'config/n_estimators': 23, 'config/max_leaves': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796909, 'experiment_tag': 'exp', 'time_total_s': 0.4073638916015625}\n",
      "[flaml.tune.tune: 06-10 14:13:56] {202} INFO - result: {'pred_time': 3.902435302734375e-07, 'wall_clock_time': 4.24640679359436, 'metric_for_logging': {'pred_time': 3.902435302734375e-07}, 'val_loss': 0.3658666666666667, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d2860>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 1.0, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644693, 'reg_lambda': 0.8085739292796909}, 'config/n_estimators': 23, 'config/max_leaves': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644693, 'config/reg_lambda': 0.8085739292796909, 'experiment_tag': 'exp', 'time_total_s': 0.4082643985748291}\n",
      "[flaml.automl.logger: 06-10 14:13:56] {2392} INFO -  at 4.2s,\testimator xgboost's best error=0.3659,\tbest estimator xgboost's best error=0.3659\n",
      "[flaml.automl.logger: 06-10 14:13:56] {2219} INFO - iteration 18, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:56] {811} INFO - trial 1 config: {'n_estimators': 12, 'max_leaves': 9, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}\n",
      "[flaml.tune.tune: 06-10 14:13:56] {202} INFO - result: {'pred_time': 3.5610198974609376e-07, 'wall_clock_time': 4.564617872238159, 'metric_for_logging': {'pred_time': 3.5610198974609376e-07}, 'val_loss': 0.3986666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d1db0>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_leaves': 9, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}, 'config/n_estimators': 12, 'config/max_leaves': 9, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292995, 'experiment_tag': 'exp', 'time_total_s': 0.3141961097717285}\n",
      "[flaml.tune.tune: 06-10 14:13:56] {202} INFO - result: {'pred_time': 3.5610198974609376e-07, 'wall_clock_time': 4.564617872238159, 'metric_for_logging': {'pred_time': 3.5610198974609376e-07}, 'val_loss': 0.3986666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d1db0>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_leaves': 9, 'min_child_weight': 0.26208115308159446, 'learning_rate': 0.25775724472262795, 'subsample': 0.9079647052885418, 'colsample_bylevel': 0.9168331919232143, 'colsample_bytree': 1.0, 'reg_alpha': 0.0013933617380144253, 'reg_lambda': 0.18096917948292995}, 'config/n_estimators': 12, 'config/max_leaves': 9, 'config/min_child_weight': 0.26208115308159446, 'config/learning_rate': 0.25775724472262795, 'config/subsample': 0.9079647052885418, 'config/colsample_bylevel': 0.9168331919232143, 'config/colsample_bytree': 1.0, 'config/reg_alpha': 0.0013933617380144253, 'config/reg_lambda': 0.18096917948292995, 'experiment_tag': 'exp', 'time_total_s': 0.3150820732116699}\n",
      "[flaml.automl.logger: 06-10 14:13:56] {2392} INFO -  at 4.6s,\testimator xgboost's best error=0.3659,\tbest estimator xgboost's best error=0.3659\n",
      "[flaml.automl.logger: 06-10 14:13:56] {2219} INFO - iteration 19, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:56] {811} INFO - trial 1 config: {'n_estimators': 22, 'max_leaves': 18, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}\n",
      "[flaml.tune.tune: 06-10 14:13:57] {202} INFO - result: {'pred_time': 5.272547403971354e-07, 'wall_clock_time': 5.392204999923706, 'metric_for_logging': {'pred_time': 5.272547403971354e-07}, 'val_loss': 0.3090666666666667, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d0910>, 'training_iteration': 0, 'config': {'n_estimators': 22, 'max_leaves': 18, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}, 'config/n_estimators': 22, 'config/max_leaves': 18, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 0.8060470431177518, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8256882078026019, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365184, 'experiment_tag': 'exp', 'time_total_s': 0.8238558769226074}\n",
      "[flaml.tune.tune: 06-10 14:13:57] {202} INFO - result: {'pred_time': 5.272547403971354e-07, 'wall_clock_time': 5.392204999923706, 'metric_for_logging': {'pred_time': 5.272547403971354e-07}, 'val_loss': 0.3090666666666667, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d0910>, 'training_iteration': 1, 'config': {'n_estimators': 22, 'max_leaves': 18, 'min_child_weight': 0.7694377042261122, 'learning_rate': 0.8060470431177518, 'subsample': 1.0, 'colsample_bylevel': 0.8256882078026019, 'colsample_bytree': 0.7967145599266738, 'reg_alpha': 0.058176484040363505, 'reg_lambda': 4.081433281365184}, 'config/n_estimators': 22, 'config/max_leaves': 18, 'config/min_child_weight': 0.7694377042261122, 'config/learning_rate': 0.8060470431177518, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8256882078026019, 'config/colsample_bytree': 0.7967145599266738, 'config/reg_alpha': 0.058176484040363505, 'config/reg_lambda': 4.081433281365184, 'experiment_tag': 'exp', 'time_total_s': 0.8247554302215576}\n",
      "[flaml.automl.logger: 06-10 14:13:57] {2392} INFO -  at 5.4s,\testimator xgboost's best error=0.3091,\tbest estimator xgboost's best error=0.3091\n",
      "[flaml.automl.logger: 06-10 14:13:57] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:57] {811} INFO - trial 1 config: {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}\n",
      "[flaml.tune.tune: 06-10 14:13:57] {202} INFO - result: {'pred_time': 3.881136576334635e-07, 'wall_clock_time': 5.811646938323975, 'metric_for_logging': {'pred_time': 3.881136576334635e-07}, 'val_loss': 0.35973333333333335, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d0250>, 'training_iteration': 0, 'config': {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}, 'config/n_estimators': 23, 'config/max_leaves': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796903, 'experiment_tag': 'exp', 'time_total_s': 0.41495800018310547}\n",
      "[flaml.tune.tune: 06-10 14:13:57] {202} INFO - result: {'pred_time': 3.881136576334635e-07, 'wall_clock_time': 5.811646938323975, 'metric_for_logging': {'pred_time': 3.881136576334635e-07}, 'val_loss': 0.35973333333333335, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d0250>, 'training_iteration': 1, 'config': {'n_estimators': 23, 'max_leaves': 6, 'min_child_weight': 0.533808799890526, 'learning_rate': 0.6618201818236865, 'subsample': 0.9661106209889765, 'colsample_bylevel': 0.7979503033535307, 'colsample_bytree': 0.8499027725496043, 'reg_alpha': 0.0022617568611644698, 'reg_lambda': 0.8085739292796903}, 'config/n_estimators': 23, 'config/max_leaves': 6, 'config/min_child_weight': 0.533808799890526, 'config/learning_rate': 0.6618201818236865, 'config/subsample': 0.9661106209889765, 'config/colsample_bylevel': 0.7979503033535307, 'config/colsample_bytree': 0.8499027725496043, 'config/reg_alpha': 0.0022617568611644698, 'config/reg_lambda': 0.8085739292796903, 'experiment_tag': 'exp', 'time_total_s': 0.4158473014831543}\n",
      "[flaml.automl.logger: 06-10 14:13:57] {2392} INFO -  at 5.8s,\testimator xgboost's best error=0.3091,\tbest estimator xgboost's best error=0.3091\n",
      "[flaml.automl.logger: 06-10 14:13:57] {2219} INFO - iteration 21, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:57] {811} INFO - trial 1 config: {'n_estimators': 11, 'max_leaves': 13, 'min_child_weight': 0.15023279902189693, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.7816755498175155, 'colsample_bytree': 0.8954074711475323, 'reg_alpha': 0.16394177411347696, 'reg_lambda': 11.791813911233042}\n",
      "[flaml.tune.tune: 06-10 14:13:58] {202} INFO - result: {'pred_time': 3.8369496663411457e-07, 'wall_clock_time': 6.208905220031738, 'metric_for_logging': {'pred_time': 3.8369496663411457e-07}, 'val_loss': 0.33333333333333337, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d0850>, 'training_iteration': 0, 'config': {'n_estimators': 11, 'max_leaves': 13, 'min_child_weight': 0.15023279902189693, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.7816755498175155, 'colsample_bytree': 0.8954074711475323, 'reg_alpha': 0.16394177411347696, 'reg_lambda': 11.791813911233042}, 'config/n_estimators': 11, 'config/max_leaves': 13, 'config/min_child_weight': 0.15023279902189693, 'config/learning_rate': 1.0, 'config/subsample': 0.8286310106576346, 'config/colsample_bylevel': 0.7816755498175155, 'config/colsample_bytree': 0.8954074711475323, 'config/reg_alpha': 0.16394177411347696, 'config/reg_lambda': 11.791813911233042, 'experiment_tag': 'exp', 'time_total_s': 0.39354777336120605}\n",
      "[flaml.tune.tune: 06-10 14:13:58] {202} INFO - result: {'pred_time': 3.8369496663411457e-07, 'wall_clock_time': 6.208905220031738, 'metric_for_logging': {'pred_time': 3.8369496663411457e-07}, 'val_loss': 0.33333333333333337, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d0850>, 'training_iteration': 1, 'config': {'n_estimators': 11, 'max_leaves': 13, 'min_child_weight': 0.15023279902189693, 'learning_rate': 1.0, 'subsample': 0.8286310106576346, 'colsample_bylevel': 0.7816755498175155, 'colsample_bytree': 0.8954074711475323, 'reg_alpha': 0.16394177411347696, 'reg_lambda': 11.791813911233042}, 'config/n_estimators': 11, 'config/max_leaves': 13, 'config/min_child_weight': 0.15023279902189693, 'config/learning_rate': 1.0, 'config/subsample': 0.8286310106576346, 'config/colsample_bylevel': 0.7816755498175155, 'config/colsample_bytree': 0.8954074711475323, 'config/reg_alpha': 0.16394177411347696, 'config/reg_lambda': 11.791813911233042, 'experiment_tag': 'exp', 'time_total_s': 0.39453125}\n",
      "[flaml.automl.logger: 06-10 14:13:58] {2392} INFO -  at 6.2s,\testimator xgboost's best error=0.3091,\tbest estimator xgboost's best error=0.3091\n",
      "[flaml.automl.logger: 06-10 14:13:58] {2219} INFO - iteration 22, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:13:58] {811} INFO - trial 1 config: {'n_estimators': 43, 'max_leaves': 25, 'min_child_weight': 3.940779806668313, 'learning_rate': 0.5169621222429032, 'subsample': 1.0, 'colsample_bylevel': 0.8697008657876882, 'colsample_bytree': 0.6980216487058154, 'reg_alpha': 0.020644544769632598, 'reg_lambda': 1.4126832186833143}\n",
      "[flaml.tune.tune: 06-10 14:14:00] {202} INFO - result: {'pred_time': 7.940928141276042e-07, 'wall_clock_time': 8.2720468044281, 'metric_for_logging': {'pred_time': 7.940928141276042e-07}, 'val_loss': 0.28759999999999997, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d2650>, 'training_iteration': 0, 'config': {'n_estimators': 43, 'max_leaves': 25, 'min_child_weight': 3.940779806668313, 'learning_rate': 0.5169621222429032, 'subsample': 1.0, 'colsample_bylevel': 0.8697008657876882, 'colsample_bytree': 0.6980216487058154, 'reg_alpha': 0.020644544769632598, 'reg_lambda': 1.4126832186833143}, 'config/n_estimators': 43, 'config/max_leaves': 25, 'config/min_child_weight': 3.940779806668313, 'config/learning_rate': 0.5169621222429032, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8697008657876882, 'config/colsample_bytree': 0.6980216487058154, 'config/reg_alpha': 0.020644544769632598, 'config/reg_lambda': 1.4126832186833143, 'experiment_tag': 'exp', 'time_total_s': 2.0594465732574463}\n",
      "[flaml.tune.tune: 06-10 14:14:00] {202} INFO - result: {'pred_time': 7.940928141276042e-07, 'wall_clock_time': 8.2720468044281, 'metric_for_logging': {'pred_time': 7.940928141276042e-07}, 'val_loss': 0.28759999999999997, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409d2650>, 'training_iteration': 1, 'config': {'n_estimators': 43, 'max_leaves': 25, 'min_child_weight': 3.940779806668313, 'learning_rate': 0.5169621222429032, 'subsample': 1.0, 'colsample_bylevel': 0.8697008657876882, 'colsample_bytree': 0.6980216487058154, 'reg_alpha': 0.020644544769632598, 'reg_lambda': 1.4126832186833143}, 'config/n_estimators': 43, 'config/max_leaves': 25, 'config/min_child_weight': 3.940779806668313, 'config/learning_rate': 0.5169621222429032, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.8697008657876882, 'config/colsample_bytree': 0.6980216487058154, 'config/reg_alpha': 0.020644544769632598, 'config/reg_lambda': 1.4126832186833143, 'experiment_tag': 'exp', 'time_total_s': 2.060394525527954}\n",
      "[flaml.automl.logger: 06-10 14:14:00] {2392} INFO -  at 8.3s,\testimator xgboost's best error=0.2876,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:00] {2219} INFO - iteration 23, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:00] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.25982789311146137, 'max_leaves': 14, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:00] {202} INFO - result: {'pred_time': 2.1719614664713542e-06, 'wall_clock_time': 8.377066373825073, 'metric_for_logging': {'pred_time': 2.1719614664713542e-06}, 'val_loss': 0.5889333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d2440>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.25982789311146137, 'max_leaves': 14, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.25982789311146137, 'config/max_leaves': 14, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.10063791275024414}\n",
      "[flaml.tune.tune: 06-10 14:14:00] {202} INFO - result: {'pred_time': 2.1719614664713542e-06, 'wall_clock_time': 8.377066373825073, 'metric_for_logging': {'pred_time': 2.1719614664713542e-06}, 'val_loss': 0.5889333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d2440>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.25982789311146137, 'max_leaves': 14, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.25982789311146137, 'config/max_leaves': 14, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.10128498077392578}\n",
      "[flaml.automl.logger: 06-10 14:14:00] {2392} INFO -  at 8.4s,\testimator extra_tree's best error=0.5889,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:00] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:00] {811} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.2590257088752454, 'max_leaves': 8, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:00] {202} INFO - result: {'pred_time': 2.3482958475748697e-06, 'wall_clock_time': 8.507477760314941, 'metric_for_logging': {'pred_time': 2.3482958475748697e-06}, 'val_loss': 0.5985333333333334, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240961a50>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.2590257088752454, 'max_leaves': 8, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.2590257088752454, 'config/max_leaves': 8, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.12723851203918457}\n",
      "[flaml.tune.tune: 06-10 14:14:00] {202} INFO - result: {'pred_time': 2.3482958475748697e-06, 'wall_clock_time': 8.507477760314941, 'metric_for_logging': {'pred_time': 2.3482958475748697e-06}, 'val_loss': 0.5985333333333334, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240961a50>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.2590257088752454, 'max_leaves': 8, 'criterion': 'gini'}, 'config/n_estimators': 8, 'config/max_features': 0.2590257088752454, 'config/max_leaves': 8, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.1279759407043457}\n",
      "[flaml.automl.logger: 06-10 14:14:00] {2392} INFO -  at 8.5s,\testimator extra_tree's best error=0.5889,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:00] {2219} INFO - iteration 25, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:14:00] {811} INFO - trial 1 config: {'n_estimators': 13, 'max_leaves': 53, 'min_child_weight': 3.315670565896274, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7429418788184767, 'reg_alpha': 0.06408898861750664, 'reg_lambda': 0.7793954798138993}\n",
      "[flaml.tune.tune: 06-10 14:14:01] {202} INFO - result: {'pred_time': 5.400657653808594e-07, 'wall_clock_time': 9.815671920776367, 'metric_for_logging': {'pred_time': 5.400657653808594e-07}, 'val_loss': 0.31653333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b3130>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_leaves': 53, 'min_child_weight': 3.315670565896274, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7429418788184767, 'reg_alpha': 0.06408898861750664, 'reg_lambda': 0.7793954798138993}, 'config/n_estimators': 13, 'config/max_leaves': 53, 'config/min_child_weight': 3.315670565896274, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.7429418788184767, 'config/reg_alpha': 0.06408898861750664, 'config/reg_lambda': 0.7793954798138993, 'experiment_tag': 'exp', 'time_total_s': 1.304835319519043}\n",
      "[flaml.tune.tune: 06-10 14:14:01] {202} INFO - result: {'pred_time': 5.400657653808594e-07, 'wall_clock_time': 9.815671920776367, 'metric_for_logging': {'pred_time': 5.400657653808594e-07}, 'val_loss': 0.31653333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b3130>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_leaves': 53, 'min_child_weight': 3.315670565896274, 'learning_rate': 1.0, 'subsample': 0.9728097438800569, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.7429418788184767, 'reg_alpha': 0.06408898861750664, 'reg_lambda': 0.7793954798138993}, 'config/n_estimators': 13, 'config/max_leaves': 53, 'config/min_child_weight': 3.315670565896274, 'config/learning_rate': 1.0, 'config/subsample': 0.9728097438800569, 'config/colsample_bylevel': 1.0, 'config/colsample_bytree': 0.7429418788184767, 'config/reg_alpha': 0.06408898861750664, 'config/reg_lambda': 0.7793954798138993, 'experiment_tag': 'exp', 'time_total_s': 1.3063609600067139}\n",
      "[flaml.automl.logger: 06-10 14:14:01] {2392} INFO -  at 9.8s,\testimator xgboost's best error=0.2876,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:01] {2219} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:01] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.2606325616553224, 'max_leaves': 24, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:01] {202} INFO - result: {'pred_time': 2.1407445271809897e-06, 'wall_clock_time': 9.920227766036987, 'metric_for_logging': {'pred_time': 2.1407445271809897e-06}, 'val_loss': 0.5553333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1390>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.2606325616553224, 'max_leaves': 24, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.2606325616553224, 'config/max_leaves': 24, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.09939765930175781}\n",
      "[flaml.tune.tune: 06-10 14:14:01] {202} INFO - result: {'pred_time': 2.1407445271809897e-06, 'wall_clock_time': 9.920227766036987, 'metric_for_logging': {'pred_time': 2.1407445271809897e-06}, 'val_loss': 0.5553333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1390>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.2606325616553224, 'max_leaves': 24, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.2606325616553224, 'config/max_leaves': 24, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.10002732276916504}\n",
      "[flaml.automl.logger: 06-10 14:14:01] {2392} INFO -  at 9.9s,\testimator extra_tree's best error=0.5553,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:01] {2219} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:01] {811} INFO - trial 1 config: {'n_estimators': 11, 'max_features': 0.2212302463940774, 'max_leaves': 44, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:02] {202} INFO - result: {'pred_time': 2.456474304199219e-06, 'wall_clock_time': 10.094038486480713, 'metric_for_logging': {'pred_time': 2.456474304199219e-06}, 'val_loss': 0.46573333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bd300>, 'training_iteration': 0, 'config': {'n_estimators': 11, 'max_features': 0.2212302463940774, 'max_leaves': 44, 'criterion': 'gini'}, 'config/n_estimators': 11, 'config/max_features': 0.2212302463940774, 'config/max_leaves': 44, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17063283920288086}\n",
      "[flaml.tune.tune: 06-10 14:14:02] {202} INFO - result: {'pred_time': 2.456474304199219e-06, 'wall_clock_time': 10.094038486480713, 'metric_for_logging': {'pred_time': 2.456474304199219e-06}, 'val_loss': 0.46573333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bd300>, 'training_iteration': 1, 'config': {'n_estimators': 11, 'max_features': 0.2212302463940774, 'max_leaves': 44, 'criterion': 'gini'}, 'config/n_estimators': 11, 'config/max_features': 0.2212302463940774, 'config/max_leaves': 44, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.17149925231933594}\n",
      "[flaml.automl.logger: 06-10 14:14:02] {2392} INFO -  at 10.1s,\testimator extra_tree's best error=0.4657,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:02] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:02] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.26063256165532234, 'max_leaves': 24, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:02] {202} INFO - result: {'pred_time': 2.0724296569824217e-06, 'wall_clock_time': 10.193849086761475, 'metric_for_logging': {'pred_time': 2.0724296569824217e-06}, 'val_loss': 0.5298666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d3730>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.26063256165532234, 'max_leaves': 24, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.26063256165532234, 'config/max_leaves': 24, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.09650063514709473}\n",
      "[flaml.tune.tune: 06-10 14:14:02] {202} INFO - result: {'pred_time': 2.0724296569824217e-06, 'wall_clock_time': 10.193849086761475, 'metric_for_logging': {'pred_time': 2.0724296569824217e-06}, 'val_loss': 0.5298666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d3730>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.26063256165532234, 'max_leaves': 24, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.26063256165532234, 'config/max_leaves': 24, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.09712076187133789}\n",
      "[flaml.automl.logger: 06-10 14:14:02] {2392} INFO -  at 10.2s,\testimator extra_tree's best error=0.4657,\tbest estimator xgboost's best error=0.2876\n",
      "[flaml.automl.logger: 06-10 14:14:02] {2219} INFO - iteration 29, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:14:02] {811} INFO - trial 1 config: {'n_estimators': 138, 'max_leaves': 12, 'min_child_weight': 4.683741999092974, 'learning_rate': 0.1895176788575096, 'subsample': 1.0, 'colsample_bylevel': 0.6879746019660484, 'colsample_bytree': 0.6531014185931541, 'reg_alpha': 0.00665008510727136, 'reg_lambda': 2.560540737067101}\n",
      "[flaml.tune.tune: 06-10 14:14:05] {202} INFO - result: {'pred_time': 1.4867464701334635e-06, 'wall_clock_time': 13.977594375610352, 'metric_for_logging': {'pred_time': 1.4867464701334635e-06}, 'val_loss': 0.2825333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409632e0>, 'training_iteration': 0, 'config': {'n_estimators': 138, 'max_leaves': 12, 'min_child_weight': 4.683741999092974, 'learning_rate': 0.1895176788575096, 'subsample': 1.0, 'colsample_bylevel': 0.6879746019660484, 'colsample_bytree': 0.6531014185931541, 'reg_alpha': 0.00665008510727136, 'reg_lambda': 2.560540737067101}, 'config/n_estimators': 138, 'config/max_leaves': 12, 'config/min_child_weight': 4.683741999092974, 'config/learning_rate': 0.1895176788575096, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6879746019660484, 'config/colsample_bytree': 0.6531014185931541, 'config/reg_alpha': 0.00665008510727136, 'config/reg_lambda': 2.560540737067101, 'experiment_tag': 'exp', 'time_total_s': 3.7805585861206055}\n",
      "[flaml.tune.tune: 06-10 14:14:05] {202} INFO - result: {'pred_time': 1.4867464701334635e-06, 'wall_clock_time': 13.977594375610352, 'metric_for_logging': {'pred_time': 1.4867464701334635e-06}, 'val_loss': 0.2825333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409632e0>, 'training_iteration': 1, 'config': {'n_estimators': 138, 'max_leaves': 12, 'min_child_weight': 4.683741999092974, 'learning_rate': 0.1895176788575096, 'subsample': 1.0, 'colsample_bylevel': 0.6879746019660484, 'colsample_bytree': 0.6531014185931541, 'reg_alpha': 0.00665008510727136, 'reg_lambda': 2.560540737067101}, 'config/n_estimators': 138, 'config/max_leaves': 12, 'config/min_child_weight': 4.683741999092974, 'config/learning_rate': 0.1895176788575096, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.6879746019660484, 'config/colsample_bytree': 0.6531014185931541, 'config/reg_alpha': 0.00665008510727136, 'config/reg_lambda': 2.560540737067101, 'experiment_tag': 'exp', 'time_total_s': 3.7817249298095703}\n",
      "[flaml.automl.logger: 06-10 14:14:05] {2392} INFO -  at 14.0s,\testimator xgboost's best error=0.2825,\tbest estimator xgboost's best error=0.2825\n",
      "[flaml.automl.logger: 06-10 14:14:05] {2219} INFO - iteration 30, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:14:05] {811} INFO - trial 1 config: {'n_estimators': 75, 'max_leaves': 7, 'min_child_weight': 32.62281629450526, 'learning_rate': 0.11361182995409279, 'subsample': 0.9827721799620315, 'colsample_bylevel': 0.8788150902947329, 'colsample_bytree': 0.737274890340923, 'reg_alpha': 0.0036882514114169444, 'reg_lambda': 4.912706988701248}\n",
      "[flaml.tune.tune: 06-10 14:14:07] {202} INFO - result: {'pred_time': 8.315404256184896e-07, 'wall_clock_time': 15.51714563369751, 'metric_for_logging': {'pred_time': 8.315404256184896e-07}, 'val_loss': 0.37239999999999995, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1090>, 'training_iteration': 0, 'config': {'n_estimators': 75, 'max_leaves': 7, 'min_child_weight': 32.62281629450526, 'learning_rate': 0.11361182995409279, 'subsample': 0.9827721799620315, 'colsample_bylevel': 0.8788150902947329, 'colsample_bytree': 0.737274890340923, 'reg_alpha': 0.0036882514114169444, 'reg_lambda': 4.912706988701248}, 'config/n_estimators': 75, 'config/max_leaves': 7, 'config/min_child_weight': 32.62281629450526, 'config/learning_rate': 0.11361182995409279, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 0.8788150902947329, 'config/colsample_bytree': 0.737274890340923, 'config/reg_alpha': 0.0036882514114169444, 'config/reg_lambda': 4.912706988701248, 'experiment_tag': 'exp', 'time_total_s': 1.534698486328125}\n",
      "[flaml.tune.tune: 06-10 14:14:07] {202} INFO - result: {'pred_time': 8.315404256184896e-07, 'wall_clock_time': 15.51714563369751, 'metric_for_logging': {'pred_time': 8.315404256184896e-07}, 'val_loss': 0.37239999999999995, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b1090>, 'training_iteration': 1, 'config': {'n_estimators': 75, 'max_leaves': 7, 'min_child_weight': 32.62281629450526, 'learning_rate': 0.11361182995409279, 'subsample': 0.9827721799620315, 'colsample_bylevel': 0.8788150902947329, 'colsample_bytree': 0.737274890340923, 'reg_alpha': 0.0036882514114169444, 'reg_lambda': 4.912706988701248}, 'config/n_estimators': 75, 'config/max_leaves': 7, 'config/min_child_weight': 32.62281629450526, 'config/learning_rate': 0.11361182995409279, 'config/subsample': 0.9827721799620315, 'config/colsample_bylevel': 0.8788150902947329, 'config/colsample_bytree': 0.737274890340923, 'config/reg_alpha': 0.0036882514114169444, 'config/reg_lambda': 4.912706988701248, 'experiment_tag': 'exp', 'time_total_s': 1.5356178283691406}\n",
      "[flaml.automl.logger: 06-10 14:14:07] {2392} INFO -  at 15.5s,\testimator xgboost's best error=0.2825,\tbest estimator xgboost's best error=0.2825\n",
      "[flaml.automl.logger: 06-10 14:14:07] {2219} INFO - iteration 31, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:14:07] {811} INFO - trial 1 config: {'n_estimators': 252, 'max_leaves': 21, 'min_child_weight': 0.6724569367655245, 'learning_rate': 0.3161374182076913, 'subsample': 1.0, 'colsample_bylevel': 0.49713411363736404, 'colsample_bytree': 0.5689279468453852, 'reg_alpha': 0.011990406021958952, 'reg_lambda': 1.3345735622456516}\n",
      "[flaml.tune.tune: 06-10 14:14:17] {202} INFO - result: {'pred_time': 2.665233612060547e-06, 'wall_clock_time': 25.160227298736572, 'metric_for_logging': {'pred_time': 2.665233612060547e-06}, 'val_loss': 0.2746666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b2440>, 'training_iteration': 0, 'config': {'n_estimators': 252, 'max_leaves': 21, 'min_child_weight': 0.6724569367655245, 'learning_rate': 0.3161374182076913, 'subsample': 1.0, 'colsample_bylevel': 0.49713411363736404, 'colsample_bytree': 0.5689279468453852, 'reg_alpha': 0.011990406021958952, 'reg_lambda': 1.3345735622456516}, 'config/n_estimators': 252, 'config/max_leaves': 21, 'config/min_child_weight': 0.6724569367655245, 'config/learning_rate': 0.3161374182076913, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.49713411363736404, 'config/colsample_bytree': 0.5689279468453852, 'config/reg_alpha': 0.011990406021958952, 'config/reg_lambda': 1.3345735622456516, 'experiment_tag': 'exp', 'time_total_s': 9.639302253723145}\n",
      "[flaml.tune.tune: 06-10 14:14:17] {202} INFO - result: {'pred_time': 2.665233612060547e-06, 'wall_clock_time': 25.160227298736572, 'metric_for_logging': {'pred_time': 2.665233612060547e-06}, 'val_loss': 0.2746666666666666, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409b2440>, 'training_iteration': 1, 'config': {'n_estimators': 252, 'max_leaves': 21, 'min_child_weight': 0.6724569367655245, 'learning_rate': 0.3161374182076913, 'subsample': 1.0, 'colsample_bylevel': 0.49713411363736404, 'colsample_bytree': 0.5689279468453852, 'reg_alpha': 0.011990406021958952, 'reg_lambda': 1.3345735622456516}, 'config/n_estimators': 252, 'config/max_leaves': 21, 'config/min_child_weight': 0.6724569367655245, 'config/learning_rate': 0.3161374182076913, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.49713411363736404, 'config/colsample_bytree': 0.5689279468453852, 'config/reg_alpha': 0.011990406021958952, 'config/reg_lambda': 1.3345735622456516, 'experiment_tag': 'exp', 'time_total_s': 9.641175746917725}\n",
      "[flaml.automl.logger: 06-10 14:14:17] {2392} INFO -  at 25.2s,\testimator xgboost's best error=0.2747,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:17] {2219} INFO - iteration 32, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:17] {811} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.24212118739441296, 'max_leaves': 9, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:17] {202} INFO - result: {'pred_time': 2.496782938639323e-06, 'wall_clock_time': 25.313980102539062, 'metric_for_logging': {'pred_time': 2.496782938639323e-06}, 'val_loss': 0.6178666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1c30>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_features': 0.24212118739441296, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 13, 'config/max_features': 0.24212118739441296, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.14619207382202148}\n",
      "[flaml.tune.tune: 06-10 14:14:17] {202} INFO - result: {'pred_time': 2.496782938639323e-06, 'wall_clock_time': 25.313980102539062, 'metric_for_logging': {'pred_time': 2.496782938639323e-06}, 'val_loss': 0.6178666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1c30>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_features': 0.24212118739441296, 'max_leaves': 9, 'criterion': 'gini'}, 'config/n_estimators': 13, 'config/max_features': 0.24212118739441296, 'config/max_leaves': 9, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.14701008796691895}\n",
      "[flaml.automl.logger: 06-10 14:14:17] {2392} INFO -  at 25.3s,\testimator extra_tree's best error=0.4657,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:17] {2219} INFO - iteration 33, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:14:17] {811} INFO - trial 1 config: {'n_estimators': 116, 'max_leaves': 9, 'min_child_weight': 0.9183923207161553, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.649377771475732, 'colsample_bytree': 0.6033918380604777, 'reg_alpha': 0.0076803757690513015, 'reg_lambda': 3.294786137875348}\n",
      "[flaml.tune.tune: 06-10 14:14:19] {202} INFO - result: {'pred_time': 9.71698760986328e-07, 'wall_clock_time': 27.721081256866455, 'metric_for_logging': {'pred_time': 9.71698760986328e-07}, 'val_loss': 0.3012, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409bc0d0>, 'training_iteration': 0, 'config': {'n_estimators': 116, 'max_leaves': 9, 'min_child_weight': 0.9183923207161553, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.649377771475732, 'colsample_bytree': 0.6033918380604777, 'reg_alpha': 0.0076803757690513015, 'reg_lambda': 3.294786137875348}, 'config/n_estimators': 116, 'config/max_leaves': 9, 'config/min_child_weight': 0.9183923207161553, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.649377771475732, 'config/colsample_bytree': 0.6033918380604777, 'config/reg_alpha': 0.0076803757690513015, 'config/reg_lambda': 3.294786137875348, 'experiment_tag': 'exp', 'time_total_s': 2.403761863708496}\n",
      "[flaml.tune.tune: 06-10 14:14:19] {202} INFO - result: {'pred_time': 9.71698760986328e-07, 'wall_clock_time': 27.721081256866455, 'metric_for_logging': {'pred_time': 9.71698760986328e-07}, 'val_loss': 0.3012, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409bc0d0>, 'training_iteration': 1, 'config': {'n_estimators': 116, 'max_leaves': 9, 'min_child_weight': 0.9183923207161553, 'learning_rate': 1.0, 'subsample': 1.0, 'colsample_bylevel': 0.649377771475732, 'colsample_bytree': 0.6033918380604777, 'reg_alpha': 0.0076803757690513015, 'reg_lambda': 3.294786137875348}, 'config/n_estimators': 116, 'config/max_leaves': 9, 'config/min_child_weight': 0.9183923207161553, 'config/learning_rate': 1.0, 'config/subsample': 1.0, 'config/colsample_bylevel': 0.649377771475732, 'config/colsample_bytree': 0.6033918380604777, 'config/reg_alpha': 0.0076803757690513015, 'config/reg_lambda': 3.294786137875348, 'experiment_tag': 'exp', 'time_total_s': 2.404676914215088}\n",
      "[flaml.automl.logger: 06-10 14:14:19] {2392} INFO -  at 27.7s,\testimator xgboost's best error=0.2747,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:19] {2219} INFO - iteration 34, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:19] {811} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.20214183833427524, 'max_leaves': 224, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:19] {202} INFO - result: {'pred_time': 2.296892801920573e-06, 'wall_clock_time': 27.90642523765564, 'metric_for_logging': {'pred_time': 2.296892801920573e-06}, 'val_loss': 0.36706666666666665, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bc520>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_features': 0.20214183833427524, 'max_leaves': 224, 'criterion': 'entropy'}, 'config/n_estimators': 9, 'config/max_features': 0.20214183833427524, 'config/max_leaves': 224, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.18117403984069824}\n",
      "[flaml.tune.tune: 06-10 14:14:19] {202} INFO - result: {'pred_time': 2.296892801920573e-06, 'wall_clock_time': 27.90642523765564, 'metric_for_logging': {'pred_time': 2.296892801920573e-06}, 'val_loss': 0.36706666666666665, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bc520>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_features': 0.20214183833427524, 'max_leaves': 224, 'criterion': 'entropy'}, 'config/n_estimators': 9, 'config/max_features': 0.20214183833427524, 'config/max_leaves': 224, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.1819627285003662}\n",
      "[flaml.automl.logger: 06-10 14:14:19] {2392} INFO -  at 27.9s,\testimator extra_tree's best error=0.3671,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:19] {2219} INFO - iteration 35, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:19] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.16847091990242505, 'max_leaves': 165, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:19] {202} INFO - result: {'pred_time': 2.1407763163248697e-06, 'wall_clock_time': 28.065587520599365, 'metric_for_logging': {'pred_time': 2.1407763163248697e-06}, 'val_loss': 0.4509333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240961a50>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.16847091990242505, 'max_leaves': 165, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.16847091990242505, 'config/max_leaves': 165, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.15569639205932617}\n",
      "[flaml.tune.tune: 06-10 14:14:19] {202} INFO - result: {'pred_time': 2.1407763163248697e-06, 'wall_clock_time': 28.065587520599365, 'metric_for_logging': {'pred_time': 2.1407763163248697e-06}, 'val_loss': 0.4509333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240961a50>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.16847091990242505, 'max_leaves': 165, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.16847091990242505, 'config/max_leaves': 165, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.1563558578491211}\n",
      "[flaml.automl.logger: 06-10 14:14:19] {2392} INFO -  at 28.1s,\testimator extra_tree's best error=0.3671,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:19] {2219} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:19] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.24254229055570137, 'max_leaves': 304, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.611955006917318e-06, 'wall_clock_time': 28.274654865264893, 'metric_for_logging': {'pred_time': 2.611955006917318e-06}, 'val_loss': 0.3409333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d2710>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.24254229055570137, 'max_leaves': 304, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.24254229055570137, 'config/max_leaves': 304, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.20599675178527832}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.611955006917318e-06, 'wall_clock_time': 28.274654865264893, 'metric_for_logging': {'pred_time': 2.611955006917318e-06}, 'val_loss': 0.3409333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d2710>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.24254229055570137, 'max_leaves': 304, 'criterion': 'entropy'}, 'config/n_estimators': 15, 'config/max_features': 0.24254229055570137, 'config/max_leaves': 304, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.20680928230285645}\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2392} INFO -  at 28.3s,\testimator extra_tree's best error=0.3409,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2219} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:20] {811} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.2570539164309897, 'max_leaves': 547, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.170085906982422e-06, 'wall_clock_time': 28.466992616653442, 'metric_for_logging': {'pred_time': 2.170085906982422e-06}, 'val_loss': 0.3309333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240963d00>, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_features': 0.2570539164309897, 'max_leaves': 547, 'criterion': 'entropy'}, 'config/n_estimators': 6, 'config/max_features': 0.2570539164309897, 'config/max_leaves': 547, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.18910598754882812}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.170085906982422e-06, 'wall_clock_time': 28.466992616653442, 'metric_for_logging': {'pred_time': 2.170085906982422e-06}, 'val_loss': 0.3309333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240963d00>, 'training_iteration': 1, 'config': {'n_estimators': 6, 'max_features': 0.2570539164309897, 'max_leaves': 547, 'criterion': 'entropy'}, 'config/n_estimators': 6, 'config/max_features': 0.2570539164309897, 'config/max_leaves': 547, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.1898198127746582}\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2392} INFO -  at 28.5s,\testimator extra_tree's best error=0.3309,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2219} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:20] {811} INFO - trial 1 config: {'n_estimators': 16, 'max_features': 0.2425422905557013, 'max_leaves': 304, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.638403574625651e-06, 'wall_clock_time': 28.665065050125122, 'metric_for_logging': {'pred_time': 2.638403574625651e-06}, 'val_loss': 0.3322666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d3940>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_features': 0.2425422905557013, 'max_leaves': 304, 'criterion': 'gini'}, 'config/n_estimators': 16, 'config/max_features': 0.2425422905557013, 'config/max_leaves': 304, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.19473934173583984}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.638403574625651e-06, 'wall_clock_time': 28.665065050125122, 'metric_for_logging': {'pred_time': 2.638403574625651e-06}, 'val_loss': 0.3322666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d3940>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_features': 0.2425422905557013, 'max_leaves': 304, 'criterion': 'gini'}, 'config/n_estimators': 16, 'config/max_features': 0.2425422905557013, 'config/max_leaves': 304, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.19543910026550293}\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2392} INFO -  at 28.7s,\testimator extra_tree's best error=0.3309,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2219} INFO - iteration 39, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:20] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.2988150326431143, 'max_leaves': 1876, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.1456400553385417e-06, 'wall_clock_time': 28.917481422424316, 'metric_for_logging': {'pred_time': 2.1456400553385417e-06}, 'val_loss': 0.3002666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409628f0>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.2988150326431143, 'max_leaves': 1876, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.2988150326431143, 'config/max_leaves': 1876, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.24909615516662598}\n",
      "[flaml.tune.tune: 06-10 14:14:20] {202} INFO - result: {'pred_time': 2.1456400553385417e-06, 'wall_clock_time': 28.917481422424316, 'metric_for_logging': {'pred_time': 2.1456400553385417e-06}, 'val_loss': 0.3002666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409628f0>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.2988150326431143, 'max_leaves': 1876, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.2988150326431143, 'config/max_leaves': 1876, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.24977350234985352}\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2392} INFO -  at 28.9s,\testimator extra_tree's best error=0.3003,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:20] {2219} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:20] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.25705391643098957, 'max_leaves': 547, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.2073427836100262e-06, 'wall_clock_time': 29.10770583152771, 'metric_for_logging': {'pred_time': 2.2073427836100262e-06}, 'val_loss': 0.3302666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d1090>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.25705391643098957, 'max_leaves': 547, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.25705391643098957, 'config/max_leaves': 547, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.18705487251281738}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.2073427836100262e-06, 'wall_clock_time': 29.10770583152771, 'metric_for_logging': {'pred_time': 2.2073427836100262e-06}, 'val_loss': 0.3302666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d1090>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.25705391643098957, 'max_leaves': 547, 'criterion': 'gini'}, 'config/n_estimators': 7, 'config/max_features': 0.25705391643098957, 'config/max_leaves': 547, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.18768835067749023}\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2392} INFO -  at 29.1s,\testimator extra_tree's best error=0.3003,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2219} INFO - iteration 41, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:14:21] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.1133278403987422, 'max_leaves': 17, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.0622571309407553e-06, 'wall_clock_time': 29.275826930999756, 'metric_for_logging': {'pred_time': 2.0622571309407553e-06}, 'val_loss': 0.5473333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b0400>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.1133278403987422, 'max_leaves': 17, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.1133278403987422, 'config/max_leaves': 17, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.16508793830871582}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.0622571309407553e-06, 'wall_clock_time': 29.275826930999756, 'metric_for_logging': {'pred_time': 2.0622571309407553e-06}, 'val_loss': 0.5473333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b0400>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.1133278403987422, 'max_leaves': 17, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.1133278403987422, 'config/max_leaves': 17, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.16572237014770508}\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2392} INFO -  at 29.3s,\testimator rf's best error=0.5473,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2219} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:21] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.21886886403333713, 'max_leaves': 2436, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.2081693013509116e-06, 'wall_clock_time': 29.425445079803467, 'metric_for_logging': {'pred_time': 2.2081693013509116e-06}, 'val_loss': 0.32066666666666666, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240963b50>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.21886886403333713, 'max_leaves': 2436, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.21886886403333713, 'config/max_leaves': 2436, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.14640450477600098}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.2081693013509116e-06, 'wall_clock_time': 29.425445079803467, 'metric_for_logging': {'pred_time': 2.2081693013509116e-06}, 'val_loss': 0.32066666666666666, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240963b50>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.21886886403333713, 'max_leaves': 2436, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.21886886403333713, 'config/max_leaves': 2436, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.14722657203674316}\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2392} INFO -  at 29.4s,\testimator extra_tree's best error=0.3003,\tbest estimator xgboost's best error=0.2747\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2219} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:21] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.40796311584961276, 'max_leaves': 1445, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.399158477783203e-06, 'wall_clock_time': 29.691814661026, 'metric_for_logging': {'pred_time': 2.399158477783203e-06}, 'val_loss': 0.2692, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b2110>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.40796311584961276, 'max_leaves': 1445, 'criterion': 'gini'}, 'config/n_estimators': 10, 'config/max_features': 0.40796311584961276, 'config/max_leaves': 1445, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2630331516265869}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.399158477783203e-06, 'wall_clock_time': 29.691814661026, 'metric_for_logging': {'pred_time': 2.399158477783203e-06}, 'val_loss': 0.2692, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b2110>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.40796311584961276, 'max_leaves': 1445, 'criterion': 'gini'}, 'config/n_estimators': 10, 'config/max_features': 0.40796311584961276, 'config/max_leaves': 1445, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2638211250305176}\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2392} INFO -  at 29.7s,\testimator extra_tree's best error=0.2692,\tbest estimator extra_tree's best error=0.2692\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2219} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:21] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.6301238371796296, 'max_leaves': 2171, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.3303667704264325e-06, 'wall_clock_time': 30.064091444015503, 'metric_for_logging': {'pred_time': 2.3303667704264325e-06}, 'val_loss': 0.26680000000000004, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bc1c0>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.6301238371796296, 'max_leaves': 2171, 'criterion': 'gini'}, 'config/n_estimators': 10, 'config/max_features': 0.6301238371796296, 'config/max_leaves': 2171, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.36390018463134766}\n",
      "[flaml.tune.tune: 06-10 14:14:21] {202} INFO - result: {'pred_time': 2.3303667704264325e-06, 'wall_clock_time': 30.064091444015503, 'metric_for_logging': {'pred_time': 2.3303667704264325e-06}, 'val_loss': 0.26680000000000004, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bc1c0>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.6301238371796296, 'max_leaves': 2171, 'criterion': 'gini'}, 'config/n_estimators': 10, 'config/max_features': 0.6301238371796296, 'config/max_leaves': 2171, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3647274971008301}\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2392} INFO -  at 30.1s,\testimator extra_tree's best error=0.2668,\tbest estimator extra_tree's best error=0.2668\n",
      "[flaml.automl.logger: 06-10 14:14:21] {2219} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:21] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.40796311584961265, 'max_leaves': 1445, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:22] {202} INFO - result: {'pred_time': 2.2631009419759115e-06, 'wall_clock_time': 30.34664821624756, 'metric_for_logging': {'pred_time': 2.2631009419759115e-06}, 'val_loss': 0.2764, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1a50>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.40796311584961265, 'max_leaves': 1445, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.40796311584961265, 'config/max_leaves': 1445, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.278639554977417}\n",
      "[flaml.tune.tune: 06-10 14:14:22] {202} INFO - result: {'pred_time': 2.2631009419759115e-06, 'wall_clock_time': 30.34664821624756, 'metric_for_logging': {'pred_time': 2.2631009419759115e-06}, 'val_loss': 0.2764, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1a50>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.40796311584961265, 'max_leaves': 1445, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.40796311584961265, 'config/max_leaves': 1445, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.27940821647644043}\n",
      "[flaml.automl.logger: 06-10 14:14:22] {2392} INFO -  at 30.3s,\testimator extra_tree's best error=0.2668,\tbest estimator extra_tree's best error=0.2668\n",
      "[flaml.automl.logger: 06-10 14:14:22] {2219} INFO - iteration 46, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:22] {811} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 0.6642171871266367, 'max_leaves': 1503, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:22] {202} INFO - result: {'pred_time': 2.4298667907714842e-06, 'wall_clock_time': 30.683496713638306, 'metric_for_logging': {'pred_time': 2.4298667907714842e-06}, 'val_loss': 0.2645333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bded0>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 0.6642171871266367, 'max_leaves': 1503, 'criterion': 'gini'}, 'config/n_estimators': 12, 'config/max_features': 0.6642171871266367, 'config/max_leaves': 1503, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3337252140045166}\n",
      "[flaml.tune.tune: 06-10 14:14:22] {202} INFO - result: {'pred_time': 2.4298667907714842e-06, 'wall_clock_time': 30.683496713638306, 'metric_for_logging': {'pred_time': 2.4298667907714842e-06}, 'val_loss': 0.2645333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bded0>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 0.6642171871266367, 'max_leaves': 1503, 'criterion': 'gini'}, 'config/n_estimators': 12, 'config/max_features': 0.6642171871266367, 'config/max_leaves': 1503, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3347151279449463}\n",
      "[flaml.automl.logger: 06-10 14:14:22] {2392} INFO -  at 30.7s,\testimator extra_tree's best error=0.2645,\tbest estimator extra_tree's best error=0.2645\n",
      "[flaml.automl.logger: 06-10 14:14:22] {2219} INFO - iteration 47, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:22] {811} INFO - trial 1 config: {'n_estimators': 10, 'max_features': 0.6301238371796294, 'max_leaves': 2171, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:23] {202} INFO - result: {'pred_time': 2.3465792338053387e-06, 'wall_clock_time': 31.081984519958496, 'metric_for_logging': {'pred_time': 2.3465792338053387e-06}, 'val_loss': 0.2718666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1990>, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_features': 0.6301238371796294, 'max_leaves': 2171, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.6301238371796294, 'config/max_leaves': 2171, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.39444899559020996}\n",
      "[flaml.tune.tune: 06-10 14:14:23] {202} INFO - result: {'pred_time': 2.3465792338053387e-06, 'wall_clock_time': 31.081984519958496, 'metric_for_logging': {'pred_time': 2.3465792338053387e-06}, 'val_loss': 0.2718666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1990>, 'training_iteration': 1, 'config': {'n_estimators': 10, 'max_features': 0.6301238371796294, 'max_leaves': 2171, 'criterion': 'entropy'}, 'config/n_estimators': 10, 'config/max_features': 0.6301238371796294, 'config/max_leaves': 2171, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.39524149894714355}\n",
      "[flaml.automl.logger: 06-10 14:14:23] {2392} INFO -  at 31.1s,\testimator extra_tree's best error=0.2645,\tbest estimator extra_tree's best error=0.2645\n",
      "[flaml.automl.logger: 06-10 14:14:23] {2219} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:23] {811} INFO - trial 1 config: {'n_estimators': 25, 'max_features': 0.561186037412054, 'max_leaves': 1098, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:23] {202} INFO - result: {'pred_time': 2.8630892435709635e-06, 'wall_clock_time': 31.45824360847473, 'metric_for_logging': {'pred_time': 2.8630892435709635e-06}, 'val_loss': 0.26959999999999995, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bf280>, 'training_iteration': 0, 'config': {'n_estimators': 25, 'max_features': 0.561186037412054, 'max_leaves': 1098, 'criterion': 'entropy'}, 'config/n_estimators': 25, 'config/max_features': 0.561186037412054, 'config/max_leaves': 1098, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.37285852432250977}\n",
      "[flaml.tune.tune: 06-10 14:14:23] {202} INFO - result: {'pred_time': 2.8630892435709635e-06, 'wall_clock_time': 31.45824360847473, 'metric_for_logging': {'pred_time': 2.8630892435709635e-06}, 'val_loss': 0.26959999999999995, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bf280>, 'training_iteration': 1, 'config': {'n_estimators': 25, 'max_features': 0.561186037412054, 'max_leaves': 1098, 'criterion': 'entropy'}, 'config/n_estimators': 25, 'config/max_features': 0.561186037412054, 'config/max_leaves': 1098, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.37369322776794434}\n",
      "[flaml.automl.logger: 06-10 14:14:23] {2392} INFO -  at 31.5s,\testimator extra_tree's best error=0.2645,\tbest estimator extra_tree's best error=0.2645\n",
      "[flaml.automl.logger: 06-10 14:14:23] {2219} INFO - iteration 49, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:23] {811} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.7861643773408411, 'max_leaves': 2057, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:23] {202} INFO - result: {'pred_time': 2.1674474080403647e-06, 'wall_clock_time': 31.84100914001465, 'metric_for_logging': {'pred_time': 2.1674474080403647e-06}, 'val_loss': 0.2758666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240962230>, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_features': 0.7861643773408411, 'max_leaves': 2057, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.7861643773408411, 'config/max_leaves': 2057, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3796355724334717}\n",
      "[flaml.tune.tune: 06-10 14:14:23] {202} INFO - result: {'pred_time': 2.1674474080403647e-06, 'wall_clock_time': 31.84100914001465, 'metric_for_logging': {'pred_time': 2.1674474080403647e-06}, 'val_loss': 0.2758666666666667, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4240962230>, 'training_iteration': 1, 'config': {'n_estimators': 6, 'max_features': 0.7861643773408411, 'max_leaves': 2057, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.7861643773408411, 'config/max_leaves': 2057, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3803737163543701}\n",
      "[flaml.automl.logger: 06-10 14:14:23] {2392} INFO -  at 31.8s,\testimator extra_tree's best error=0.2645,\tbest estimator extra_tree's best error=0.2645\n",
      "[flaml.automl.logger: 06-10 14:14:23] {2219} INFO - iteration 50, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:23] {811} INFO - trial 1 config: {'n_estimators': 17, 'max_features': 0.4526392259976311, 'max_leaves': 1085, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:14:24] {202} INFO - result: {'pred_time': 2.6705106099446615e-06, 'wall_clock_time': 32.12016463279724, 'metric_for_logging': {'pred_time': 2.6705106099446615e-06}, 'val_loss': 0.2724, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d21a0>, 'training_iteration': 0, 'config': {'n_estimators': 17, 'max_features': 0.4526392259976311, 'max_leaves': 1085, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.4526392259976311, 'config/max_leaves': 1085, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2759971618652344}\n",
      "[flaml.tune.tune: 06-10 14:14:24] {202} INFO - result: {'pred_time': 2.6705106099446615e-06, 'wall_clock_time': 32.12016463279724, 'metric_for_logging': {'pred_time': 2.6705106099446615e-06}, 'val_loss': 0.2724, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409d21a0>, 'training_iteration': 1, 'config': {'n_estimators': 17, 'max_features': 0.4526392259976311, 'max_leaves': 1085, 'criterion': 'gini'}, 'config/n_estimators': 17, 'config/max_features': 0.4526392259976311, 'config/max_leaves': 1085, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2767765522003174}\n",
      "[flaml.automl.logger: 06-10 14:14:24] {2392} INFO -  at 32.1s,\testimator extra_tree's best error=0.2645,\tbest estimator extra_tree's best error=0.2645\n",
      "[flaml.automl.logger: 06-10 14:14:24] {2219} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:14:24] {811} INFO - trial 1 config: {'n_estimators': 8, 'max_features': 0.9746934121806099, 'max_leaves': 2082, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:14:24] {202} INFO - result: {'pred_time': 2.2357622782389323e-06, 'wall_clock_time': 32.60515546798706, 'metric_for_logging': {'pred_time': 2.2357622782389323e-06}, 'val_loss': 0.2637333333333334, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409635e0>, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_features': 0.9746934121806099, 'max_leaves': 2082, 'criterion': 'entropy'}, 'config/n_estimators': 8, 'config/max_features': 0.9746934121806099, 'config/max_leaves': 2082, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.48164868354797363}\n",
      "[flaml.tune.tune: 06-10 14:14:24] {202} INFO - result: {'pred_time': 2.2357622782389323e-06, 'wall_clock_time': 32.60515546798706, 'metric_for_logging': {'pred_time': 2.2357622782389323e-06}, 'val_loss': 0.2637333333333334, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409635e0>, 'training_iteration': 1, 'config': {'n_estimators': 8, 'max_features': 0.9746934121806099, 'max_leaves': 2082, 'criterion': 'entropy'}, 'config/n_estimators': 8, 'config/max_features': 0.9746934121806099, 'config/max_leaves': 2082, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.48241186141967773}\n",
      "[flaml.automl.logger: 06-10 14:14:24] {2392} INFO -  at 32.6s,\testimator extra_tree's best error=0.2637,\tbest estimator extra_tree's best error=0.2637\n",
      "[flaml.automl.logger: 06-10 14:14:24] {2219} INFO - iteration 52, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:14:24] {811} INFO - trial 1 config: {'n_estimators': 546, 'max_leaves': 48, 'min_child_weight': 0.4923803494474474, 'learning_rate': 0.09857269201987773, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.3448904557989961, 'colsample_bytree': 0.5344640556302928, 'reg_alpha': 0.01871911490981493, 'reg_lambda': 0.5405772995614172}\n",
      "[flaml.tune.tune: 06-10 14:15:05] {202} INFO - result: {'pred_time': 8.461157480875651e-06, 'wall_clock_time': 73.84007477760315, 'metric_for_logging': {'pred_time': 8.461157480875651e-06}, 'val_loss': 0.2617333333333334, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409bfa00>, 'training_iteration': 0, 'config': {'n_estimators': 546, 'max_leaves': 48, 'min_child_weight': 0.4923803494474474, 'learning_rate': 0.09857269201987773, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.3448904557989961, 'colsample_bytree': 0.5344640556302928, 'reg_alpha': 0.01871911490981493, 'reg_lambda': 0.5405772995614172}, 'config/n_estimators': 546, 'config/max_leaves': 48, 'config/min_child_weight': 0.4923803494474474, 'config/learning_rate': 0.09857269201987773, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.3448904557989961, 'config/colsample_bytree': 0.5344640556302928, 'config/reg_alpha': 0.01871911490981493, 'config/reg_lambda': 0.5405772995614172, 'experiment_tag': 'exp', 'time_total_s': 41.23124432563782}\n",
      "[flaml.tune.tune: 06-10 14:15:05] {202} INFO - result: {'pred_time': 8.461157480875651e-06, 'wall_clock_time': 73.84007477760315, 'metric_for_logging': {'pred_time': 8.461157480875651e-06}, 'val_loss': 0.2617333333333334, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f42409bfa00>, 'training_iteration': 1, 'config': {'n_estimators': 546, 'max_leaves': 48, 'min_child_weight': 0.4923803494474474, 'learning_rate': 0.09857269201987773, 'subsample': 0.8895588746662894, 'colsample_bylevel': 0.3448904557989961, 'colsample_bytree': 0.5344640556302928, 'reg_alpha': 0.01871911490981493, 'reg_lambda': 0.5405772995614172}, 'config/n_estimators': 546, 'config/max_leaves': 48, 'config/min_child_weight': 0.4923803494474474, 'config/learning_rate': 0.09857269201987773, 'config/subsample': 0.8895588746662894, 'config/colsample_bylevel': 0.3448904557989961, 'config/colsample_bytree': 0.5344640556302928, 'config/reg_alpha': 0.01871911490981493, 'config/reg_lambda': 0.5405772995614172, 'experiment_tag': 'exp', 'time_total_s': 41.23306965827942}\n",
      "[flaml.automl.logger: 06-10 14:15:05] {2392} INFO -  at 73.8s,\testimator xgboost's best error=0.2617,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:05] {2219} INFO - iteration 53, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:05] {811} INFO - trial 1 config: {'n_estimators': 11, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:06] {202} INFO - result: {'pred_time': 2.445856730143229e-06, 'wall_clock_time': 74.43496632575989, 'metric_for_logging': {'pred_time': 2.445856730143229e-06}, 'val_loss': 0.47053333333333336, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409bf9a0>, 'training_iteration': 0, 'config': {'n_estimators': 11, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy'}, 'config/n_estimators': 11, 'config/max_features': 0.1, 'config/max_leaves': 31, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5883324146270752}\n",
      "[flaml.tune.tune: 06-10 14:15:06] {202} INFO - result: {'pred_time': 2.445856730143229e-06, 'wall_clock_time': 74.43496632575989, 'metric_for_logging': {'pred_time': 2.445856730143229e-06}, 'val_loss': 0.47053333333333336, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409bf9a0>, 'training_iteration': 1, 'config': {'n_estimators': 11, 'max_features': 0.1, 'max_leaves': 31, 'criterion': 'entropy'}, 'config/n_estimators': 11, 'config/max_features': 0.1, 'config/max_leaves': 31, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5890371799468994}\n",
      "[flaml.automl.logger: 06-10 14:15:06] {2392} INFO -  at 74.4s,\testimator rf's best error=0.4705,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:06] {2219} INFO - iteration 54, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:06] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.11781054620852233, 'max_leaves': 17, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:06] {202} INFO - result: {'pred_time': 2.1334330240885418e-06, 'wall_clock_time': 74.76635193824768, 'metric_for_logging': {'pred_time': 2.1334330240885418e-06}, 'val_loss': 0.5502666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409d21d0>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.11781054620852233, 'max_leaves': 17, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.11781054620852233, 'config/max_leaves': 17, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.32817673683166504}\n",
      "[flaml.tune.tune: 06-10 14:15:06] {202} INFO - result: {'pred_time': 2.1334330240885418e-06, 'wall_clock_time': 74.76635193824768, 'metric_for_logging': {'pred_time': 2.1334330240885418e-06}, 'val_loss': 0.5502666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409d21d0>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.11781054620852233, 'max_leaves': 17, 'criterion': 'entropy'}, 'config/n_estimators': 4, 'config/max_features': 0.11781054620852233, 'config/max_leaves': 17, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.32890987396240234}\n",
      "[flaml.automl.logger: 06-10 14:15:06] {2392} INFO -  at 74.8s,\testimator rf's best error=0.4705,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:06] {2219} INFO - iteration 55, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:06] {811} INFO - trial 1 config: {'n_estimators': 13, 'max_features': 0.10944307631566913, 'max_leaves': 6, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:07] {202} INFO - result: {'pred_time': 2.5938987731933594e-06, 'wall_clock_time': 75.21418261528015, 'metric_for_logging': {'pred_time': 2.5938987731933594e-06}, 'val_loss': 0.6028, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b3310>, 'training_iteration': 0, 'config': {'n_estimators': 13, 'max_features': 0.10944307631566913, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.10944307631566913, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.44468212127685547}\n",
      "[flaml.tune.tune: 06-10 14:15:07] {202} INFO - result: {'pred_time': 2.5938987731933594e-06, 'wall_clock_time': 75.21418261528015, 'metric_for_logging': {'pred_time': 2.5938987731933594e-06}, 'val_loss': 0.6028, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409b3310>, 'training_iteration': 1, 'config': {'n_estimators': 13, 'max_features': 0.10944307631566913, 'max_leaves': 6, 'criterion': 'entropy'}, 'config/n_estimators': 13, 'config/max_features': 0.10944307631566913, 'config/max_leaves': 6, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.44544529914855957}\n",
      "[flaml.automl.logger: 06-10 14:15:07] {2392} INFO -  at 75.2s,\testimator rf's best error=0.4705,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:07] {2219} INFO - iteration 56, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:07] {811} INFO - trial 1 config: {'n_estimators': 9, 'max_features': 0.1, 'max_leaves': 158, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:15:07] {202} INFO - result: {'pred_time': 2.3182233174641926e-06, 'wall_clock_time': 75.5994462966919, 'metric_for_logging': {'pred_time': 2.3182233174641926e-06}, 'val_loss': 0.3845333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409f4700>, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_features': 0.1, 'max_leaves': 158, 'criterion': 'gini'}, 'config/n_estimators': 9, 'config/max_features': 0.1, 'config/max_leaves': 158, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.3820159435272217}\n",
      "[flaml.tune.tune: 06-10 14:15:07] {202} INFO - result: {'pred_time': 2.3182233174641926e-06, 'wall_clock_time': 75.5994462966919, 'metric_for_logging': {'pred_time': 2.3182233174641926e-06}, 'val_loss': 0.3845333333333333, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409f4700>, 'training_iteration': 1, 'config': {'n_estimators': 9, 'max_features': 0.1, 'max_leaves': 158, 'criterion': 'gini'}, 'config/n_estimators': 9, 'config/max_features': 0.1, 'config/max_leaves': 158, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.38277244567871094}\n",
      "[flaml.automl.logger: 06-10 14:15:07] {2392} INFO -  at 75.6s,\testimator rf's best error=0.3845,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:07] {2219} INFO - iteration 57, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:07] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.1, 'max_leaves': 116, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:08] {202} INFO - result: {'pred_time': 2.0629247029622394e-06, 'wall_clock_time': 76.23383235931396, 'metric_for_logging': {'pred_time': 2.0629247029622394e-06}, 'val_loss': 0.41946666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409bc3a0>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.1, 'max_leaves': 116, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.1, 'config/max_leaves': 116, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.6309776306152344}\n",
      "[flaml.tune.tune: 06-10 14:15:08] {202} INFO - result: {'pred_time': 2.0629247029622394e-06, 'wall_clock_time': 76.23383235931396, 'metric_for_logging': {'pred_time': 2.0629247029622394e-06}, 'val_loss': 0.41946666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409bc3a0>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.1, 'max_leaves': 116, 'criterion': 'entropy'}, 'config/n_estimators': 5, 'config/max_features': 0.1, 'config/max_leaves': 116, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.6317825317382812}\n",
      "[flaml.automl.logger: 06-10 14:15:08] {2392} INFO -  at 76.2s,\testimator rf's best error=0.3845,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:08] {2219} INFO - iteration 58, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:08] {811} INFO - trial 1 config: {'n_estimators': 15, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:15:08] {202} INFO - result: {'pred_time': 2.596569061279297e-06, 'wall_clock_time': 76.65412783622742, 'metric_for_logging': {'pred_time': 2.596569061279297e-06}, 'val_loss': 0.3606666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409f5c30>, 'training_iteration': 0, 'config': {'n_estimators': 15, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.41732120513916016}\n",
      "[flaml.tune.tune: 06-10 14:15:08] {202} INFO - result: {'pred_time': 2.596569061279297e-06, 'wall_clock_time': 76.65412783622742, 'metric_for_logging': {'pred_time': 2.596569061279297e-06}, 'val_loss': 0.3606666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f42409f5c30>, 'training_iteration': 1, 'config': {'n_estimators': 15, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'gini'}, 'config/n_estimators': 15, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4181509017944336}\n",
      "[flaml.automl.logger: 06-10 14:15:08] {2392} INFO -  at 76.7s,\testimator rf's best error=0.3607,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:08] {2219} INFO - iteration 59, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:15:08] {811} INFO - trial 1 config: {'n_estimators': 12, 'max_features': 1.0, 'max_leaves': 613, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:09] {202} INFO - result: {'pred_time': 2.457269032796224e-06, 'wall_clock_time': 77.2359676361084, 'metric_for_logging': {'pred_time': 2.457269032796224e-06}, 'val_loss': 0.28800000000000003, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bc700>, 'training_iteration': 0, 'config': {'n_estimators': 12, 'max_features': 1.0, 'max_leaves': 613, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 1.0, 'config/max_leaves': 613, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5783612728118896}\n",
      "[flaml.tune.tune: 06-10 14:15:09] {202} INFO - result: {'pred_time': 2.457269032796224e-06, 'wall_clock_time': 77.2359676361084, 'metric_for_logging': {'pred_time': 2.457269032796224e-06}, 'val_loss': 0.28800000000000003, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409bc700>, 'training_iteration': 1, 'config': {'n_estimators': 12, 'max_features': 1.0, 'max_leaves': 613, 'criterion': 'entropy'}, 'config/n_estimators': 12, 'config/max_features': 1.0, 'config/max_leaves': 613, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.5790469646453857}\n",
      "[flaml.automl.logger: 06-10 14:15:09] {2392} INFO -  at 77.2s,\testimator extra_tree's best error=0.2637,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:09] {2219} INFO - iteration 60, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:09] {811} INFO - trial 1 config: {'n_estimators': 6, 'max_features': 0.12716512254425438, 'max_leaves': 387, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:15:09] {202} INFO - result: {'pred_time': 2.154223124186198e-06, 'wall_clock_time': 77.71088290214539, 'metric_for_logging': {'pred_time': 2.154223124186198e-06}, 'val_loss': 0.3406666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240daf730>, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_features': 0.12716512254425438, 'max_leaves': 387, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.12716512254425438, 'config/max_leaves': 387, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4718337059020996}\n",
      "[flaml.tune.tune: 06-10 14:15:09] {202} INFO - result: {'pred_time': 2.154223124186198e-06, 'wall_clock_time': 77.71088290214539, 'metric_for_logging': {'pred_time': 2.154223124186198e-06}, 'val_loss': 0.3406666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240daf730>, 'training_iteration': 1, 'config': {'n_estimators': 6, 'max_features': 0.12716512254425438, 'max_leaves': 387, 'criterion': 'gini'}, 'config/n_estimators': 6, 'config/max_features': 0.12716512254425438, 'config/max_leaves': 387, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4725344181060791}\n",
      "[flaml.automl.logger: 06-10 14:15:09] {2392} INFO -  at 77.7s,\testimator rf's best error=0.3407,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:09] {2219} INFO - iteration 61, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:09] {811} INFO - trial 1 config: {'n_estimators': 16, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:10] {202} INFO - result: {'pred_time': 2.615038553873698e-06, 'wall_clock_time': 78.50420117378235, 'metric_for_logging': {'pred_time': 2.615038553873698e-06}, 'val_loss': 0.358, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240ccd3f0>, 'training_iteration': 0, 'config': {'n_estimators': 16, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'entropy'}, 'config/n_estimators': 16, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7900218963623047}\n",
      "[flaml.tune.tune: 06-10 14:15:10] {202} INFO - result: {'pred_time': 2.615038553873698e-06, 'wall_clock_time': 78.50420117378235, 'metric_for_logging': {'pred_time': 2.615038553873698e-06}, 'val_loss': 0.358, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240ccd3f0>, 'training_iteration': 1, 'config': {'n_estimators': 16, 'max_features': 0.11998619016940831, 'max_leaves': 215, 'criterion': 'entropy'}, 'config/n_estimators': 16, 'config/max_features': 0.11998619016940831, 'config/max_leaves': 215, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.7907428741455078}\n",
      "[flaml.automl.logger: 06-10 14:15:10] {2392} INFO -  at 78.5s,\testimator rf's best error=0.3407,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:10] {2219} INFO - iteration 62, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:15:10] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.8279605132651962, 'max_leaves': 7072, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:15:10] {202} INFO - result: {'pred_time': 2.157751719156901e-06, 'wall_clock_time': 78.99617862701416, 'metric_for_logging': {'pred_time': 2.157751719156901e-06}, 'val_loss': 0.2925333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4241841390>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.8279605132651962, 'max_leaves': 7072, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.8279605132651962, 'config/max_leaves': 7072, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.48899126052856445}\n",
      "[flaml.tune.tune: 06-10 14:15:10] {202} INFO - result: {'pred_time': 2.157751719156901e-06, 'wall_clock_time': 78.99617862701416, 'metric_for_logging': {'pred_time': 2.157751719156901e-06}, 'val_loss': 0.2925333333333333, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f4241841390>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.8279605132651962, 'max_leaves': 7072, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.8279605132651962, 'config/max_leaves': 7072, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.4896814823150635}\n",
      "[flaml.automl.logger: 06-10 14:15:10] {2392} INFO -  at 79.0s,\testimator extra_tree's best error=0.2637,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:10] {2219} INFO - iteration 63, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:10] {811} INFO - trial 1 config: {'n_estimators': 5, 'max_features': 0.14782443610163173, 'max_leaves': 1328, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:15:11] {202} INFO - result: {'pred_time': 2.2027015686035155e-06, 'wall_clock_time': 79.56176471710205, 'metric_for_logging': {'pred_time': 2.2027015686035155e-06}, 'val_loss': 0.32399999999999995, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402bcb9ba0>, 'training_iteration': 0, 'config': {'n_estimators': 5, 'max_features': 0.14782443610163173, 'max_leaves': 1328, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.14782443610163173, 'config/max_leaves': 1328, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5624527931213379}\n",
      "[flaml.tune.tune: 06-10 14:15:11] {202} INFO - result: {'pred_time': 2.2027015686035155e-06, 'wall_clock_time': 79.56176471710205, 'metric_for_logging': {'pred_time': 2.2027015686035155e-06}, 'val_loss': 0.32399999999999995, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f402bcb9ba0>, 'training_iteration': 1, 'config': {'n_estimators': 5, 'max_features': 0.14782443610163173, 'max_leaves': 1328, 'criterion': 'gini'}, 'config/n_estimators': 5, 'config/max_features': 0.14782443610163173, 'config/max_leaves': 1328, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.5630900859832764}\n",
      "[flaml.automl.logger: 06-10 14:15:11] {2392} INFO -  at 79.6s,\testimator rf's best error=0.3240,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:11] {2219} INFO - iteration 64, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:11] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 0.12716512254425436, 'max_leaves': 387, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:12] {202} INFO - result: {'pred_time': 2.248859405517578e-06, 'wall_clock_time': 80.6404960155487, 'metric_for_logging': {'pred_time': 2.248859405517578e-06}, 'val_loss': 0.33986666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f424090a230>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 0.12716512254425436, 'max_leaves': 387, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.12716512254425436, 'config/max_leaves': 387, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0751821994781494}\n",
      "[flaml.tune.tune: 06-10 14:15:12] {202} INFO - result: {'pred_time': 2.248859405517578e-06, 'wall_clock_time': 80.6404960155487, 'metric_for_logging': {'pred_time': 2.248859405517578e-06}, 'val_loss': 0.33986666666666665, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f424090a230>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 0.12716512254425436, 'max_leaves': 387, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 0.12716512254425436, 'config/max_leaves': 387, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 1.0761771202087402}\n",
      "[flaml.automl.logger: 06-10 14:15:12] {2392} INFO -  at 80.6s,\testimator rf's best error=0.3240,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:12] {2219} INFO - iteration 65, current learner extra_tree\n",
      "[flaml.tune.tune: 06-10 14:15:12] {811} INFO - trial 1 config: {'n_estimators': 7, 'max_features': 1.0, 'max_leaves': 1680, 'criterion': 'entropy'}\n",
      "[flaml.tune.tune: 06-10 14:15:13] {202} INFO - result: {'pred_time': 2.3523330688476564e-06, 'wall_clock_time': 81.11571645736694, 'metric_for_logging': {'pred_time': 2.3523330688476564e-06}, 'val_loss': 0.27, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1750>, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_features': 1.0, 'max_leaves': 1680, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 1.0, 'config/max_leaves': 1680, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.47184157371520996}\n",
      "[flaml.tune.tune: 06-10 14:15:13] {202} INFO - result: {'pred_time': 2.3523330688476564e-06, 'wall_clock_time': 81.11571645736694, 'metric_for_logging': {'pred_time': 2.3523330688476564e-06}, 'val_loss': 0.27, 'trained_estimator': <flaml.automl.model.ExtraTreesEstimator object at 0x7f42409b1750>, 'training_iteration': 1, 'config': {'n_estimators': 7, 'max_features': 1.0, 'max_leaves': 1680, 'criterion': 'entropy'}, 'config/n_estimators': 7, 'config/max_features': 1.0, 'config/max_leaves': 1680, 'config/criterion': 'entropy', 'experiment_tag': 'exp', 'time_total_s': 0.4725193977355957}\n",
      "[flaml.automl.logger: 06-10 14:15:13] {2392} INFO -  at 81.1s,\testimator extra_tree's best error=0.2637,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:13] {2219} INFO - iteration 66, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:15:13] {811} INFO - trial 1 config: {'n_estimators': 241, 'max_leaves': 7, 'min_child_weight': 0.7194782287954906, 'learning_rate': 0.1699488535947036, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.46157621361638057, 'colsample_bytree': 0.5920758489942983, 'reg_alpha': 0.026965210811239645, 'reg_lambda': 0.17802710319230947}\n",
      "[flaml.tune.tune: 06-10 14:15:17] {202} INFO - result: {'pred_time': 1.7193476359049479e-06, 'wall_clock_time': 85.33425879478455, 'metric_for_logging': {'pred_time': 1.7193476359049479e-06}, 'val_loss': 0.2997333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f4240a86ec0>, 'training_iteration': 0, 'config': {'n_estimators': 241, 'max_leaves': 7, 'min_child_weight': 0.7194782287954906, 'learning_rate': 0.1699488535947036, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.46157621361638057, 'colsample_bytree': 0.5920758489942983, 'reg_alpha': 0.026965210811239645, 'reg_lambda': 0.17802710319230947}, 'config/n_estimators': 241, 'config/max_leaves': 7, 'config/min_child_weight': 0.7194782287954906, 'config/learning_rate': 0.1699488535947036, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.46157621361638057, 'config/colsample_bytree': 0.5920758489942983, 'config/reg_alpha': 0.026965210811239645, 'config/reg_lambda': 0.17802710319230947, 'experiment_tag': 'exp', 'time_total_s': 4.215240716934204}\n",
      "[flaml.tune.tune: 06-10 14:15:17] {202} INFO - result: {'pred_time': 1.7193476359049479e-06, 'wall_clock_time': 85.33425879478455, 'metric_for_logging': {'pred_time': 1.7193476359049479e-06}, 'val_loss': 0.2997333333333333, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f4240a86ec0>, 'training_iteration': 1, 'config': {'n_estimators': 241, 'max_leaves': 7, 'min_child_weight': 0.7194782287954906, 'learning_rate': 0.1699488535947036, 'subsample': 0.937812919568431, 'colsample_bylevel': 0.46157621361638057, 'colsample_bytree': 0.5920758489942983, 'reg_alpha': 0.026965210811239645, 'reg_lambda': 0.17802710319230947}, 'config/n_estimators': 241, 'config/max_leaves': 7, 'config/min_child_weight': 0.7194782287954906, 'config/learning_rate': 0.1699488535947036, 'config/subsample': 0.937812919568431, 'config/colsample_bylevel': 0.46157621361638057, 'config/colsample_bytree': 0.5920758489942983, 'config/reg_alpha': 0.026965210811239645, 'config/reg_lambda': 0.17802710319230947, 'experiment_tag': 'exp', 'time_total_s': 4.216137886047363}\n",
      "[flaml.automl.logger: 06-10 14:15:17] {2392} INFO -  at 85.3s,\testimator xgboost's best error=0.2617,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:17] {2219} INFO - iteration 67, current learner rf\n",
      "[flaml.tune.tune: 06-10 14:15:17] {811} INFO - trial 1 config: {'n_estimators': 4, 'max_features': 0.10827489540854032, 'max_leaves': 1725, 'criterion': 'gini'}\n",
      "[flaml.tune.tune: 06-10 14:15:17] {202} INFO - result: {'pred_time': 2.137597401936849e-06, 'wall_clock_time': 85.63795208930969, 'metric_for_logging': {'pred_time': 2.137597401936849e-06}, 'val_loss': 0.3586666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240a85990>, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_features': 0.10827489540854032, 'max_leaves': 1725, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.10827489540854032, 'config/max_leaves': 1725, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2991504669189453}\n",
      "[flaml.tune.tune: 06-10 14:15:17] {202} INFO - result: {'pred_time': 2.137597401936849e-06, 'wall_clock_time': 85.63795208930969, 'metric_for_logging': {'pred_time': 2.137597401936849e-06}, 'val_loss': 0.3586666666666667, 'trained_estimator': <flaml.automl.model.RandomForestEstimator object at 0x7f4240a85990>, 'training_iteration': 1, 'config': {'n_estimators': 4, 'max_features': 0.10827489540854032, 'max_leaves': 1725, 'criterion': 'gini'}, 'config/n_estimators': 4, 'config/max_features': 0.10827489540854032, 'config/max_leaves': 1725, 'config/criterion': 'gini', 'experiment_tag': 'exp', 'time_total_s': 0.2998361587524414}\n",
      "[flaml.automl.logger: 06-10 14:15:17] {2392} INFO -  at 85.6s,\testimator rf's best error=0.3240,\tbest estimator xgboost's best error=0.2617\n",
      "[flaml.automl.logger: 06-10 14:15:17] {2219} INFO - iteration 68, current learner xgboost\n",
      "[flaml.tune.tune: 06-10 14:15:17] {811} INFO - trial 1 config: {'n_estimators': 1238, 'max_leaves': 340, 'min_child_weight': 0.3369642038062319, 'learning_rate': 0.05717352842648702, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.22820469798161158, 'colsample_bytree': 0.47685226226628724, 'reg_alpha': 0.012994716246045418, 'reg_lambda': 1.6414568993208103}\n",
      "[flaml.tune.tune: 06-10 14:16:51] {202} INFO - result: {'pred_time': 5.976104736328125e-06, 'wall_clock_time': 179.75823760032654, 'metric_for_logging': {'pred_time': 5.976104736328125e-06}, 'val_loss': 0.26160000000000005, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f4241023310>, 'training_iteration': 0, 'config': {'n_estimators': 1238, 'max_leaves': 340, 'min_child_weight': 0.3369642038062319, 'learning_rate': 0.05717352842648702, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.22820469798161158, 'colsample_bytree': 0.47685226226628724, 'reg_alpha': 0.012994716246045418, 'reg_lambda': 1.6414568993208103}, 'config/n_estimators': 1238, 'config/max_leaves': 340, 'config/min_child_weight': 0.3369642038062319, 'config/learning_rate': 0.05717352842648702, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.22820469798161158, 'config/colsample_bytree': 0.47685226226628724, 'config/reg_alpha': 0.012994716246045418, 'config/reg_lambda': 1.6414568993208103, 'experiment_tag': 'exp', 'time_total_s': 94.11728310585022}\n",
      "[flaml.tune.tune: 06-10 14:16:51] {202} INFO - result: {'pred_time': 5.976104736328125e-06, 'wall_clock_time': 179.75823760032654, 'metric_for_logging': {'pred_time': 5.976104736328125e-06}, 'val_loss': 0.26160000000000005, 'trained_estimator': <flaml.automl.model.XGBoostSklearnEstimator object at 0x7f4241023310>, 'training_iteration': 1, 'config': {'n_estimators': 1238, 'max_leaves': 340, 'min_child_weight': 0.3369642038062319, 'learning_rate': 0.05717352842648702, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.22820469798161158, 'colsample_bytree': 0.47685226226628724, 'reg_alpha': 0.012994716246045418, 'reg_lambda': 1.6414568993208103}, 'config/n_estimators': 1238, 'config/max_leaves': 340, 'config/min_child_weight': 0.3369642038062319, 'config/learning_rate': 0.05717352842648702, 'config/subsample': 0.8413048297641477, 'config/colsample_bylevel': 0.22820469798161158, 'config/colsample_bytree': 0.47685226226628724, 'config/reg_alpha': 0.012994716246045418, 'config/reg_lambda': 1.6414568993208103, 'experiment_tag': 'exp', 'time_total_s': 94.11895489692688}\n",
      "[flaml.automl.logger: 06-10 14:16:51] {2392} INFO -  at 179.8s,\testimator xgboost's best error=0.2616,\tbest estimator xgboost's best error=0.2616\n",
      "[flaml.automl.logger: 06-10 14:16:51] {2219} INFO - iteration 69, current learner lrl1\n",
      "[flaml.tune.tune: 06-10 14:16:51] {811} INFO - trial 1 config: {'C': 1.0}\n",
      "[flaml.tune.tune: 06-10 14:17:00] {202} INFO - result: {'pred_time': 1.8444061279296874e-06, 'wall_clock_time': 188.40693378448486, 'metric_for_logging': {'pred_time': 1.8444061279296874e-06}, 'val_loss': 0.6958666666666666, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7f402bcbb9a0>, 'training_iteration': 0, 'config': {'C': 1.0}, 'config/C': 1.0, 'experiment_tag': 'exp', 'time_total_s': 8.629816770553589}\n",
      "[flaml.tune.tune: 06-10 14:17:00] {202} INFO - result: {'pred_time': 1.8444061279296874e-06, 'wall_clock_time': 188.40693378448486, 'metric_for_logging': {'pred_time': 1.8444061279296874e-06}, 'val_loss': 0.6958666666666666, 'trained_estimator': <flaml.automl.model.LRL1Classifier object at 0x7f402bcbb9a0>, 'training_iteration': 1, 'config': {'C': 1.0}, 'config/C': 1.0, 'experiment_tag': 'exp', 'time_total_s': 8.63353443145752}\n",
      "[flaml.automl.logger: 06-10 14:17:00] {2392} INFO -  at 188.4s,\testimator lrl1's best error=0.6959,\tbest estimator xgboost's best error=0.2616\n",
      "[flaml.automl.logger: 06-10 14:17:00] {2494} INFO - selected model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.22820469798161158, colsample_bynode=None,\n",
      "              colsample_bytree=0.47685226226628724, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.05717352842648702,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=340,\n",
      "              min_child_weight=0.3369642038062319, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=1238,\n",
      "              n_jobs=-1, num_parallel_tree=None, objective='multi:softprob', ...)\n",
      "[flaml.automl.logger: 06-10 14:17:00] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 06-10 14:17:00] {1932} INFO - Time taken to find the best model: 179.75823760032654\n",
      "[flaml.automl.logger: 06-10 14:17:00] {1942} WARNING - Time taken to find the best model is 100% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "Best hyper-parmeter config: {'n_estimators': 1238, 'max_leaves': 340, 'min_child_weight': 0.3369642038062319, 'learning_rate': 0.05717352842648702, 'subsample': 0.8413048297641477, 'colsample_bylevel': 0.22820469798161158, 'colsample_bytree': 0.47685226226628724, 'reg_alpha': 0.012994716246045418, 'reg_lambda': 1.6414568993208103}\n",
      "Best accuracy on validation data: 0.7384\n",
      "Training duration of best run: 94.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:17:23.914745Z",
     "start_time": "2024-06-10T14:17:23.909293Z"
    }
   },
   "cell_type": "code",
   "source": "automl.model.estimator.get_params()",
   "id": "c08a3ac308698263",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': [],\n",
       " 'colsample_bylevel': 0.22820469798161158,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 0.47685226226628724,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': 'lossguide',\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.05717352842648702,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 0,\n",
       " 'max_leaves': 340,\n",
       " 'min_child_weight': 0.3369642038062319,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': 1238,\n",
       " 'n_jobs': -1,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.012994716246045418,\n",
       " 'reg_lambda': 1.6414568993208103,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 0.8413048297641477,\n",
       " 'tree_method': 'hist',\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can transplant the best model to a scikit-learn model",
   "id": "bb410a09570aeeda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For custom estimators you need to define a custom search space\n",
    "\n",
    "```python\n",
    "from flaml.automl.model import SKLearnEstimator\n",
    "# SKLearnEstimator is derived from BaseEstimator\n",
    "import rgf\n",
    "\n",
    "\n",
    "class MyRegularizedGreedyForest(SKLearnEstimator):\n",
    "    def __init__(self, task=\"binary\", **config):\n",
    "        super().__init__(task, **config)\n",
    "\n",
    "        if task in CLASSIFICATION:\n",
    "            from rgf.sklearn import RGFClassifier\n",
    "            self.estimator_class = RGFClassifier\n",
    "        else:\n",
    "            from rgf.sklearn import RGFRegressor\n",
    "            self.estimator_class = RGFRegressor\n",
    "\n",
    "    @classmethod\n",
    "    def search_space(cls, data_size, task):\n",
    "        space = {\n",
    "        \"max_leaf\": {\n",
    "            \"domain\": tune.lograndint(lower=4, upper=data_size),\n",
    "            \"low_cost_init_value\": 4,\n",
    "        },\n",
    "        \"n_iter\": {\n",
    "            \"domain\": tune.lograndint(lower=1, upper=data_size),\n",
    "            \"low_cost_init_value\": 1,\n",
    "        },\n",
    "        \"learning_rate\": {\"domain\": tune.loguniform(lower=0.01, upper=20.0)},\n",
    "        \"min_samples_leaf\": {\n",
    "            \"domain\": tune.lograndint(lower=1, upper=20),\n",
    "            \"init_value\": 20,\n",
    "        },\n",
    "        }\n",
    "        return space\n",
    "```"
   ],
   "id": "fc449965b9c754d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bayesian optimization",
   "id": "99073c475248f08f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Bayesian Optimization builds a probability model of the objective function and uses it to select hyperparameter to evaluate in the true objective function.\n",
    "Uses Gaussian Processes and Tree-structured Parzen Estimators for finding the next best hyperparameter.\n",
    "> Prezen-Trees are a type of decision tree that uses a kernel density estimator to estimate the probability density function of the target variable.\n",
    "\n",
    "Probably better explained [here](https://towardsdatascience.com/bayesian-optimization-concept-explained-in-layman-terms-1d2bcdeaf12f)  \n"
   ],
   "id": "fb5bd76576393fdb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:17:37.584985Z",
     "start_time": "2024-06-10T14:17:31.766340Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install scikit-optimize",
   "id": "cdee33731984e9ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Collecting scikit-optimize\r\n",
      "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m107.8/107.8 KB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pyaml>=16.9\r\n",
      "  Downloading pyaml-24.4.0-py3-none-any.whl (24 kB)\r\n",
      "Requirement already satisfied: packaging>=21.3 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-optimize) (24.0)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-optimize) (1.4.1.post1)\r\n",
      "Requirement already satisfied: numpy>=1.20.3 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-optimize) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-optimize) (1.12.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-optimize) (1.3.2)\r\n",
      "Collecting PyYAML\r\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m705.5/705.5 KB\u001B[0m \u001B[31m9.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in ./envs/sentiocx/lib/python3.10/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.4.0)\r\n",
      "Installing collected packages: PyYAML, pyaml, scikit-optimize\r\n",
      "Successfully installed PyYAML-6.0.1 pyaml-24.4.0 scikit-optimize-0.10.2\r\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:41:34.637403Z",
     "start_time": "2024-06-10T14:18:43.574006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': Categorical([True, False]),\n",
    "    'max_depth': Integer(10, 100),\n",
    "    'max_features': Integer(1, 10),\n",
    "    'min_samples_leaf': Integer(1, 10),\n",
    "    'min_samples_split': Integer(2, 10),\n",
    "    'n_estimators': Integer(10, 100),\n",
    "    'max_leaf_nodes': Integer(10, 100),\n",
    "    'min_impurity_decrease': Real(0.0, 0.1),\n",
    "    'criterion': Categorical(['gini', 'entropy']),\n",
    "    'min_weight_fraction_leaf': Real(0.0, 0.5),\n",
    "}\n",
    "    \n",
    "bayes_search = BayesSearchCV(model, param_grid, n_iter=100, cv=3, n_jobs=-1, verbose=2)\n",
    "bayes_search.fit(X_train, y_train)"
   ],
   "id": "ee74e90dadd1f0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=70, max_features=4, max_leaf_nodes=59, min_impurity_decrease=0.09412262826832916, min_samples_leaf=2, min_samples_split=8, min_weight_fraction_leaf=0.42003791792002493, n_estimators=59; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=70, max_features=4, max_leaf_nodes=59, min_impurity_decrease=0.09412262826832916, min_samples_leaf=2, min_samples_split=8, min_weight_fraction_leaf=0.42003791792002493, n_estimators=59; total time=   0.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=49, max_features=6, max_leaf_nodes=49, min_impurity_decrease=0.03915258302681201, min_samples_leaf=7, min_samples_split=9, min_weight_fraction_leaf=0.4333337090808822, n_estimators=45; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=49, max_features=6, max_leaf_nodes=49, min_impurity_decrease=0.03915258302681201, min_samples_leaf=7, min_samples_split=9, min_weight_fraction_leaf=0.4333337090808822, n_estimators=45; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=49, max_features=6, max_leaf_nodes=49, min_impurity_decrease=0.03915258302681201, min_samples_leaf=7, min_samples_split=9, min_weight_fraction_leaf=0.4333337090808822, n_estimators=45; total time=   1.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=99, max_features=9, max_leaf_nodes=58, min_impurity_decrease=0.07305824530591491, min_samples_leaf=9, min_samples_split=3, min_weight_fraction_leaf=0.3661233369866595, n_estimators=43; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=99, max_features=9, max_leaf_nodes=58, min_impurity_decrease=0.07305824530591491, min_samples_leaf=9, min_samples_split=3, min_weight_fraction_leaf=0.3661233369866595, n_estimators=43; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=99, max_features=9, max_leaf_nodes=58, min_impurity_decrease=0.07305824530591491, min_samples_leaf=9, min_samples_split=3, min_weight_fraction_leaf=0.3661233369866595, n_estimators=43; total time=   1.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=11, max_features=1, max_leaf_nodes=40, min_impurity_decrease=0.09405729951367775, min_samples_leaf=9, min_samples_split=8, min_weight_fraction_leaf=0.0, n_estimators=90; total time=   1.1s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=11, max_features=1, max_leaf_nodes=40, min_impurity_decrease=0.09405729951367775, min_samples_leaf=9, min_samples_split=8, min_weight_fraction_leaf=0.0, n_estimators=90; total time=   1.2s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=11, max_features=1, max_leaf_nodes=40, min_impurity_decrease=0.09405729951367775, min_samples_leaf=9, min_samples_split=8, min_weight_fraction_leaf=0.0, n_estimators=90; total time=   1.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=62, max_features=1, max_leaf_nodes=57, min_impurity_decrease=0.007698059097111003, min_samples_leaf=8, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=21; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=62, max_features=1, max_leaf_nodes=57, min_impurity_decrease=0.007698059097111003, min_samples_leaf=8, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=21; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=62, max_features=1, max_leaf_nodes=57, min_impurity_decrease=0.007698059097111003, min_samples_leaf=8, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=21; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=33, max_features=1, max_leaf_nodes=42, min_impurity_decrease=0.036676517114242364, min_samples_leaf=4, min_samples_split=9, min_weight_fraction_leaf=0.0, n_estimators=56; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=33, max_features=1, max_leaf_nodes=42, min_impurity_decrease=0.036676517114242364, min_samples_leaf=4, min_samples_split=9, min_weight_fraction_leaf=0.0, n_estimators=56; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=33, max_features=1, max_leaf_nodes=42, min_impurity_decrease=0.036676517114242364, min_samples_leaf=4, min_samples_split=9, min_weight_fraction_leaf=0.0, n_estimators=56; total time=   0.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=72, max_features=2, max_leaf_nodes=42, min_impurity_decrease=0.06792126426318285, min_samples_leaf=8, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=37; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=72, max_features=2, max_leaf_nodes=42, min_impurity_decrease=0.06792126426318285, min_samples_leaf=8, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=37; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=72, max_features=2, max_leaf_nodes=42, min_impurity_decrease=0.06792126426318285, min_samples_leaf=8, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=37; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=96, max_features=9, max_leaf_nodes=28, min_impurity_decrease=0.025880369875727855, min_samples_leaf=9, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=25; total time=   5.4s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=96, max_features=9, max_leaf_nodes=28, min_impurity_decrease=0.025880369875727855, min_samples_leaf=9, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=25; total time=   5.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=96, max_features=9, max_leaf_nodes=28, min_impurity_decrease=0.025880369875727855, min_samples_leaf=9, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=25; total time=   5.5s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=94, max_features=6, max_leaf_nodes=42, min_impurity_decrease=0.01610821242517734, min_samples_leaf=8, min_samples_split=10, min_weight_fraction_leaf=0.0060224405050808855, n_estimators=31; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=2, max_leaf_nodes=68, min_impurity_decrease=0.005305084952369039, min_samples_leaf=1, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=   3.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=5, max_leaf_nodes=28, min_impurity_decrease=0.03637934981190102, min_samples_leaf=9, min_samples_split=5, min_weight_fraction_leaf=0.3054780023927766, n_estimators=57; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=2, max_leaf_nodes=68, min_impurity_decrease=0.005305084952369039, min_samples_leaf=1, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=5, max_leaf_nodes=28, min_impurity_decrease=0.03637934981190102, min_samples_leaf=9, min_samples_split=5, min_weight_fraction_leaf=0.3054780023927766, n_estimators=57; total time=   1.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=2, max_leaf_nodes=68, min_impurity_decrease=0.005305084952369039, min_samples_leaf=1, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=   3.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=94, max_features=6, max_leaf_nodes=42, min_impurity_decrease=0.01610821242517734, min_samples_leaf=8, min_samples_split=10, min_weight_fraction_leaf=0.0060224405050808855, n_estimators=31; total time=   0.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=1, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=10, min_weight_fraction_leaf=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=86, max_features=2, max_leaf_nodes=11, min_impurity_decrease=0.0678160048214618, min_samples_leaf=7, min_samples_split=4, min_weight_fraction_leaf=0.37823230212566755, n_estimators=28; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=1, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=10, min_weight_fraction_leaf=0.5, n_estimators=10; total time=   0.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=94, max_features=6, max_leaf_nodes=42, min_impurity_decrease=0.01610821242517734, min_samples_leaf=8, min_samples_split=10, min_weight_fraction_leaf=0.0060224405050808855, n_estimators=31; total time=   0.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=1, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=10, min_weight_fraction_leaf=0.5, n_estimators=10; total time=   0.1s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=24, max_features=2, max_leaf_nodes=72, min_impurity_decrease=0.05225480768820622, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.3830929226666833, n_estimators=24; total time=   0.3s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=100, max_features=8, max_leaf_nodes=100, min_impurity_decrease=0.04480230196668174, min_samples_leaf=10, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=33; total time=   8.4s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=52, max_features=6, max_leaf_nodes=85, min_impurity_decrease=0.02788117193062649, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.4969374483179934, n_estimators=37; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=100, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=2, min_samples_split=5, min_weight_fraction_leaf=0.5, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=83, max_features=9, max_leaf_nodes=87, min_impurity_decrease=0.09118643554622413, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.22627221410823878, n_estimators=70; total time=   1.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=100, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=2, min_samples_split=5, min_weight_fraction_leaf=0.5, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=52, max_features=6, max_leaf_nodes=85, min_impurity_decrease=0.02788117193062649, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.4969374483179934, n_estimators=37; total time=   0.6s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=100, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=2, min_samples_split=5, min_weight_fraction_leaf=0.5, n_estimators=10; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=83, max_features=9, max_leaf_nodes=87, min_impurity_decrease=0.09118643554622413, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.22627221410823878, n_estimators=70; total time=   1.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=1, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10; total time=   0.4s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=83, max_features=9, max_leaf_nodes=87, min_impurity_decrease=0.09118643554622413, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.22627221410823878, n_estimators=70; total time=   1.6s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=1, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10; total time=   0.5s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=19, max_features=9, max_leaf_nodes=99, min_impurity_decrease=0.08078319976229816, min_samples_leaf=5, min_samples_split=5, min_weight_fraction_leaf=0.24056596414387732, n_estimators=55; total time=   2.8s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=1, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10; total time=   0.5s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=53, max_features=5, max_leaf_nodes=28, min_impurity_decrease=0.03637934981190102, min_samples_leaf=9, min_samples_split=5, min_weight_fraction_leaf=0.3054780023927766, n_estimators=57; total time=   1.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=58, max_features=6, max_leaf_nodes=30, min_impurity_decrease=0.049976631692129105, min_samples_leaf=3, min_samples_split=3, min_weight_fraction_leaf=0.025894423221080105, n_estimators=24; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=4, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.7s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=87, max_features=5, max_leaf_nodes=87, min_impurity_decrease=0.0449359882648185, min_samples_leaf=1, min_samples_split=6, min_weight_fraction_leaf=0.13075334302914463, n_estimators=99; total time=   4.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=4, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.8s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, criterion=entropy, max_depth=87, max_features=5, max_leaf_nodes=87, min_impurity_decrease=0.0449359882648185, min_samples_leaf=1, min_samples_split=6, min_weight_fraction_leaf=0.13075334302914463, n_estimators=99; total time=   5.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=4, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.9s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=86, max_features=2, max_leaf_nodes=11, min_impurity_decrease=0.0678160048214618, min_samples_leaf=7, min_samples_split=4, min_weight_fraction_leaf=0.37823230212566755, n_estimators=28; total time=   0.2s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=10; total time=   3.8s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=24, max_features=2, max_leaf_nodes=72, min_impurity_decrease=0.05225480768820622, min_samples_leaf=5, min_samples_split=9, min_weight_fraction_leaf=0.3830929226666833, n_estimators=24; total time=   0.3s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=100, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=10; total time=   4.0s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=23, max_features=6, max_leaf_nodes=81, min_impurity_decrease=0.09952271685075764, min_samples_leaf=8, min_samples_split=5, min_weight_fraction_leaf=0.22534967568190556, n_estimators=24; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=100, max_features=10, max_leaf_nodes=83, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=8, min_weight_fraction_leaf=0.0607687126264713, n_estimators=100; total time=  22.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.1, min_samples_leaf=10, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100; total time=   2.5s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=23, max_features=6, max_leaf_nodes=81, min_impurity_decrease=0.09952271685075764, min_samples_leaf=8, min_samples_split=5, min_weight_fraction_leaf=0.22534967568190556, n_estimators=24; total time=   0.5s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=100, max_features=10, max_leaf_nodes=83, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=8, min_weight_fraction_leaf=0.0607687126264713, n_estimators=100; total time=  23.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.1, min_samples_leaf=10, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100; total time=   2.6s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=21, max_features=2, max_leaf_nodes=57, min_impurity_decrease=0.07146919599491772, min_samples_leaf=5, min_samples_split=6, min_weight_fraction_leaf=0.25520026609849245, n_estimators=55; total time=   0.9s\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=100, max_features=10, max_leaf_nodes=83, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=8, min_weight_fraction_leaf=0.0607687126264713, n_estimators=100; total time=  23.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.1, min_samples_leaf=10, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100; total time=   2.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=False, criterion=entropy, max_depth=76, max_features=2, max_leaf_nodes=97, min_impurity_decrease=0.013529433607445067, min_samples_leaf=9, min_samples_split=5, min_weight_fraction_leaf=0.4069912068167541, n_estimators=57; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.7s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=42, max_features=9, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  14.2s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, max_features=4, max_leaf_nodes=74, min_impurity_decrease=0.008357841693208858, min_samples_leaf=4, min_samples_split=8, min_weight_fraction_leaf=0.03866426531500062, n_estimators=52; total time=   1.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  16.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=42, max_features=9, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  14.4s\n",
      "[CV] END bootstrap=False, criterion=gini, max_depth=11, max_features=4, max_leaf_nodes=74, min_impurity_decrease=0.008357841693208858, min_samples_leaf=4, min_samples_split=8, min_weight_fraction_leaf=0.03866426531500062, n_estimators=52; total time=   2.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=42, max_features=9, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  14.6s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=28, max_features=9, max_leaf_nodes=52, min_impurity_decrease=0.08119371266793941, min_samples_leaf=2, min_samples_split=9, min_weight_fraction_leaf=0.43924329474296825, n_estimators=25; total time=   0.6s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=8, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=9, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  14.0s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=45, max_features=9, max_leaf_nodes=70, min_impurity_decrease=0.09281801151987197, min_samples_leaf=3, min_samples_split=8, min_weight_fraction_leaf=0.1887683488285124, n_estimators=34; total time=   2.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=8, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.9s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=9, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  14.1s\n",
      "[CV] END bootstrap=True, criterion=entropy, max_depth=45, max_features=9, max_leaf_nodes=70, min_impurity_decrease=0.09281801151987197, min_samples_leaf=3, min_samples_split=8, min_weight_fraction_leaf=0.1887683488285124, n_estimators=34; total time=   2.2s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=10, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=8, min_samples_split=10, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  15.8s\n",
      "[CV] END bootstrap=True, criterion=gini, max_depth=10, max_features=9, max_leaf_nodes=100, min_impurity_decrease=0.0, min_samples_leaf=10, min_samples_split=6, min_weight_fraction_leaf=0.0, n_estimators=100; total time=  14.2s\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [True, 'gini', 100, 5, 100, 0.0, 10, 2, 0.0, 100] before, using random point [True, 'gini', 79, 3, 86, 0.05096468322047318, 5, 4, 0.1176891672506021, 29]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/envs/sentiocx/lib/python3.10/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [True, 'gini', 100, 5, 100, 0.0, 10, 2, 0.0, 100] before, using random point [True, 'gini', 13, 6, 17, 0.04062779393700803, 1, 2, 0.020432155263404642, 13]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=20),\n",
       "              n_iter=100, n_jobs=-1,\n",
       "              search_spaces={'bootstrap': Categorical(categories=(True, False), prior=None),\n",
       "                             'criterion': Categorical(categories=('gini', 'entropy'), prior=None),\n",
       "                             'max_depth': Integer(low=10, high=100, prior='uniform', transform='normalize'),\n",
       "                             'max_features': Integer(low=1, high=10, prior='...\n",
       "                             'min_impurity_decrease': Real(low=0.0, high=0.1, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_leaf': Integer(low=1, high=10, prior='uniform', transform='normalize'),\n",
       "                             'min_samples_split': Integer(low=2, high=10, prior='uniform', transform='normalize'),\n",
       "                             'min_weight_fraction_leaf': Real(low=0.0, high=0.5, prior='uniform', transform='normalize'),\n",
       "                             'n_estimators': Integer(low=10, high=100, prior='uniform', transform='normalize')},\n",
       "              verbose=2)"
      ],
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=20),\n",
       "              n_iter=100, n_jobs=-1,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: Categorical(categories=(True, False), prior=None),\n",
       "                             &#x27;criterion&#x27;: Categorical(categories=(&#x27;gini&#x27;, &#x27;entropy&#x27;), prior=None),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=10, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=10, prior=&#x27;...\n",
       "                             &#x27;min_impurity_decrease&#x27;: Real(low=0.0, high=0.1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_leaf&#x27;: Integer(low=1, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_weight_fraction_leaf&#x27;: Real(low=0.0, high=0.5, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=20),\n",
       "              n_iter=100, n_jobs=-1,\n",
       "              search_spaces={&#x27;bootstrap&#x27;: Categorical(categories=(True, False), prior=None),\n",
       "                             &#x27;criterion&#x27;: Categorical(categories=(&#x27;gini&#x27;, &#x27;entropy&#x27;), prior=None),\n",
       "                             &#x27;max_depth&#x27;: Integer(low=10, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;max_features&#x27;: Integer(low=1, high=10, prior=&#x27;...\n",
       "                             &#x27;min_impurity_decrease&#x27;: Real(low=0.0, high=0.1, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_leaf&#x27;: Integer(low=1, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_samples_split&#x27;: Integer(low=2, high=10, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;min_weight_fraction_leaf&#x27;: Real(low=0.0, high=0.5, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;),\n",
       "                             &#x27;n_estimators&#x27;: Integer(low=10, high=100, prior=&#x27;uniform&#x27;, transform=&#x27;normalize&#x27;)},\n",
       "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=20)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=20)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:18:25.818483Z",
     "start_time": "2024-06-10T14:18:25.813768Z"
    }
   },
   "cell_type": "code",
   "source": "bayes_search.best_params_",
   "id": "9acd0e538c0d72d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bootstrap', True),\n",
       "             ('criterion', 'entropy'),\n",
       "             ('max_depth', 53),\n",
       "             ('max_features', 5),\n",
       "             ('max_leaf_nodes', 28),\n",
       "             ('min_impurity_decrease', 0.03637934981190102),\n",
       "             ('min_samples_leaf', 9),\n",
       "             ('min_samples_split', 5),\n",
       "             ('min_weight_fraction_leaf', 0.3054780023927766),\n",
       "             ('n_estimators', 57)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T14:41:34.643303Z",
     "start_time": "2024-06-10T14:41:34.639319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bayes_search.best_score_\n",
    "# 0.76435"
   ],
   "id": "db640283e4e99914",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76435"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T13:33:28.908921Z",
     "start_time": "2024-05-29T13:33:11.581303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from skopt.plots import plot_objective\n",
    "plot_objective(bayes_search.optimizer_results_[0])"
   ],
   "id": "20930343ce826b46",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 101 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## HEBO",
   "id": "357da747516aadb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Genetic Algorithms + Bayesian Optimisation",
   "id": "fdc7b9bfb232084c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install hebo",
   "id": "7e9415fa1efc07d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Bayesian optimsation library developed by Huawei Noahs Ark Decision Making and Reasoning (DMnR) lab. The winning submission to the NeurIPS 2020 Black-Box Optimisation Challenge.",
   "id": "debb47a734638834"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from hebo.sklearn_tuner import sklearn_tuner\n",
    "\n",
    "space_cfg = [\n",
    "    {'name' : 'max_depth', 'type' : 'int', 'lb' : 1, 'ub' : 20},\n",
    "    {'name' : 'min_samples_leaf', 'type' : 'num', 'lb' : 1e-4, 'ub' : 0.5},\n",
    "    {'name' : 'max_features', 'type' : 'cat', 'categories' : ['auto', 'sqrt', 'log2']},\n",
    "    {'name' : 'bootstrap', 'type' : 'bool'},\n",
    "    {'name' : 'min_impurity_decrease', 'type' : 'pow', 'lb' : 1e-4, 'ub' : 1.0},\n",
    "    ]\n",
    "\n",
    "result = sklearn_tuner(RandomForestRegressor, space_cfg, X_train, y_train, metric = r2_score, max_iter = 16)"
   ],
   "id": "d5787573f7f15969",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Homework: RayTune + Optuna",
   "id": "6dad7a2df5e10d32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f8c2becf403db841"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiocx",
   "language": "python",
   "name": "sentiocx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
